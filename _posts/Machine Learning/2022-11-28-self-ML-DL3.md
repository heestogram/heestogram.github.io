---
title: "[ML] í˜¼ê³µë¨¸ë‹ 3í¸ ë¡œì§€ìŠ¤í‹± íšŒê·€ì™€ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(Stochastic Gradient Descent"
excerpt: "ë¡œì§€ìŠ¤í‹± íšŒê·€ì™€ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ì"
toc: true
toc_label: "ëª©ì°¨"
toc_sticky: true

tags: [k-ìµœê·¼ì ‘ì´ì›ƒ, ML, ë¡œì§€ìŠ¤í‹± íšŒê·€]

published: true

categories:
  - ML

date: 2022-11-28 01:10:30
last_modified_at: 2022-11-28 01:10:30
---

<br>

<div class="notice--primary" markdown="1">
ğŸ’¡ â€˜í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë”¥ëŸ¬ë‹(ë°•í•´ì„  ì €)â€™ ì±…ì„ ì½ê³  ê³µë¶€í•œ ë‚´ìš©ì„ ìš”ì•½í•œ í˜ì´ì§€ì…ë‹ˆë‹¤.<br>
ì±…ì— ë‚˜ì˜¤ëŠ” ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì“°ì§€ ì•Šê³ , ì½”ë“œì™€ íŒŒë¼ë¯¸í„°ë¥¼ ë³€í˜•í•˜ê³  ì¡°ì •í•´ê°€ë©° ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ë©° ê³µë¶€í–ˆìŠµë‹ˆë‹¤.
</div>

<br>

## 04 ë‹¤ì–‘í•œ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜

---

### **04-1 ë¡œì§€ìŠ¤í‹± íšŒê·€**

- **k-ìµœê·¼ì ‘ ì´ì›ƒ ë¶„ë¥˜ê¸°**: k-ìµœê·¼ì ‘ ì´ì›ƒì„ ì´ìš©í•˜ì—¬ ì¸ì ‘ ìƒ˜í”Œì˜ í´ë˜ìŠ¤ ë¹„ìœ¨ì„ í™•ë¥ ë¡œ ë‚˜íƒ€ë‚´ëŠ” ë°©ì‹ 

```python
#ë°ì´í„° ì¤€ë¹„
import pandas as pd
fish = pd.read_csv('https://bit.ly/fish_csv_data')
fish.head() #ì²˜ìŒ 5ê°œ í–‰ ì¶œë ¥
print(pd.unique(fish['Species']))
fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()
fish_target= fish['Species'].to_numpy()

#í›ˆë ¨ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ì„¸íŠ¸ êµ¬ë¶„
from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)

#í‘œì¤€í™” ì „ì²˜ë¦¬
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
ss.fit(train_input)
train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)

from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier(n_neighbors=3)
kn.fit(train_scaled, train_target)
print(kn.score(train_scaled, train_target))
print(kn.score(test_scaled, test_target))

import numpy as np
proba = kn.predict_proba(test_scaled[:5]) #í…ŒìŠ¤íŠ¸ì„¸íŠ¸ ì²« 5ê°œ ìƒ˜í”Œì˜ í™•ë¥ 
print(np.round(proba, decimals=4)) #ì†Œìˆ˜ì  ë„¤ë²ˆì§¸ ìë¦¬ê¹Œì§€ í‘œê¸°, ë‹¤ì„¯ë²ˆì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼

distances, indexes = kn.kneighbors(test_scaled[3:4])
print(train_target[indexes])
```

ê·¸ëŸ¬ë‚˜ k-ìµœê·¼ì ‘ ì´ì›ƒ ë°©ì‹ì€ 3ê°œì˜ ìµœê·¼ì ‘ ì´ì›ƒë§Œì„ í™œìš©í•˜ê¸°ì— ê°€ëŠ¥í•œ í™•ë¥ ì€ 0/3, 1/3, 2/3, 3/3ì´ ì „ë¶€ì´ë‹¤. ë” ë””í…Œì¼í•œ í™•ë¥ ì´ í•„ìš”í•˜ë‹¤. ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ì´ê²ƒì„ ê°€ëŠ¥í•˜ê²Œ í•´ì¤€ë‹¤.

- **ë¡œì§€ìŠ¤í‹± íšŒê·€(logistic regression)**: ì„ í˜• ë°©ì •ì‹ì„ í™œìš©í•œ ë¶„ë¥˜ ëª¨ë¸ë¡œì„œ, **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜**ë‚˜ **ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜**ë¥¼ í™œìš©í•˜ì—¬ í´ë˜ìŠ¤ì˜ í™•ë¥ ì„ ì¶œë ¥í•œë‹¤. zê°’ì´ ì•„ì£¼ í° ìŒìˆ˜ì´ë©´ í™•ë¥ ì´ 0ì´ ë˜ê³ , ì•„ì£¼ í° ì–‘ìˆ˜ì´ë©´ 1ì´ ë˜ë„ë¡ í•œë‹¤.
 

<div align= 'center'>

<img src="https://user-images.githubusercontent.com/115082062/204144843-45eb7671-416c-4b20-852a-1dd48aadf363.png">

</div>

ì™¼ìª½ì€ ì‹œê·¸ëª¨ì´ë“œ ê·¸ë˜í”„, ì˜¤ë¥¸ìª½ì€ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜. xê°’ì´ ë¡œì§€ìŠ¤í‹± ë°©ì •ì‹ì´ë‹¤.



```python
#ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ê·¸ë¦¬ê¸°
import numpy as np
import matplotlib.pyplot as plt
z = np.arange(-5,5,0.1)
phi = 1/(1+np.exp(-z))
plt.plot(z, phi)
plt.xlabel('z')
plt.ylabel('phi')
plt.show()
```

ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ ê°„ë‹¨í•œ ì´ì§„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•´ë³´ì. ì´ì§„ë¶„ë¥˜ì˜ ê²½ìš° ì‹œê·¸ëª¨ì´ë“œì˜ ì¶œë ¥ì´ 0.5ë³´ë‹¤ í¬ë©´ ì–‘ì„±, ì‘ìœ¼ë©´ ìŒì„±ìœ¼ë¡œ íŒë‹¨í•œë‹¤.

```python
#ë¶ˆë¦¬ì–¸ ì¸ë±ì‹±ì„ í™œìš©í•˜ì—¬ ë„ë¯¸(Bream)ì™€ ë¹™ì–´(Smelt)ë§Œ ë½‘ì•„ëƒ„
bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt')

train_bream_smelt = train_scaled[bream_smelt_indexes]
target_bream_smelt = train_target[bream_smelt_indexes]

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(train_bream_smelt, target_bream_smelt)

print(lr.predict(train_bream_smelt[:5])) #ì²˜ìŒ 5ê°œ ìƒ˜í”Œ ì˜ˆì¸¡
print(lr.predict_proba(train_bream_smelt[:5])) #ì²˜ìŒ 5ê°œ ìƒ˜í”Œì˜ í™•ë¥  ì¶œë ¥
#ê²°ê³¼ê°’
['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']
[[0.99759855 0.00240145]
 [0.02735183 0.97264817]
 [0.99486072 0.00513928]
 [0.98584202 0.01415798]
 [0.99767269 0.00232731]]

#decision_function(): zê°’ì„ ê³„ì‚°í•˜ëŠ” ë©”ì„œë“œ
decisions = lr.decision_function(train_bream_smelt[:5])
print(decisions)
#ê²°ê³¼ê°’
[-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]
#ì´ zê°’ì„ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì— ë„£ìœ¼ë©´ í™•ë¥ ì„ ì–»ì„ ìˆ˜ ìˆìŒ

from scipy.special import expit
print(expit(decisions))
#ê²°ê³¼ê°’
[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
#predict_proba()ë©”ì„œë“œ ì¶œë ¥ì˜ ë‘ë²ˆì§¸ ì—´ê³¼ ë™ì¼!
```

ì´ì œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ ë‹¤ì¤‘ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•´ë³´ì.

```python
lr = LogisticRegression(C=20, max_iter=1000)
#max_iterë§¤ê°œë³€ìˆ˜ëŠ” ë°˜ë³µ íšŸìˆ˜ë¥¼ ì§€ì •
#CëŠ” ë¦¿ì§€ì˜ alphaì²˜ëŸ¼ ê·œì œì˜ ì •ë„ë¥¼ ìœ„í•œ ë§¤ê°œë³€ìˆ˜. ì‘ì„ìˆ˜ë¡ ê·œì œê°€ ì»¤ì§.
lr.fit(train_scaled, train_target)
print(lr.score(train_scaled, train_target)) #0.9327
print(lr.score(test_scaled, test_target)) #0.925
print(lr.predict(test_scaled[:5]))
proba = lr.predict_proba(test_scaled[:5])
print(np.round(proba, decimals=3))
```

ë‹¤ì¤‘ë¶„ë¥˜ëŠ” í´ë˜ìŠ¤ë§ˆë‹¤ zê°’ì„ í•˜ë‚˜ì”© ê³„ì‚°í•œë‹¤. ì´ì¤‘ ë¶„ë¥˜ì˜ ê²½ìš° zê°’ì„ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í™•ë¥ ë¡œ ë³€í™˜í–ˆì§€ë§Œ, ë‹¤ì¤‘ ë¶„ë¥˜ì˜ ê²½ìš° **ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜**ë¥¼ ì‚¬ìš©í•˜ì—¬ zê°’ì„ í™•ë¥ ë¡œ ë³€í™˜í•œë‹¤.

```python
decision = lr.decision_function(test_scaled[:5])
print(np.round(decision, decimals=2)) #zê°’ ì¶œë ¥.

from scipy.special import softmax
proba = softmax(decision, axis=1) #axisë§¤ê°œë³€ìˆ˜ëŠ” ê³„ì‚°í•  ì¶•ì„ ì§€ì •
print(np.round(proba, decimals=3))
#ê²°ê³¼ê°’
[[0.    0.014 0.841 0.    0.136 0.007 0.003]
 [0.    0.003 0.044 0.    0.007 0.946 0.   ]
 [0.    0.    0.034 0.935 0.015 0.016 0.   ]
 [0.011 0.034 0.306 0.007 0.567 0.    0.076]
 [0.    0.    0.904 0.002 0.089 0.002 0.001]]
#ì•ì„œ êµ¬í•œ proba ë°°ì—´ê³¼ ê²°ê³¼ê°€ ì¼ì¹˜í•¨!
```

**04-1 í•µì‹¬ í‚¤ì›Œë“œ**

- **ë¡œì§€ìŠ¤í‹± íšŒê·€**: ì„ í˜• ë°©ì •ì‹ì„ ì‚¬ìš©í•œ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜
- ë‹¤ì¤‘ ë¶„ë¥˜: íƒ€ê¹ƒ í´ë˜ìŠ¤ê°€ 2ê°œ ì´ìƒì¸ ë¶„ë¥˜ ë¬¸ì œ
- **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜**: ì´ì¤‘ ë¶„ë¥˜ì—ì„œ ì“°ì´ë©°, ì„ í˜• ë°©ì •ì‹ì˜ ì¶œë ¥(z)ì„ 0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥ ê°’ìœ¼ë¡œ ì¶œë ¥
- **ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜**: ë‹¤ì¤‘ ë¶„ë¥˜ì—ì„œ ì“°ì´ë©°, ì—¬ëŸ¬ ì„ í˜• ë°©ì •ì‹ì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ì •ê·œí™”í•˜ì—¬ í•©ì´ 1ì´ ë˜ë„ë¡ ë§Œë“¦.

**04-1 í•µì‹¬ íŒ¨í‚¤ì§€ì™€ í•¨ìˆ˜**

- scikit-learn
    - `LogisticRegression`: ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ìœ„í•œ í´ë˜ìŠ¤. Cë§¤ê°œë³€ìˆ˜ì—ì„œ ê·œì œì˜ ê°•ë„ë¥¼ ì œì–´í•œë‹¤. ì‘ì„ìˆ˜ë¡ ê·œì œê°€ ê°•í•´ì§„ë‹¤.
    - `predict_proba()`: ì˜ˆì¸¡ í™•ë¥ ì„ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ
    - `decision_function()`: ëª¨ë¸ì´ í•™ìŠµí•œ ì„ í˜• ë°©ì •ì‹ì˜ ê°’(z)ì„ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ.

---

<br>

### **04-2 í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•**

ì•ì„œ í›ˆë ¨í•œ ëª¨ë¸ì„ ë²„ë¦¬ì§€ ì•Šê³  ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ì¡°ê¸ˆì”© í›ˆë ¨í•  ìˆ˜ ì—†ì„ê¹Œ? â‡’ì´ëŸ¬í•œ ë°©ì‹ì´ ì ì§„ì  í•™ìŠµì´ë‹¤. ëŒ€í‘œì ì¸ ì ì§„ì  í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì€ **í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(Stochastic Gradient Descent)** ì´ë‹¤.

í›ˆë ¨ì„¸íŠ¸ì—ì„œ ëœë¤í•˜ê²Œ í•˜ë‚˜ì˜ ìƒ˜í”Œì„ ì„ íƒí•˜ì—¬ ê°€íŒŒë¥¸ ê²½ì‚¬ë¥¼ ì¡°ê¸ˆ ë‚´ë ¤ê°„ë‹¤. ê·¸ ë‹¤ìŒ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ëœë¤í•˜ê²Œ ë˜ ë‹¤ë¥¸ ìƒ˜í”Œì„ í•˜ë‚˜ ì„ íƒí•˜ì—¬ ê²½ì‚¬ë¥¼ ì¡°ê¸ˆ ë‚´ë ¤ê°„ë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ì „ì²´ ìƒ˜í”Œì„ ëª¨ë‘ ì‚¬ìš©í•  ë•Œê¹Œì§€ ê³„ì†í•œë‹¤. ë§Œì•½ ëª¨ë“  ìƒ˜í”Œì„ ì‚¬ìš©í–ˆë‹¤ë©´, í›ˆë ¨ì„¸íŠ¸ì— ëª¨ë“  ìƒ˜í”Œì„ ë‹¤ì‹œ ì±„ì›Œë„£ê³  ì•ì„  ê³¼ì •ì„ ë°˜ë³µí•œë‹¤. ì´ ë•Œ í›ˆë ¨ì„¸íŠ¸ë¥¼ í•œ ë²ˆ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” í…€ì„ **ì—í¬í¬(epoch)** ë¼ê³  ë¶€ë¥¸ë‹¤.

ìƒ˜í”Œì„ 1ê°œì”© êº¼ë‚´ëŠ” ê²ƒì´ **í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•**, ìƒ˜í”Œì„ ì—¬ëŸ¬ê°œì”© êº¼ë‚´ëŠ” ê²ƒì´ **ë¯¸ë‹ˆë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•**, ìƒ˜í”Œì„ ì „ë¶€ êº¼ë‚´ëŠ” ê²ƒì´ **ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•**ì´ë‹¤.

- **ì†ì‹¤í•¨ìˆ˜(loss function)**: ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì´ ì–¼ë§ˆë‚˜ ì—‰í„°ë¦¬ì¸ì§€ ì¸¡ì •í•˜ëŠ” í•¨ìˆ˜. ë¡œì§€ìŠ¤í‹± ì†ì‹¤ í•¨ìˆ˜, í¬ë¡œìŠ¤ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ ë“±ì´ ìˆë‹¤.


```python
#ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
import pandas as pd
fish = pd.read_csv('http://bit.ly/fish_csv_data')

fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()
fish_target = fish[['Species']].to_numpy()
from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
ss.fit(train_input)
train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)
```

```python
# í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•ì„ ì œê³µí•˜ëŠ” ë¶„ë¥˜ìš© í´ë˜ìŠ¤ SGDClassifier
from sklearn.linear_model import SGDClassifier
sc = SGDClassifier(loss='log', max_iter=10, random_state=42)
#lossëŠ” ì†ì‹¤í•¨ìˆ˜ë¥¼ ì§€ì •í•˜ëŠ” ë§¤ê°œë³€ìˆ˜. logëŠ” ë¡œì§€ìŠ¤í‹± ì†ì‹¤ í•¨ìˆ˜
#max_iterëŠ” ìˆ˜í–‰í•  ì—í¬íŠ¸ íšŸìˆ˜
sc.fit(train_scaled, train_target)
print(sc.score(train_scaled, train_target)) #0.7731
print(sc.score(test_scaled, test_target)) #0.775
#ì¶œë ¥ëœ í›ˆë ¨ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ì„¸íŠ¸ì˜ ì •í™•ë„ê°€ ë‚®ì€ ê±¸ ë³´ì•„í•˜ë‹ˆ ë°˜ë³µ íšŸìˆ˜ 10ë²ˆì´ ë¶€ì¡±í•œ ê²ƒìœ¼ë¡œ ë³´ì„.

sc.partial_fit(train_scaled, train_target)
#partial_fitë©”ì„œë“œëŠ” í˜¸ì¶œí•  ë•Œë§ˆë‹¤ 1 ì—í¬í¬ì”© ì´ì–´ì„œ í›ˆë ¨í•œë‹¤.
print(sc.score(train_scaled, train_target)) #0.8151
print(sc.score(test_scaled, test_target)) #0.825
#ì•„ì§ ì ìˆ˜ê°€ ë‚®ì§€ë§Œ ê·¸ë˜ë„ ë‚˜ì•„ì¡Œë‹¤.
```

ê·¸ë ‡ë‹¤ë©´ ì—í¬í¬ë¥¼ ì–´ëŠ ì •ë„ë¡œ ë‘ì–´ì•¼ ê°€ì¥ ë›°ì–´ë‚œ ì ìˆ˜ê°€ ë‚˜ì˜¬ê¹Œ.

```python
import numpy as np
sc = SGDClassifier(loss='log', random_state=42)
train_score = []
test_score = []
classes = np.unique(train_target)

for _ in range(300): #300ë²ˆì˜ ì—í¬í¬ë¥¼ ë°˜ë³µ
  sc.partial_fit(train_scaled, train_target, classes = classes)
  train_score.append(sc.score(train_scaled, train_target))
  test_score.append(sc.score(test_scaled, test_target))

import matplotlib.pyplot as plt
plt.plot(train_score)
plt.plot(test_score)
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.show()
```
<div align= 'center'>

<img src="https://user-images.githubusercontent.com/115082062/204144945-2b7985f1-e998-4614-8227-d54eaf271875.jpg">

</div>


ì£¼í™©ìƒ‰ì€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸, íŒŒë€ìƒ‰ì€ í›ˆë ¨ ì„¸íŠ¸ì´ë‹¤.

50ë²ˆì§¸ ì—í¬í¬ë¶€í„°ëŠ” ì ìˆ˜ê°€ ê±°ì˜ í–¥ìƒí•˜ì§€ ì•Šê³ , 100ë²ˆì§¸ ì—í¬í¬ë¶€í„°ëŠ” ë‘ ì„¸íŠ¸ ê°„ì˜ ê²©ì°¨ê°€ ë²Œì–´ì§€ê³  ìˆë‹¤. ë”°ë¼ì„œ ë°± ë²ˆì§¸ ì—í¬í¬ê°€ ì ì ˆí•œ ë°˜ë³µ íšŸìˆ˜ë¡œ ë³´ì¸ë‹¤.

```python
sc = SGDClassifier(loss='log', max_iter=100, tol=None, random_state=42)
#SGDClassifierëŠ” ì¼ì • ì—í¬í¬ë™ì•ˆ ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ë©ˆì¶˜ë‹¤
#ê·¸ëŸ¬ë‚˜ tolë§¤ê°œë³€ìˆ˜ë¥¼ Noneìœ¼ë¡œ ì§€ì •í•˜ë©´ ìë™ìœ¼ë¡œ ë©ˆì¶”ì§€ ì•Šê³  ëê¹Œì§€ ê°„ë‹¤.
sc.fit(train_scaled, train_target)
print(sc.score(train_scaled, train_target)) #0.9579
print(sc.score(test_scaled, test_target)) #0.925
#ìµœì¢… ê²°ê³¼ê°€ ì¢‹ê²Œ ë‚˜ì˜´!
```

**04-2 í•µì‹¬ í‚¤ì›Œë“œ**

- **í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(stochastic gradient descent)**: í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ìƒ˜í”Œ í•˜ë‚˜ì”© êº¼ë‚´ ì†ì‹¤ í•¨ìˆ˜ì˜ ê²½ì‚¬ë¥¼ ë”°ë¼ ìµœì ì˜ ëª¨ë¸ì„ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜.
- ì†ì‹¤í•¨ìˆ˜: í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•ì´ ìµœì í™”í•  ëŒ€ìƒìœ¼ë¡œ, ì´ì¤‘ ë¶„ë¥˜ì—ëŠ” **ë¡œì§€ìŠ¤í‹± íšŒê·€ ì†ì‹¤í•¨ìˆ˜**ë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¤ì¤‘ ë¶„ë¥˜ì—ëŠ” í¬**ë¡œìŠ¤ì—”íŠ¸ë¡œí”¼ ì†ì‹¤í•¨ìˆ˜**ë¥¼ ì‚¬ìš©í•œë‹¤.
- **ì—í¬í¬(epoch)**: í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•ì—ì„œ ì „ì²´ ìƒ˜í”Œì„ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” í•œ ë²ˆ ë°˜ë³µì„ ì˜ë¯¸í•œë‹¤.

**04-2 í•µì‹¬ íŒ¨í‚¤ì§€ì™€ í•¨ìˆ˜**

- scikit-learn
    - **`SGDClassifier`**: í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‚¬ìš©í•œ ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤.
        - `loss` ë§¤ê°œë³€ìˆ˜ëŠ” ìµœì í™”í•  ì†ì‹¤ í•¨ìˆ˜ë¥¼ íƒí•œë‹¤.
        - `penalty` ë§¤ê°œë³€ìˆ˜ëŠ” ê·œì œì˜ ì¢…ë¥˜ë¥¼ ì§€ì •í•œë‹¤.
        - `max_iter` ë§¤ê°œë³€ìˆ˜ëŠ” ì—í¬í¬ íšŸìˆ˜ë¥¼ ì§€ì •í•œë‹¤.
        - `tol` ë§¤ê°œë³€ìˆ˜ëŠ” ë°˜ë³µì„ ë©ˆì¶œ ì¡°ê±´ì´ë‹¤.
    - `SGDRegressor`: í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‚¬ìš©í•œ íšŒê·€ ëª¨ë¸ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤

<br>