---
title: "[ML] í˜¼ê³µë¨¸ë‹ 6í¸ ë”¥ëŸ¬ë‹ ê¸°ì´ˆ ì¼€ë¼ìŠ¤(keras), TensorFlow"
excerpt: "ì—¬ëŸ¬ ì¢…ë¥˜ì˜ íŠ¸ë¦¬ ì•Œê³ ë¦¬ì¦˜ë“¤ê³¼ ì•ˆì •ì„±ì„ ë†’ì´ëŠ” êµì°¨ê²€ì¦, ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•„ì£¼ëŠ” ê·¸ë¦¬ë“œì„œì¹˜ì— ëŒ€í•´ ì•Œì•„ë³´ì"
toc: true
toc_label: "ëª©ì°¨"
toc_sticky: true

tags: [Deep Learning, TensorFlow, keras]

published: true

categories:
  - DL

date: 2022-12-06 01:40:00
last_modified_at: 2022-12-06 01:40:00
---

<br>

<div class="notice--primary" markdown="1">
ğŸ’¡ â€˜í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë”¥ëŸ¬ë‹(ë°•í•´ì„  ì €)â€™ ì±…ì„ ì½ê³  ê³µë¶€í•œ ë‚´ìš©ì„ ìš”ì•½í•œ í˜ì´ì§€ì…ë‹ˆë‹¤.<br>
ì±…ì— ë‚˜ì˜¤ëŠ” ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì“°ì§€ ì•Šê³ , ì½”ë“œì™€ íŒŒë¼ë¯¸í„°ë¥¼ ë³€í˜•í•˜ê³  ì¡°ì •í•´ê°€ë©° ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ë©° ê³µë¶€í–ˆìŠµë‹ˆë‹¤.
</div>

<br>

## 07 ë”¥ëŸ¬ë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤

---

### **07-1 ì¸ê³µ ì‹ ê²½ë§**

ì¸ê³µ ì‹ ê²½ë§ì„ ì„¤ëª…í•˜ê¸° ì•ì„œ íŒ¨ì…˜MNIST ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ë³´ì. ì´ ë°ì´í„°ëŠ” í…ì„œí”Œë¡œ(TensorFlow)ë¥¼ ì‚¬ìš©í•´ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.

```python
from tensorflow import keras
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
print(train_input.shape, train_target.shape)
#(60000, 28, 28) (60000,)
#ë°ì´í„°ëŠ” 28*28í¬ê¸°ì˜ 60,000ê°œ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. íƒ€ê¹ƒë„ 60,000ê°œì˜ ì›ì†Œê°€ ìˆëŠ” 1ì°¨ì› ë°°ì—´ì´ë‹¤.
```

```python
#10ê°œì˜ ìƒ˜í”Œì„ ê·¸ë¦¼ìœ¼ë¡œ ì¶œë ¥í•´ë³´ì
import matplotlib.pyplot as plt
fig, axs = plt.subplots(1,10,figsize=(10,10))
for i in range(10):
  axs[i].imshow(train_input[i], cmap='gray_r')
  axs[i].axis('off')
plt.show()
```

<img src="https://user-images.githubusercontent.com/115082062/205688149-82017145-cf42-4ca3-a3ac-394b4823088a.jpg">

ì´ í›ˆë ¨ ìƒ˜í”Œì€ 60,000ê°œë‚˜ ë˜ê¸° ë•Œë¬¸ì— ì „ì²´ ë°ì´í„°ë¥¼ í•œêº¼ë²ˆì— ì“°ëŠ” ê²ƒë³´ë‹¤ í•˜ë‚˜ì”© êº¼ë‚´ì„œ í›ˆë ¨í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì´ë‹¤. ì´ëŸ´ ë•Œ ìœ ìš©í•œ ê²ƒì´ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•ì´ë‹¤. `SGDClassifier`ë¥¼ ì‚¬ìš©í•  ë• ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ í•´ì¤˜ì•¼ í–ˆë‹¤. íŒ¨ì…˜MNIST ë°ì´í„°ëŠ” ê° í”½ì…€ì´ 0~255ì˜ ì •ìˆ«ê°’ì„ ê°€ì§€ë¯€ë¡œ ì´ë¥¼ 255ë¡œ ë‚˜ëˆ„ì–´ 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì •ê·œí™”í•˜ê³  1ì°¨ì› ë°°ì—´ë¡œ í¼ì³ì•¼ í•œë‹¤.

```python
train_scaled = train_input/255.0
train_scaled = train_scaled.reshape(-1, 28*28)
```

```python
import numpy as np
#êµì°¨ê²€ì¦ìœ¼ë¡œ ì„±ëŠ¥ í™•ì¸
from sklearn.model_selection import cross_validate
from sklearn.linear_model import SGDClassifier
sc = SGDClassifier(loss='log', max_iter=5, random_state=42)
scores = cross_validate(sc, train_scaled, train_target, n_jobs=-1)
print(np.mean(scores['test_score'])) #0.81956
```

ê²€ì¦ ì ìˆ˜ê°€ ì© ë§Œì¡±ìŠ¤ëŸ½ì§„ ì•Šë‹¤.

ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ ì›ë¦¬ì´ë©´ì„œ ë™ì‹œì— ë” ì§ˆë†’ì€ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ë°”ë¡œ **ì¸ê³µ ì‹ ê²½ë§(artificial neural network)** ì´ë‹¤.

<img src="https://user-images.githubusercontent.com/115082062/205688282-5cbb2dbe-feac-410e-b0d7-dff8e898e64e.png">

ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œëŠ” êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•´ ëª¨ë¸ì„ í‰ê°€í–ˆì§€ë§Œ, ì¸ê³µ ì‹ ê²½ë§ì—ì„œëŠ” êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê²€ì¦ ì„¸íŠ¸ë¥¼ ë³„ë„ë¡œ ëœì–´ë‚´ì–´ ì‚¬ìš©í•œë‹¤. ì´ë ‡ê²Œ í•˜ëŠ” ì´ìœ ëŠ” ì‹œê°„ì„ ëœê¸° ìœ„í•¨ê³¼ ë”¥ëŸ¬ë‹ ë¶„ì•¼ì˜ ë°ì´í„°ì…‹ì€ ì¶©ë¶„íˆ í¬ê¸°ì— ê²€ì¦ ì ìˆ˜ê°€ ì•ˆì •ì ì´ê¸° ë•Œë¬¸ì´ë‹¤.

```python
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
train_scaled, val_scaled, train_target, val_target =train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)
```

ì¼€ë¼ìŠ¤ì˜ `Dense` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ **ë°€ì§‘ì¸µ(dense layer)** ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤.

```python
dense = keras.layers.Dense(10, activation='softmax', input_shape=(784,))
#ì²«ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ì—ëŠ” ë‰´ëŸ° ê°œìˆ˜ë¥¼ ì§€ì •í•œë‹¤.
#activationë§¤ê°œë³€ìˆ˜ëŠ” ë‰´ëŸ°ì—ì„œ ì¶œë ¥ë˜ëŠ” ê°’ì„ í™•ë¥ ë¡œ ë°”ê¾¸ê¸° ìœ„í•œ í•¨ìˆ˜ë¥¼ ì…ë ¥í•œë‹¤.
#2ì§„ë¶„ë¥˜ë¼ë©´ sigmoidë¥¼ ì“°ê³  ë‹¤ì¤‘ë¶„ë¥˜ë¼ë©´ softmaxë¥¼ ì“´ë‹¤.
model=keras.Sequential(dense)

#ì¼€ë¼ìŠ¤ì—ì„œ í›ˆë ¨í•˜ê¸° ì „ ì„¤ì •ë‹¨ê³„
model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')
#lossë§¤ê°œë³€ìˆ˜ì— ì†ì‹¤í•¨ìˆ˜ì˜ ì¢…ë¥˜ë¥¼ ì…ë ¥.
#metricsë§¤ê°œë³€ìˆ˜ì— accuracyë¥¼ ì…ë ¥í•˜ì—¬ ì •í™•ë„ ì§€í‘œë¥¼ ê°™ì´ ì¶œë ¥
```

ì´ì§„ë¶„ë¥˜ì—ì„  ì†ì‹¤í•¨ìˆ˜ë¥¼ `binary_crossentropy`ë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¤ì¤‘ë¶„ë¥˜ì—ì„  ì†â€™`categorial_crossentropy`ë¥¼ ì‚¬ìš©í•œë‹¤. ì´ ë•Œ ì •ìˆ˜ë¡œ ëœ íƒ€ê¹ƒê°’ì„ ì›-í•« ì¸ì½”ë”©ìœ¼ë¡œ ë°”ê¾¸ì§€ ì•Šê³  ë°”ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ **`sparse_categorial_crossentropy`**ì´ë‹¤.

```python
model.fit(train_scaled, train_target, epochs=5)
#ê²°ê³¼ê°’
Epoch 1/5
1500/1500 [==============================] - 3s 1ms/step - loss: 0.6051 - accuracy: 0.7949
Epoch 2/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4789 - accuracy: 0.8395
Epoch 3/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4555 - accuracy: 0.8465
Epoch 4/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4460 - accuracy: 0.8521
Epoch 5/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4377 - accuracy: 0.8549
<keras.callbacks.History at 0x7f2d68606590>
#í›ˆë ¨ì„¸íŠ¸ì˜ ì •í™•ë„ëŠ” 0.8549

model.evaluate(val_scaled, val_target)
#ê²°ê³¼ê°’
375/375 [==============================] - 1s 1ms/step - loss: 0.4554 - accuracy: 0.8469
[0.45541203022003174, 0.846916675567627]
#ê²€ì¦ì„¸íŠ¸ì˜ ì •í™•ë„ëŠ” 0.8359
```

**07-1 í•µì‹¬ í‚¤ì›Œë“œ**

- **ì¸ê³µ ì‹ ê²½ë§**: ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë‹¤ë£¨ê¸° ì–´ë ¤ì› ë˜ ì´ë¯¸ì§€, ìŒì„±, í…ìŠ¤íŠ¸ ë¶„ì•¼ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•œë‹¤. ì¢…ì¢… ë”¥ëŸ¬ë‹ìœ¼ë¡œ ë¶ˆë¦°ë‹¤.
- í…ì„œí”Œë¡œ: êµ¬ê¸€ì´ ë§Œë“  ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **ë°€ì§‘ì¸µ**: ê°€ì¥ ê°„ë‹¨í•œ ì¸ê³µ ì‹ ê²½ë§ì˜ ì¸µ. ë‰´ëŸ°ë“¤ì´ ëª¨ë‘ ì—°ê²°ë˜ì–´ ìˆê¸°ì— ì™„ì „ ì—°ê²° ì¸µì´ë¼ê³ ë„ ë¶ˆë¦°ë‹¤.
- **ì›-í•« ì¸ì½”ë”©**: ì •ìˆ«ê°’ì„ ë°°ì—´ì—ì„œ í•´ë‹¹ ì •ìˆ˜ ìœ„ì¹˜ì˜ ì›ì†Œë§Œ 1ì´ê³  ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ëª¨ë‘ ë³€í™˜í•˜ëŠ” ê²ƒ. `sparse_categorical_entropy` ì†ì‹¤í•¨ìˆ˜ëŠ” ì´ëŸ° ë³€í™˜ì„ ìˆ˜í–‰í•  í•„ìš”ê°€ ì—†ë‹¤.

**07-1 í•µì‹¬ íŒ¨í‚¤ì§€ì™€ í•¨ìˆ˜**

- TensorFlow
    - **`Dense`**: ì‹ ê²½ë§ì—ì„œ ê°€ì¥ ê¸°ë³¸ ì¸µì¸ **ë°€ì§‘ì¸µ**ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤
        - **`activation`**ë§¤ê°œë³€ìˆ˜ì— ì‚¬ìš©í•  í™œì„±í™” í•¨ìˆ˜ë¥¼ ì§€ì •. ë‹¤ì¤‘ë¶„ë¥˜ëŠ” **`softmax**` í•¨ìˆ˜ ì§€ì •
    - `Sequential`: ì‹ ê²½ë§ ëª¨ë¸ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤
    - **`compile()`**: ëª¨ë¸ ê°ì²´ë¥¼ ë§Œë“  í›„ í›ˆë ¨í•˜ê¸° ì „ì— ì‚¬ìš©í•  ì†ì‹¤í•¨ìˆ˜ì™€ ì¸¡ì • ì§€í‘œë¥¼ ì§€ì •í•˜ëŠ” ë©”ì„œë“œ
        - **`loss`**ë§¤ê°œë³€ìˆ˜ì— ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì§€ì •. ì´ì§„ë¶„ë¥˜ë©´ `binary_crossentropy`, ë‹¤ì¤‘ë¶„ë¥˜ë©´ `categorical_crossentropy`, í´ë˜ìŠ¤ ë ˆì´ë¸”ì´ ì •ìˆ˜ì¼ ê²½ìš° **`sparse_categorical_crossentropy`**ë¥¼ ì§€ì •
        - `metrics`ë§¤ê°œë³€ìˆ˜ì— í›ˆë ¨ ê³¼ì •ì—ì„œ ì¸¡ì •í•˜ê³ í”ˆ ì§€í‘œ ì§€ì •

---

<br>

### **07-2 ì‹¬ì¸µ ì‹ ê²½ë§**

ì´ë²ˆì—” ì‹ ê²½ë§ì— ì¸µì„ ì¶”ê°€í•´ë³´ì.

```python
rom tensorflow import keras
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()

from sklearn.model_selection import train_test_split
train_scaled = train_input/255.0
train_scaled = train_scaled.reshape(-1,28*28)
train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)
```

ì•ì„  ì ˆì—ì„œ ë§Œë“  ê²ƒê³¼ì˜ ì°¨ì´ëŠ” ì…ë ¥ì¸µê³¼ ì¶œë ¥ì¸µ ì‚¬ì´ì— **ì€ë‹‰ì¸µ(hidden layer)** ì„ ì¶”ê°€í•œ ê²ƒì´ë‹¤. ì€ë‹‰ì¸µì—ë„ í™œì„±í™”í•¨ìˆ˜ë¥¼ ì ìš©í•˜ëŠ”ë°, ëŒ€í‘œì ìœ¼ë¡œ **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜**ë‚˜ `ë ë£¨(ReLU)`í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.

```python
#ì€ë‹‰ì¸µ. sigmoidí•¨ìˆ˜ë¥¼ ì¨ì„œ zê°’ì„ 0ê³¼ 1ì‚¬ì´ë¡œ ì••ì¶•
#ì€ë‹‰ì¸µì˜ ë‰´ëŸ° ê°œìˆ˜ëŠ” ì„ì˜ë¡œ ì„¤ì •í•˜ëŠ”ë°, ì¶œë ¥ì¸µì˜ ë‰´ëŸ°ë³´ë‹¨ ë§ì•„ì•¼ í•œë‹¤.
dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))
#ì¶œë ¥ì¸µ
dense2 = keras.layers.Dense(10, activation='softmax')
```

```python
model = keras.Sequential([dense1, dense2])
model.summary()
#summaryê°’
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 100)               78500     
                                                                 
 dense_1 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
```

`summary()`ë©”ì„œë“œë¥¼ ì¶œë ¥í•˜ë©´ ìœ„ì²˜ëŸ¼ ìœ ìš©í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ë§¨ ì²« ì¤„ì— ëª¨ë¸ì˜ ì´ë¦„ì´ ë‚˜ì˜¤ê³ , ê·¸ ë‹¤ìŒì— ì´ ëª¨ë¸ì˜ ì¸µì´ ìˆœì„œë¡œ ë‚˜ì—´ëœë‹¤. ì¸µë§ˆë‹¤ ì¸µ ì´ë¦„, í´ë˜ìŠ¤, ì¶œë ¥ í¬ê¸°, ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°œìˆ˜ê°€ ì¶œë ¥ëœë‹¤. ì´ ëª¨ë¸ì˜ ê²½ìš° í”½ì…€784ê°œê°€ ì…ë ¥ì¸µì˜ ë‰´ëŸ° ìˆ˜ê³ , ì´ê²ƒì´ ì€ë‹‰ì¸µ 100ê°œ ë‰´ëŸ°ê³¼ ê³±í•´ì§€ë¯€ë¡œ 78,400ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤. ê±°ê¸°ì— ë‰´ëŸ°ë§ˆë‹¤ 1ê°œì˜ ì ˆí¸ì´ ìˆìœ¼ë‹ˆ ì´ 78,500ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤. ê·¸ë¦¬ê³ ì„  ë‘ë²ˆì§¸ ì¸µì—ì„œ 100ê°œì˜ ì€ë‹‰ì¸µ ë‰´ëŸ°ê³¼ 10ê°œì˜ ì¶œë ¥ì¸µ ë‰´ëŸ°ì´ ì—°ê²°ë˜ë‹ˆ 1,000+10(ì ˆí¸), ì´ 1,010ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤. ì´ë“¤ì„ í•©í•˜ë©´ summaryì— ë‚˜ì˜¨ 79,510 ê°’ì´ ë„ì¶œëœë‹¤.

ì¸µì„ ì¶”ê°€í•˜ëŠ” ë‹¤ë¥¸ ë°©ë²•ë„ ìˆë‹¤. ë°”ë¡œ ë‹¤ìŒì²˜ëŸ¼ `Sequential` í´ë˜ìŠ¤ ìƒì„±ì ì•ˆì— ë°”ë¡œ Denseí´ë˜ìŠ¤ì˜ ê°ì²´ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì´ë‹¤.

```python
model = keras.Sequential([keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'), keras.layers.Dense(10, activation='softmax', name='output')], name='íŒ¨ì…˜ MNIST ëª¨ë¸')
```

í•˜ì§€ë§Œ ìœ„ ë°©ë²•ì€ ì¸µì„ ì—¬ëŸ¬ê°œ ì¶”ê°€í•˜ë©´ Sequential ìƒì„±ìê°€ ë„ˆë¬´ ê¸¸ì–´ì§„ë‹¤. ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì€ `add()`ë©”ì„œë“œì´ë‹¤. ì´ ë°©ë²•ì€ í•œëˆˆì— ì¶”ê°€ë˜ëŠ” ì¸µì„ ë³¼ ìˆ˜ ìˆê³  í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹œ ë™ì ìœ¼ë¡œ ì¸µì„ ì„ íƒí•˜ì—¬ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤.

```python
model = keras.Sequential()
model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))
model.add(keras.layers.Dense(10, activation='softmax'))
```

<img src="https://user-images.githubusercontent.com/115082062/205688607-92b871a5-7ca2-4047-a99e-69cca49cc8d1.png">

**ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜**ëŠ” ì–‘ëì—ì„œ ê·¸ë˜í”„ê°€ ëˆ„ì›Œìˆê¸°ì— ì˜¬ë°”ë¥¸ ì¶œë ¥ì„ ë§Œë“œëŠ”ë° ì‹ ì†í•˜ê²Œ ëŒ€ì‘í•˜ì§€ ëª»í•œë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤. ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ í™œì„±í™”í•¨ìˆ˜ê°€ **ë ë£¨(ReLU)** í•¨ìˆ˜ì´ë‹¤.

<img src="https://user-images.githubusercontent.com/115082062/205688748-6d59b993-82b5-4b06-bb28-c69b8217ccbf.png">

ë ë£¨ í•¨ìˆ˜ëŠ” max(0,z)ì™€ ê°™ì´ ì“¸ ìˆ˜ ìˆë‹¤. ì–‘ìˆ˜ì¼ ê²½ìš°ì—” í™œì„±í™” í•¨ìˆ˜ê°€ ì—†ëŠ” ì–‘ ê°’ì„ ê·¸ëƒ¥ í†µê³¼ì‹œí‚¤ê³  ìŒìˆ˜ì¸ ê²½ìš°ì—” 0ì„ ì¶œë ¥í•œë‹¤. ë ë£¨ í•¨ìˆ˜ëŠ” íŠ¹íˆ ì´ë¯¸ì§€ ì²˜ë¦¬ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ë‹¤.

```python
model= keras.Sequential()
model.add(keras.layers.Flatten(input_shape=(28,28)))
#Flattení´ë˜ìŠ¤ëŠ” ì…ë ¥ì°¨ì›ì„ ì¼ë ¬ë¡œ í¼ì¹˜ëŠ” ì—­í• 
model.add(keras.layers.Dense(100,activation='relu')) #relu
model.add(keras.layers.Dense(10, activation='softmax'))
```

```python
#ëª¨ë¸ í›ˆë ¨
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
train_scaled = train_input/255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)

model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')
model.fit(train_scaled, train_target, epochs=5)

#ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œë³´ë‹¤ ì„±ëŠ¥ì´ ì¡°ê¸ˆ í–¥ìƒ
```

**07-2 í•µì‹¬ í‚¤ì›Œë“œ**

- **ì‹¬ì¸µ ì‹ ê²½ë§**: 2ê°œ ì´ìƒì˜ ì¸µì„ í¬í•¨í•œ ì‹ ê²½ë§
- **ë ë£¨ í•¨ìˆ˜**: ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì˜ ì€ë‹‰ì¸µì— ë§ì´ ì‚¬ìš©í•˜ëŠ” í™œì„±í™”í•¨ìˆ˜
- **ì˜µí‹°ë§ˆì´ì €**: ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ì™€ ì ˆí¸ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜. ì¼€ë¼ìŠ¤ì—ëŠ” ë‹¤ì–‘í•œ ê²½ì‚¬ í•˜ê°•ë²• ì•Œê³ ë¦¬ì¦˜ì´ ì˜µí‹°ë§ˆì´ì €ë¡œ êµ¬í˜„ë˜ì–´ ìˆë‹¤.

**07-2 í•µì‹¬ íŒ¨í‚¤ì§€ì™€ í•¨ìˆ˜**

- TensorFlow
    - **`add()`**: ì¼€ë¼ìŠ¤ ëª¨ë¸ì— ì¸µì„ ì¶”ê°€í•˜ëŠ” ë©”ì„œë“œ
    - `summary()`: ì¼€ë¼ìŠ¤ ëª¨ë¸ì˜ ì •ë³´ë¥¼ ì¶œë ¥í•˜ëŠ” ë©”ì„œë“œ
    - `SGD`: ê¸°ë³¸ ê²½ì‚¬ í•˜ê°•ë²• ì˜µí‹°ë§ˆì´ì € í´ë˜ìŠ¤
    - `Adagrad`: Adagrad ì˜µí‹°ë§ˆì´ì € í´ë˜ìŠ¤
    - `RMSprop`: RMSprop ì˜µí‹°ë§ˆì´ì € í´ë˜ìŠ¤

---

<br>

### 07-3 ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨

`History` ê°ì²´ì—ëŠ” í›ˆë ¨ ê³¼ì •ì—ì„œ ê³„ì‚°í•œ ì§€í‘œ, ì¦‰ ì†ì‹¤ê³¼ ì •í™•ë„ ê°’ì´ ì €ì¥ë˜ì–´ ìˆë‹¤. ì´ ê°’ì„ ì‚¬ìš©í•˜ë©´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆë‹¤.

```python
#ë°ì´í„° ì¤€ë¹„
from tensorflow import keras
from sklearn.model_selection import train_test_split
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
train_scaled = train_input/255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)
```

```python
def model_fn(a_layer=None):
  model = keras.Sequential()
  model.add(keras.layers.Flatten(input_shape=(28,28)))
  model.add(keras.layers.Dense(100, activation='relu'))
  if a_layer: #ì¸µì„ ì¶”ê°€í•˜ë©´ ì€ë‹‰ì¸µ ë’¤ì— ë˜ í•˜ë‚˜ì˜ ì¸µì„ ì¶”ê°€í•˜ëŠ” ifë¬¸
    model.add(a_layer)    
  model.add(keras.layers.Dense(10, activation='softmax'))
  return model

#fit()ë©”ì„œë“œì˜ ê²°ê³¼ë¥¼ historyë³€ìˆ˜ì— ë‹´ê¸°
model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')
history = model.fit(train_scaled, train_target, epochs=5, verbose=0)
print(history.history.keys())
#ê²°ê³¼ê°’
dict_keys(['loss', 'accuracy'])
```

history ê°ì²´ì—ëŠ” ì†ì‹¤ê³¼ ì •í™•ë„ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ê°€ ìˆë‹¤. ì´ëŠ” ê° ì—í¬í¬ë§ˆë‹¤ ê³„ì‚°í•œ ê°’ì´ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´ëœ ë‹¨ìˆœí•œ ë¦¬ìŠ¤íŠ¸ë‹¤. ë§·í”Œë¡¯ë¦½ì„ ì‚¬ìš©í•´ ì‰½ê²Œ ê·¸ë˜í”„ë¡œ ê·¸ë¦´ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

```python
import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()
plt.plot(history.history['accuracy'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()
```

<img src="https://user-images.githubusercontent.com/115082062/205688929-8462ac46-f95f-4422-8bc0-348f9247052e.jpg">

ì—í¬í¬ì— ë”°ë¥¸ ê³¼ëŒ€/ê³¼ì†Œì í•©ì„ ì˜ íŒŒì•…í•˜ë ¤ë©´ í›ˆë ¨ì„¸íŠ¸ì˜ ì†ì‹¤ë§Œ ê·¸ë ¤ì„œëŠ” ì•ˆ ë˜ê³  **ê²€ì¦ ì„¸íŠ¸ì˜ ì†ì‹¤** ì—­ì‹œë„ ê·¸ë ¤ì•¼ í•œë‹¤. ì´ë¥¼ ìœ„í•´ì„  `fit()`ë©”ì„œë“œì— `validation_data`ë§¤ê°œë³€ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ë©´ ëœë‹¤.

```python
model = model_fn()
model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')
history = model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target))
print(history.history.keys())
#ê²°ê³¼ê°’
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
#ê²€ì¦ì„¸íŠ¸ì— ëŒ€í•œ ì†ì‹¤ê³¼ ì •í™•ë„ë„ ì €ì¥ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
```

```python
plt.plot(history.history['val_loss'])
plt.plot(history.history['loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['val', 'train'])
plt.show()
```

<img src="https://user-images.githubusercontent.com/115082062/205689072-c2db5df5-9644-4663-8261-049dc5296fa6.jpg">

ë…¸ë€ìƒ‰ì´ í›ˆë ¨ì„¸íŠ¸ì˜ ì†ì‹¤, íŒŒë€ìƒ‰ì´ ê²€ì¦ì„¸íŠ¸ì˜ ì†ì‹¤ì´ë‹¤

ì´ˆê¸°ì— ê²€ì¦ ì†ì‹¤ì´ ê°ì†Œí•˜ë‹¤ê°€ ê¸ˆë°© ë‹¤ì‹œ ìƒìŠ¹í•˜ê¸° ì‹œì‘í•œë‹¤. ê²€ì¦ì†ì‹¤ì´ ë‹¤ì‹œ ìƒìŠ¹í•˜ëŠ” ì‹œì ì„ ê°€ëŠ¥í•œ ë’¤ë¡œ ëŠ¦ì¶”ë©´ í›¨ì”¬ ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ ê²ƒì´ë‹¤.

**ë“œë¡­ì•„ì›ƒ(dropout)** ì€ í›ˆë ¨ ê³¼ì •ì—ì„œ ì¸µì— ìˆëŠ” ì¼ë¶€ ë‰´ëŸ°ì„ ëœë¤í•˜ê²Œ êº¼ì„œ ì¶œë ¥ì„ 0ìœ¼ë¡œ ë§Œë“¤ê³ , ê³¼ëŒ€ì í•©ì„ ë§‰ëŠ” ë°©ë²•ì´ë‹¤. ì¼€ë¼ìŠ¤ì—ì„œëŠ” ë“œë¡­ì•„ì›ƒì„ `keras.layers` íŒ¨í‚¤ì§€ ì•„ë˜ `Dropout` í´ë˜ìŠ¤ë¡œ ì œê³µí•œë‹¤.

```python
#ì•ì„œ ì •ì˜í•œ model_fní•¨ìˆ˜ì— ë“œë¡­ì•„ì›ƒ ì¸µì„ ë„£ì–´ë³´ì
model = model_fn(keras.layers.Dropout(0.3))
model.summary()
Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_5 (Flatten)         (None, 784)               0         
                                                                 
 dense_14 (Dense)            (None, 100)               78500     
                                                                 
 dropout (Dropout)           (None, 100)               0         
                                                                 
 dense_15 (Dense)            (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
```

ì€ë‹‰ì¸µ ë’¤ì— ì¶”ê°€ëœ  Dropoutì¸µì„ ë³´ë©´ í›ˆë ¨ë˜ëŠ” ëª¨ë¸ íŒŒë¼ë¯¸í„°ê°€ ì—†ë‹¤. ì¼ë¶€ ë‰´ëŸ°ì˜ ì¶œë ¥ì„ 0ìœ¼ë¡œ ë§Œë“¤ì§€ë§Œ ì „ì²´ ì¶œë ¥ ë°°ì—´ì˜ í¬ê¸°ë¥¼ ë°”ê¾¸ì§€ëŠ” ì•ŠëŠ”ë‹¤. ë‹¹ì—°íˆ í›ˆë ¨ ì¢…ë£Œ í›„ í‰ê°€ë‚˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ë•ŒëŠ” ë“œë¡­ì•„ì›ƒì´ ì ìš©ë˜ë©´ ì•ˆ ëœë‹¤. ë˜‘ë˜‘í•˜ê²Œë„ Dropoutí´ë˜ìŠ¤ëŠ” í‰ê°€/ì˜ˆì¸¡ ì‹œì— ìë™ìœ¼ë¡œ ë“œë¡­ì•„ì›ƒì„ ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ì „ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ í›ˆë ¨ì†ì‹¤ê³¼ ê²€ì¦ì†ì‹¤ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë³´ì

```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
history = model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

<img src="https://user-images.githubusercontent.com/115082062/205689234-086bc83b-1238-4279-847c-ec07b475198f.jpg">

ê³¼ëŒ€ì í•©ì´ í™•ì‹¤íˆ ì¤„ì–´ë“  ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

ì´ì œ ì´ ëª¨ë¸ì˜ í›ˆë ¨ëœ íŒŒë¼ë¯¸í„°ë¥¼ ì €ì¥í•´ë³´ì.

```python
model = model_fn(keras.layers.Dropout(0.3))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
history = model.fit(train_scaled, train_target, epochs=10, verbose=0, validation_data=(val_scaled, val_target))
model.save_weights('model-weights.h5') #í›ˆë ¨ íŒŒë¼ë¯¸í„°ë¥¼ ì €ì¥í•˜ëŠ” ë©”ì„œë“œ
model.save('model-whole.h5') #ëª¨ë¸ êµ¬ì¡°ì™€ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ í•¨ê»˜ ì €ì¥í•˜ëŠ” ë©”ì„œë“œ
```

**ì½œë°±(callback)** ì€ í›ˆë ¨ ê³¼ì • ì¤‘ê°„ì— ì–´ë–¤ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê°ì²´ë¡œ `keras.callbacks` íŒ¨í‚¤ì§€ ì•„ë˜ì— ìˆëŠ” í´ë˜ìŠ¤ë“¤ì´ë‹¤. `fit()`ë©”ì„œë“œì˜ `callbacks` ë§¤ê°œë³€ìˆ˜ì— ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•˜ì—¬ ì‚¬ìš©í•œë‹¤.

```python
model = model_fn(keras.layers.Dropout(0.3))
model.compile(optimizer='adam', loss='aparse_categorical_crossentropy', metrics='accuracy')
checkpoint_cb = keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only=True)
#save_best_onlyë§¤ê°œë³€ìˆ˜ë¥¼ Trueë¡œ ì„¤ì •í•˜ì—¬ ê°€ì¥ ë‚®ì€ ê²€ì¦ ì ìˆ˜ë¥¼ ë§Œë“œëŠ” ëª¨ë¸ì„ ì €ì¥í•œë‹¤.
history.model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb])
#checkpoint_cbë¥¼ ë§Œë“  í›„ callbacksë§¤ê°œë³€ìˆ˜ì— ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ì „ë‹¬í•´ì¤€ë‹¤.
#ëª¨ë¸ì´ í›ˆë ¨í•œ í›„ best-model.h5ì— ìµœìƒì˜ ê²€ì¦ ì ìˆ˜ë¥¼ ë‚¸ ëª¨ë¸ì´ ì €ì¥ëœë‹¤.
```

ë” ë‚˜ì•„ê°€ ê³¼ëŒ€ì í•©ì´ ì‹œì‘ë˜ê¸° ì „ì— ë¯¸ë¦¬ í›ˆë ¨ì„ ì¤‘ì§€í•˜ë„ë¡ í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ **ì¡°ê¸° ì¢…ë£Œ(early stopping)** ë¼ê³  ë¶€ë¥¸ë‹¤. ì¼€ë¼ìŠ¤ì—ì„œëŠ” ì¡°ê¸° ì¢…ë£Œë¥¼ ìœ„í•œ `EarlyStopping` ì½œë°±ì„ ì œê³µí•œë‹¤.

```python
model = model_fn(keras.layers.Dropout(0.3))
model.compile(optimizer='adam', loss='aparse_categorical_crossentropy', metrics='accuracy')
checkpoint_cb = keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)
#patienceë¥¼ 2ë¡œ ì§€ì •í•˜ë©´ 2ë²ˆ ì—°ì† ê²€ì¦ ì ìˆ˜ í–¥ìƒì´ ì—†ì„ ì‹œ í›ˆë ¨ ì¤‘ì§€
#retore_best_weightsë¥¼ Trueë¡œ ì§€ì •í•˜ë©´ ê°€ì¥ ë‚®ì€ ê²€ì¦ ì†ì‹¤ì„ ë‚¸ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¡œ ë˜ëŒë¦¼
history.model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb])

#ëª‡ ì—í¬í¬ë§Œì— í›ˆë ¨ì„ ì¤‘ì§€í–ˆëŠ”ì§€
print(early_stopping_cb.stopped_epoch) 
```

**07-3 í•µì‹¬ í‚¤ì›Œë“œ**

- **ë“œë¡­ì•„ì›ƒ**: ì€ë‹‰ì¸µì— ìˆëŠ” ë‰´ëŸ°ì˜ ì¶œë ¥ì„ ëœë¤í•˜ê²Œ êº¼ì„œ ê³¼ëŒ€ì í•©ì„ ë§‰ëŠ” ê¸°ë²•. ë“œë¡­ì•„ì›ƒì€ í›ˆë ¨ ì¤‘ì— ì ìš©ë˜ë©° í‰ê°€ë‚˜ ì˜ˆì¸¡ì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ.
- **ì½œë°±**: ì¼€ë¼ìŠ¤ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë„ì¤‘ ì–´ë–¤ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë„êµ¬
- **ì¡°ê¸° ì¢…ë£Œ**: ê²€ì¦ì ìˆ˜ê°€ ë” ì´ìƒ ê°ì†Œí•˜ì§€ ì•Šê³  ìƒìŠ¹í•˜ì—¬ ê³¼ëŒ€ì í•©ì´ ì¼ì–´ë‚˜ë©´ í›ˆë ¨ì„ ì¤‘ì§€í•˜ëŠ” ê¸°ë²•

**07-3 í•µì‹¬ íŒ¨í‚¤ì§€ì™€ í•¨ìˆ˜**

- TensorFlow
    - **`Dropout`**
        - ì²«ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ë¡œ ë“œë¡­ì•„ì›ƒ í•  ë¹„ìœ¨ì„ ì§€ì •
    - `save_weights()`: ëª¨ë“  ì¸µì˜ ê°€ì¤‘ì¹˜ì™€ ì ˆí¸ì„ íŒŒì¼ì— ì €ì¥
    - `load_weights()`: ëª¨ë“  ì¸µì˜ ê°€ì¤‘ì¹˜ì™€ ì ˆí¸ì„ íŒŒì¼ì— ì½ìŒ
    - `save()`: ëª¨ë¸ êµ¬ì¡°ì™€ ëª¨ë“  ê°€ì¤‘ì¹˜ì™€ ì ˆí¸ì„ íŒŒì¼ì— ì €ì¥
    - **`ModelCheckpoint`**:  ì¼€ë¼ìŠ¤ ëª¨ë¸ê³¼ ê°€ì¤‘ì¹˜ë¥¼ ì¼ì • ê°„ê²©ìœ¼ë¡œ ì €ì¥
        - ì²«ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ì— ì €ì¥í•  íŒŒì¼ ì§€ì •
        - `monitor`ë§¤ê°œë³€ìˆ˜ì— ëª¨ë‹ˆí„°ë§í•  ì§€í‘œ ì§€ì •
        - **`save_best_only`**ë§¤ê°œë³€ìˆ˜ë¥¼ **True**ë¡œ ì§€ì •í•˜ë©´ ê°€ì¥ ë‚®ì€ ì ìˆ˜ë¥¼ ë§Œë“œëŠ” ëª¨ë¸ì„ ì €ì¥
    - **`EarlyStopping`**: ê´€ì‹¬ ì§€í‘œê°€ ë” ì´ìƒ í–¥ìƒí•˜ì§€ ì•Šìœ¼ë©´ í›ˆë ¨ ì¤‘ì§€
        - **`patience`**ë§¤ê°œë³€ìˆ˜ì— ëª¨ë¸ì´ ì§€ì†ê°€ëŠ¥í•œ ìµœëŒ€ ì—í¬í¬ íšŸìˆ˜ ì§€ì •
- Numpy
    - `argmax`: ë°°ì—´ì—ì„œ ì¶•ì„ ë”°ë¼ ìµœëŒ“ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜

<br>