---
title: "[DL] RNN, LSTM, GRUë¥¼ í™œìš©í•œ ë¯¸êµ­ ì—ë„ˆì§€ ì†Œë¹„ëŸ‰ ì˜ˆì¸¡"
excerpt: "ë¯¸êµ­ ì „ë ¥ ì—ë„ˆì§€ ì†Œë¹„ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ PyTorchì˜ RNN, LSTM, GRUë¡œ ì˜ˆì¸¡ ë° ë¹„êµí•´ë³´ì."
toc: true
toc_label: "ëª©ì°¨"
toc_sticky: true

tags: [Deep Learning, RNN, LSTM, GRU, ì‹œê³„ì—´, pytorch]

published: true

categories:
  - DL

date: 2023-02-15 21:00:00
last_modified_at: 2023-02-15 21:00:00
---


<br>

<div class="notice--primary" markdown="1">
ğŸ’¡ êµë‚´ í•™íšŒ NLP ë¶„ë°˜ì—ì„œ í•™ìŠµí•œ ë‚´ìš©ì„ ì •ë¦¬í•œ í¬ìŠ¤íŒ…ì…ë‹ˆë‹¤.
</div>

<br>

## 1. Installing Libaries



```python
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"{device}" " is available.")
```

    cpu is available.
    


```python
from google.colab import drive
drive.mount('/content/drive')
```

    Mounted at /content/drive
    

## 2. Loading Dataset, EDA

ë°ì´í„°ì…‹ì€ ë¯¸êµ­ ì—¬ëŸ¬ ì§€ì—­ì˜ ì „ë ¥ ì—ë„ˆì§€ ì†Œë¹„ëŸ‰ì„ ì‹œê³„ì—´ ë°ì´í„°ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤. ê·¸ ì¤‘ Duquesne(ë“€ì¼€ì¸ in íœì‹¤ë² ë‹ˆì•„)ì´ë¼ëŠ” ì§€ì—­ì˜ ë°ì´í„°ì…‹ì„ íƒí–ˆë‹¤. ë‹¨ìœ„ëŠ” ë©”ê°€ì™€íŠ¸(MW)ë¼ê³  í•œë‹¤.

ê´€ì¸¡ê¸°ê°„ì€ 2005ë…„ 1ì›” 1ì¼ ~ 2018ë…„ 8ì›” 3ì¼ì´ë‹¤.



```python
df = pd.read_csv('/content/drive/MyDrive/kubig/DUQ_hourly.csv')
```


```python
df.head()
```





  <div id="df-0d0e852e-238c-4411-9951-103752472a03">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Datetime</th>
      <th>DUQ_MW</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2005-12-31 01:00:00</td>
      <td>1458.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2005-12-31 02:00:00</td>
      <td>1377.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2005-12-31 03:00:00</td>
      <td>1351.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2005-12-31 04:00:00</td>
      <td>1336.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2005-12-31 05:00:00</td>
      <td>1356.0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-0d0e852e-238c-4411-9951-103752472a03')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-0d0e852e-238c-4411-9951-103752472a03 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-0d0e852e-238c-4411-9951-103752472a03');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
df.describe()
```





  <div id="df-765f245f-2dc2-4fff-9902-37c55e3c167b">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DUQ_MW</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>119068.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1658.820296</td>
    </tr>
    <tr>
      <th>std</th>
      <td>301.740640</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1014.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1444.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1630.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1819.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3054.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-765f245f-2dc2-4fff-9902-37c55e3c167b')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-765f245f-2dc2-4fff-9902-37c55e3c167b button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-765f245f-2dc2-4fff-9902-37c55e3c167b');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 119068 entries, 0 to 119067
    Data columns (total 2 columns):
     #   Column    Non-Null Count   Dtype  
    ---  ------    --------------   -----  
     0   Datetime  119068 non-null  object 
     1   DUQ_MW    119068 non-null  float64
    dtypes: float64(1), object(1)
    memory usage: 1.8+ MB
    


```python
import plotly.graph_objs as go
from plotly.offline import iplot

def plot_dataset(df, title):
    data = []
    
    value = go.Scatter(
        x=df.index,
        y=df.value,
        mode="lines",
        name="values",
        marker=dict(),
        text=df.index,
        line=dict(color="rgba(0,0,0, 0.3)"),
    )
    data.append(value)

    layout = dict(
        title=title,
        xaxis=dict(title="Date", ticklen=5, zeroline=False),
        yaxis=dict(title="Value", ticklen=5, zeroline=False),
    )

    fig = dict(data=data, layout=layout)
    iplot(fig)
    
```


```python
df = df.set_index(['Datetime'])
df = df.rename(columns={'DUQ_MW': 'value'})

df.index = pd.to_datetime(df.index)
if not df.index.is_monotonic:
    df = df.sort_index()
    
plot_dataset(df, title='Duquesne (DUQ) Region: estimated energy consumption in Megawatts (MW)')
```


<br>

## 2. Loading Dataset, EDA

ë°ì´í„°ì…‹ì€ ë¯¸êµ­ ì—¬ëŸ¬ ì§€ì—­ì˜ ì „ë ¥ ì—ë„ˆì§€ ì†Œë¹„ëŸ‰ì„ ì‹œê³„ì—´ ë°ì´í„°ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤. ê·¸ ì¤‘ Duquesne(ë“€ì¼€ì¸ in íœì‹¤ë² ë‹ˆì•„)ì´ë¼ëŠ” ì§€ì—­ì˜ ë°ì´í„°ì…‹ì„ íƒí–ˆë‹¤. ë‹¨ìœ„ëŠ” ë©”ê°€ì™€íŠ¸(MW)ë¼ê³  í•œë‹¤.

ê´€ì¸¡ê¸°ê°„ì€ 2005ë…„ 1ì›” 1ì¼ ~ 2018ë…„ 8ì›” 3ì¼ì´ë‹¤.



```python
df = pd.read_csv('/content/drive/MyDrive/kubig/DUQ_hourly.csv')
```


```python
df.head()
```





  <div id="df-0d0e852e-238c-4411-9951-103752472a03">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Datetime</th>
      <th>DUQ_MW</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2005-12-31 01:00:00</td>
      <td>1458.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2005-12-31 02:00:00</td>
      <td>1377.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2005-12-31 03:00:00</td>
      <td>1351.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2005-12-31 04:00:00</td>
      <td>1336.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2005-12-31 05:00:00</td>
      <td>1356.0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-0d0e852e-238c-4411-9951-103752472a03')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-0d0e852e-238c-4411-9951-103752472a03 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-0d0e852e-238c-4411-9951-103752472a03');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
df.describe()
```





  <div id="df-765f245f-2dc2-4fff-9902-37c55e3c167b">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DUQ_MW</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>119068.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1658.820296</td>
    </tr>
    <tr>
      <th>std</th>
      <td>301.740640</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1014.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1444.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1630.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1819.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3054.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-765f245f-2dc2-4fff-9902-37c55e3c167b')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-765f245f-2dc2-4fff-9902-37c55e3c167b button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-765f245f-2dc2-4fff-9902-37c55e3c167b');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 119068 entries, 0 to 119067
    Data columns (total 2 columns):
     #   Column    Non-Null Count   Dtype  
    ---  ------    --------------   -----  
     0   Datetime  119068 non-null  object 
     1   DUQ_MW    119068 non-null  float64
    dtypes: float64(1), object(1)
    memory usage: 1.8+ MB
    


```python
import plotly.graph_objs as go
from plotly.offline import iplot

def plot_dataset(df, title):
    data = []
    
    value = go.Scatter(
        x=df.index,
        y=df.value,
        mode="lines",
        name="values",
        marker=dict(),
        text=df.index,
        line=dict(color="rgba(0,0,0, 0.3)"),
    )
    data.append(value)

    layout = dict(
        title=title,
        xaxis=dict(title="Date", ticklen=5, zeroline=False),
        yaxis=dict(title="Value", ticklen=5, zeroline=False),
    )

    fig = dict(data=data, layout=layout)
    iplot(fig)
    
```


```python
df = df.set_index(['Datetime'])
df = df.rename(columns={'DUQ_MW': 'value'})

df.index = pd.to_datetime(df.index)
if not df.index.is_monotonic:
    df = df.sort_index()
    
plot_dataset(df, title='Duquesne (DUQ) Region: estimated energy consumption in Megawatts (MW)')
```

<br>

## 3. Generating time-lagged observations, date/time features

ë³¸ ë°ì´í„°ì…‹ì—ì„œëŠ” ì—ë„ˆì§€ ì†Œë¹„ëŸ‰ì„ ì œì™¸í•˜ê³ ëŠ” ë‹¤ë¥¸ predictorsê°€ ì „í˜€ ì—†ë‹¤. ë•Œë¬¸ì— featureë¥¼ ìƒˆë¡œì´ ìƒì„±í•  í•„ìš”ê°€ ìˆë‹¤. ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œ ê°€ì¥ ë³´í¸ì ì¸ ë°©ì‹ì€ ê³¼ê±° ë°ì´í„°(lagged observation)ë¥¼ ìƒì„±í•´ì£¼ëŠ” ê²ƒì´ë‹¤.

ì˜ˆë¥¼ ë“¤ì–´ íŠ¹ì • ì‹œê°„ì˜ valueë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ 1ì‹œê°„ ì „ value, 2ì‹œê°„ ì „ value, ..., nì‹œê°„ ì „ valueë¥¼ ìƒˆë¡œìš´ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€í•´ì£¼ëŠ” ê²ƒì´ë‹¤. `shift()` í•¨ìˆ˜ë¡œ ê°„ë‹¨íˆ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.

ì—¬ê¸°ì„  1~100ì‹œê°„ ì „ ë°ì´í„°ë¥¼ lag1 ~ lag100ìœ¼ë¡œ ë§Œë“¤ì–´ ì‚¬ìš©í•  ê²ƒì´ë‹¤.

í•˜ì§€ë§Œ ì´ ê²½ìš° ë§¨ ì²˜ìŒ 100ê°œì˜ ë°ì´í„°ëŠ” ì†Œì‹¤ëœë‹¤ëŠ” ë‹¨ì ì´ ì¡´ì¬í•œë‹¤. ê·¸ë˜ì„œ ì›ë˜ëŠ” 1ì›” 1ì¼ë¶€í„° ì‹œì‘í–ˆë˜ ë°ì´í„°ê°€ ì²« rowê°€ 1ì›” 5ì¼ 05ì‹œë¡œ ë°”ë€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.


```python
def generate_time_lags(df, n_lags):
    df_n = df.copy()
    for n in range(1, n_lags + 1):
        df_n[f"lag{n}"] = df_n["value"].shift(n)
    df_n = df_n.iloc[n_lags:]
    return df_n

input_dim = 100

df_timelags = generate_time_lags(df, input_dim)
df_timelags
```

    <ipython-input-6-9686bd7878a4>:4: PerformanceWarning:
    
    DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`
    
    





  <div id="df-d21f4007-913b-4bb7-8249-3aa2cd60d0ad">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>value</th>
      <th>lag1</th>
      <th>lag2</th>
      <th>lag3</th>
      <th>lag4</th>
      <th>lag5</th>
      <th>lag6</th>
      <th>lag7</th>
      <th>lag8</th>
      <th>lag9</th>
      <th>...</th>
      <th>lag91</th>
      <th>lag92</th>
      <th>lag93</th>
      <th>lag94</th>
      <th>lag95</th>
      <th>lag96</th>
      <th>lag97</th>
      <th>lag98</th>
      <th>lag99</th>
      <th>lag100</th>
    </tr>
    <tr>
      <th>Datetime</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2005-01-05 05:00:00</th>
      <td>1369.0</td>
      <td>1372.0</td>
      <td>1344.0</td>
      <td>1364.0</td>
      <td>1442.0</td>
      <td>1486.0</td>
      <td>1608.0</td>
      <td>1735.0</td>
      <td>1771.0</td>
      <td>1818.0</td>
      <td>...</td>
      <td>1274.0</td>
      <td>1270.0</td>
      <td>1258.0</td>
      <td>1215.0</td>
      <td>1181.0</td>
      <td>1166.0</td>
      <td>1170.0</td>
      <td>1218.0</td>
      <td>1273.0</td>
      <td>1364.0</td>
    </tr>
    <tr>
      <th>2005-01-05 06:00:00</th>
      <td>1417.0</td>
      <td>1369.0</td>
      <td>1372.0</td>
      <td>1344.0</td>
      <td>1364.0</td>
      <td>1442.0</td>
      <td>1486.0</td>
      <td>1608.0</td>
      <td>1735.0</td>
      <td>1771.0</td>
      <td>...</td>
      <td>1330.0</td>
      <td>1274.0</td>
      <td>1270.0</td>
      <td>1258.0</td>
      <td>1215.0</td>
      <td>1181.0</td>
      <td>1166.0</td>
      <td>1170.0</td>
      <td>1218.0</td>
      <td>1273.0</td>
    </tr>
    <tr>
      <th>2005-01-05 07:00:00</th>
      <td>1569.0</td>
      <td>1417.0</td>
      <td>1369.0</td>
      <td>1372.0</td>
      <td>1344.0</td>
      <td>1364.0</td>
      <td>1442.0</td>
      <td>1486.0</td>
      <td>1608.0</td>
      <td>1735.0</td>
      <td>...</td>
      <td>1352.0</td>
      <td>1330.0</td>
      <td>1274.0</td>
      <td>1270.0</td>
      <td>1258.0</td>
      <td>1215.0</td>
      <td>1181.0</td>
      <td>1166.0</td>
      <td>1170.0</td>
      <td>1218.0</td>
    </tr>
    <tr>
      <th>2005-01-05 08:00:00</th>
      <td>1736.0</td>
      <td>1569.0</td>
      <td>1417.0</td>
      <td>1369.0</td>
      <td>1372.0</td>
      <td>1344.0</td>
      <td>1364.0</td>
      <td>1442.0</td>
      <td>1486.0</td>
      <td>1608.0</td>
      <td>...</td>
      <td>1371.0</td>
      <td>1352.0</td>
      <td>1330.0</td>
      <td>1274.0</td>
      <td>1270.0</td>
      <td>1258.0</td>
      <td>1215.0</td>
      <td>1181.0</td>
      <td>1166.0</td>
      <td>1170.0</td>
    </tr>
    <tr>
      <th>2005-01-05 09:00:00</th>
      <td>1809.0</td>
      <td>1736.0</td>
      <td>1569.0</td>
      <td>1417.0</td>
      <td>1369.0</td>
      <td>1372.0</td>
      <td>1344.0</td>
      <td>1364.0</td>
      <td>1442.0</td>
      <td>1486.0</td>
      <td>...</td>
      <td>1356.0</td>
      <td>1371.0</td>
      <td>1352.0</td>
      <td>1330.0</td>
      <td>1274.0</td>
      <td>1270.0</td>
      <td>1258.0</td>
      <td>1215.0</td>
      <td>1181.0</td>
      <td>1166.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-08-02 20:00:00</th>
      <td>1966.0</td>
      <td>1999.0</td>
      <td>2050.0</td>
      <td>2039.0</td>
      <td>2029.0</td>
      <td>1983.0</td>
      <td>1952.0</td>
      <td>1931.0</td>
      <td>1865.0</td>
      <td>1792.0</td>
      <td>...</td>
      <td>1453.0</td>
      <td>1557.0</td>
      <td>1675.0</td>
      <td>1789.0</td>
      <td>1817.0</td>
      <td>1866.0</td>
      <td>1907.0</td>
      <td>1943.0</td>
      <td>1922.0</td>
      <td>1862.0</td>
    </tr>
    <tr>
      <th>2018-08-02 21:00:00</th>
      <td>1944.0</td>
      <td>1966.0</td>
      <td>1999.0</td>
      <td>2050.0</td>
      <td>2039.0</td>
      <td>2029.0</td>
      <td>1983.0</td>
      <td>1952.0</td>
      <td>1931.0</td>
      <td>1865.0</td>
      <td>...</td>
      <td>1376.0</td>
      <td>1453.0</td>
      <td>1557.0</td>
      <td>1675.0</td>
      <td>1789.0</td>
      <td>1817.0</td>
      <td>1866.0</td>
      <td>1907.0</td>
      <td>1943.0</td>
      <td>1922.0</td>
    </tr>
    <tr>
      <th>2018-08-02 22:00:00</th>
      <td>1901.0</td>
      <td>1944.0</td>
      <td>1966.0</td>
      <td>1999.0</td>
      <td>2050.0</td>
      <td>2039.0</td>
      <td>2029.0</td>
      <td>1983.0</td>
      <td>1952.0</td>
      <td>1931.0</td>
      <td>...</td>
      <td>1332.0</td>
      <td>1376.0</td>
      <td>1453.0</td>
      <td>1557.0</td>
      <td>1675.0</td>
      <td>1789.0</td>
      <td>1817.0</td>
      <td>1866.0</td>
      <td>1907.0</td>
      <td>1943.0</td>
    </tr>
    <tr>
      <th>2018-08-02 23:00:00</th>
      <td>1789.0</td>
      <td>1901.0</td>
      <td>1944.0</td>
      <td>1966.0</td>
      <td>1999.0</td>
      <td>2050.0</td>
      <td>2039.0</td>
      <td>2029.0</td>
      <td>1983.0</td>
      <td>1952.0</td>
      <td>...</td>
      <td>1312.0</td>
      <td>1332.0</td>
      <td>1376.0</td>
      <td>1453.0</td>
      <td>1557.0</td>
      <td>1675.0</td>
      <td>1789.0</td>
      <td>1817.0</td>
      <td>1866.0</td>
      <td>1907.0</td>
    </tr>
    <tr>
      <th>2018-08-03 00:00:00</th>
      <td>1656.0</td>
      <td>1789.0</td>
      <td>1901.0</td>
      <td>1944.0</td>
      <td>1966.0</td>
      <td>1999.0</td>
      <td>2050.0</td>
      <td>2039.0</td>
      <td>2029.0</td>
      <td>1983.0</td>
      <td>...</td>
      <td>1330.0</td>
      <td>1312.0</td>
      <td>1332.0</td>
      <td>1376.0</td>
      <td>1453.0</td>
      <td>1557.0</td>
      <td>1675.0</td>
      <td>1789.0</td>
      <td>1817.0</td>
      <td>1866.0</td>
    </tr>
  </tbody>
</table>
<p>118968 rows Ã— 101 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-d21f4007-913b-4bb7-8249-3aa2cd60d0ad')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-d21f4007-913b-4bb7-8249-3aa2cd60d0ad button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-d21f4007-913b-4bb7-8249-3aa2cd60d0ad');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




ë˜í•œ ì¸ë±ìŠ¤ë¡œ ì§€ì •í•œ `Datetimeì„ ì´ìš©í•˜ì—¬ ì‹œê°„, ë‚ ì§œ, ì›”, ìš”ì¼, í•œ í•´ ì¤‘ ëª‡ ì£¼ì°¨ ë“±ì˜ featureë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤.



```python
df = df.reset_index(drop=False)
df['HOUR'] = df['Datetime'].dt.hour #ì‹œê°„ ë³€ìˆ˜ ì¶”ê°€
df['MONTH'] = df['Datetime'].dt.month #ì›” ë³€ìˆ˜ ì¶”ê°€
df['WEEK'] = df['Datetime'].dt.weekofyear #ì£¼ì°¨ ë³€ìˆ˜ ì¶”ê°€
df['DAY'] = df['Datetime'].dt.dayofyear #ì¼ ë³€ìˆ˜ ì¶”ê°€
df['WEEKDAY'] = df['Datetime'].dt.weekday #ìš”ì¼ ë³€ìˆ˜ ì¶”ê°€
```

    <ipython-input-7-29a1151e7af4>:4: FutureWarning:
    
    Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.
    
    

ê·¸ë¦¬ê³  ê° datetime featuresë¡œ groupbyë¥¼ í•´ì„œ ê·¸ë˜í”„ ì¶”ì´ë¥¼ í™•ì¸í•´ë³´ì•˜ë‹¤.


```python
draw_list = ["HOUR","DAY","MONTH","WEEK","WEEKDAY"]

#ì‹œê°„ ë³€ìˆ˜ë¥¼ xì¶•ì—, ì „ë ¥ ì†Œë¹„ëŸ‰ì„ yì¶•ì— ë‘ê³  ê·¸ë¦° line plot í•¨ìˆ˜
def plot_per_time(sets, draw_list):
    plt.figure(figsize=(20,10))
    idx=1
    for var in draw_list:
        groupby = sets.groupby(var).mean()
        groupby.reset_index(inplace=True)
        plt.subplot(3,2,idx)
        plt.plot(groupby[var], groupby['value'])
        plt.title(var)
        idx+=1
        
plot_per_time(df, draw_list)
```


    
<img src="https://user-images.githubusercontent.com/115082062/229084143-7cfcac13-af48-4537-a995-9bcff55926b6.png">

<br>
    


- HOUR: ì£¼ë¡œ ìƒˆë²½ ì‹œê°„ëŒ€ì—ëŠ” ì†Œë¹„ëŸ‰ì´ ë‚®ê±°ë‚˜ ê±°ì˜ ì—†ë‹¤. í•˜ë£¨ ì¤‘ ê°€ì¥ ë†’ì€ ì‹œê°„ëŒ€ëŠ” 17~18ì‹œê²½ìœ¼ë¡œ ë³´ì´ë©° ì´ëŠ” ë°¤ì´ ì°¾ì•„ì˜´ì— ë”°ë¼ ì „ë ¥ëŸ‰ì´ ë†’ì•„ì§€ê³ , ì§ì¥ì¸ë“¤ì˜ í‡´ê·¼ ì§ì „, ìƒê¶Œì´ í™œë°œí•´ì§€ê¸° ì‹œì‘í•˜ëŠ” ì‹œê°„, ê°€ì •ì§‘ì—ì„œë„ ì „ë ¥ì´ ì†Œë¹„ë˜ê¸° ì‹œì‘í•˜ëŠ” ì‹œê°„ëŒ€ë¼ ê·¸ëŸ° ê²ƒìœ¼ë¡œ ì‚¬ë£Œëœë‹¤.
- DAY, MONTH, WEEK: ê¸°í›„ê°€ ì˜¨í™”í•œ ë´„, ê°€ì„ì—ëŠ” ì†Œë¹„ëŸ‰ì´ ë‚®ê³  ì—¬ë¦„ì— ê°€ì¥ ë†’ê³  ê²¨ìš¸ì´ ê·¸ë¥¼ ë’¤ë”°ë¥¸ë‹¤. ëƒ‰ë‚œë°© ì¥ì¹˜ì˜ ê°€ë™ìœ¼ë¡œ ì´ìœ ë¥¼ ì‰½ê²Œ ì¶”ë¡ í•  ìˆ˜ ìˆë‹¤. 
- WEEKDAY: ì£¼ë§(5,6)ì—ëŠ” ì§ì¥ì¸ë“¤ì´ ì¶œê·¼í•˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ì¼ë°˜ì ì´ë‹ˆ ì†Œë¹„ëŸ‰ì´ ì ì–´ë“  ê²ƒìœ¼ë¡œ ì‚¬ë£Œëœë‹¤.

<br>

## 4. One-hot encoding

datetime featuresë“¤ì€ ê°’ì´ í¬ë‹¤ê³  í•˜ì—¬ ì˜í–¥ë ¥ì´ í° ê²ƒì´ ì•„ë‹ˆë¼ ê·¸ì € ë²”ì£¼í˜• ë³€ìˆ˜ì´ë¯€ë¡œ ê°’ì˜ í¬ê¸°ê°€ ì˜ˆì¸¡ì— ì˜í–¥ì„ ì£¼ë©´ ì•ˆëœë‹¤ë‹¤. ë•Œë¬¸ì— ì›í•«ì¸ì½”ë”©ì„ í•´ì¤„ í•„ìš”ê°€ ìˆë‹¤. pandasì—ì„  `get_dummies`ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

DAYë¥¼ ì›í•«ì¸ì½”ë”©ì„ í•˜ë©´ 365ê°œì˜ featureê°€ ì¶”ê°€ë˜ì–´ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ MONTH, WEEK, WEEKDAYì— ëŒ€í•´ì„œë§Œ ì›í•«ì¸ì½”ë”©ì„ í•œë‹¤.


```python
def onehot_encode_pd(df, cols):
    for col in cols:
        dummies = pd.get_dummies(df[col], prefix=col)
        df = pd.concat([df, dummies], axis=1)
    
    return df.drop(columns=cols)

df_features = onehot_encode_pd(df, ['MONTH','WEEK','WEEKDAY'])
df_features
```





  <div id="df-f1baa507-175b-4232-a37d-276968324b52">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Datetime</th>
      <th>value</th>
      <th>HOUR</th>
      <th>DAY</th>
      <th>MONTH_1</th>
      <th>MONTH_2</th>
      <th>MONTH_3</th>
      <th>MONTH_4</th>
      <th>MONTH_5</th>
      <th>MONTH_6</th>
      <th>...</th>
      <th>WEEK_51</th>
      <th>WEEK_52</th>
      <th>WEEK_53</th>
      <th>WEEKDAY_0</th>
      <th>WEEKDAY_1</th>
      <th>WEEKDAY_2</th>
      <th>WEEKDAY_3</th>
      <th>WEEKDAY_4</th>
      <th>WEEKDAY_5</th>
      <th>WEEKDAY_6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2005-01-01 01:00:00</td>
      <td>1364.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2005-01-01 02:00:00</td>
      <td>1273.0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2005-01-01 03:00:00</td>
      <td>1218.0</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2005-01-01 04:00:00</td>
      <td>1170.0</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2005-01-01 05:00:00</td>
      <td>1166.0</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>119063</th>
      <td>2018-08-02 20:00:00</td>
      <td>1966.0</td>
      <td>20</td>
      <td>214</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>119064</th>
      <td>2018-08-02 21:00:00</td>
      <td>1944.0</td>
      <td>21</td>
      <td>214</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>119065</th>
      <td>2018-08-02 22:00:00</td>
      <td>1901.0</td>
      <td>22</td>
      <td>214</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>119066</th>
      <td>2018-08-02 23:00:00</td>
      <td>1789.0</td>
      <td>23</td>
      <td>214</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>119067</th>
      <td>2018-08-03 00:00:00</td>
      <td>1656.0</td>
      <td>0</td>
      <td>215</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>119068 rows Ã— 76 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-f1baa507-175b-4232-a37d-276968324b52')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-f1baa507-175b-4232-a37d-276968324b52 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-f1baa507-175b-4232-a37d-276968324b52');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>


<br>

## 5. Generating cyclical features (sin/cos transformations)

ì‹œê°„ì€ 0~23ì´ë¼ëŠ” ì •ìˆ˜í˜• íƒ€ì…ìœ¼ë¡œ í‘œí˜„ëœë‹¤. ê·¸ëŸ°ë° ì´ë ‡ê²Œë˜ë©´ 1ì›” 1ì¼ 23ì‹œì™€ 1ì›” 2ì¼ 00ì‹œê°€ ì‹¤ì œë¡œ í•œ ì‹œê°„ì˜ ì°¨ì´ë¥¼ ê°€ì§ì—ë„ 23ì˜ ì°¨ë¦¬ì„ ê°–ëŠ” ê¼´ì´ ëœë‹¤. ê·¸ë˜ì„œ ì´ë¥¼ í•´ê²°í•˜ê³ ì ì‚¼ê°í•¨ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°„ì´ ì—°ì†ì„±ì„ ê°–ê²Œ í•  ê²ƒì´ë‹¤.

HOUR, DAYì— ëŒ€í•´ì„œë§Œ ì‚¼ê°ë³€ìˆ˜ ë³€í™˜ì„ í•´ì£¼ê³  ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ë‘”ë‹¤.


```python
def generate_cyclical_features(df, col_name, period, start_num=0):
    kwargs = {
        f'sin_{col_name}' : lambda x: np.sin(2*np.pi*(df[col_name]-start_num)/period),
        f'cos_{col_name}' : lambda x: np.cos(2*np.pi*(df[col_name]-start_num)/period)    
             }
    return df.assign(**kwargs).drop(columns=[col_name])

df_features = generate_cyclical_features(df_features, 'HOUR', 24, 0)
df_features = generate_cyclical_features(df_features, 'DAY', 365, 1)
# df_features = generate_cyclical_features(df_features, 'day_of_week', 7, 0)
# df_features = generate_cyclical_features(df_features, 'month', 12, 1)
# df_features = generate_cyclical_features(df_features, 'week_of_year', 52, 0)

df_features
```





  <div id="df-c3aa9151-0548-40db-8e5a-76d257e62a58">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Datetime</th>
      <th>value</th>
      <th>MONTH_1</th>
      <th>MONTH_2</th>
      <th>MONTH_3</th>
      <th>MONTH_4</th>
      <th>MONTH_5</th>
      <th>MONTH_6</th>
      <th>MONTH_7</th>
      <th>MONTH_8</th>
      <th>...</th>
      <th>WEEKDAY_1</th>
      <th>WEEKDAY_2</th>
      <th>WEEKDAY_3</th>
      <th>WEEKDAY_4</th>
      <th>WEEKDAY_5</th>
      <th>WEEKDAY_6</th>
      <th>sin_HOUR</th>
      <th>cos_HOUR</th>
      <th>sin_DAY</th>
      <th>cos_DAY</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2005-01-01 01:00:00</td>
      <td>1364.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.258819</td>
      <td>0.965926</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2005-01-01 02:00:00</td>
      <td>1273.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.500000</td>
      <td>0.866025</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2005-01-01 03:00:00</td>
      <td>1218.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.707107</td>
      <td>0.707107</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2005-01-01 04:00:00</td>
      <td>1170.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.866025</td>
      <td>0.500000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2005-01-01 05:00:00</td>
      <td>1166.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.965926</td>
      <td>0.258819</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>119063</th>
      <td>2018-08-02 20:00:00</td>
      <td>1966.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.866025</td>
      <td>0.500000</td>
      <td>-0.501242</td>
      <td>-0.865307</td>
    </tr>
    <tr>
      <th>119064</th>
      <td>2018-08-02 21:00:00</td>
      <td>1944.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.707107</td>
      <td>0.707107</td>
      <td>-0.501242</td>
      <td>-0.865307</td>
    </tr>
    <tr>
      <th>119065</th>
      <td>2018-08-02 22:00:00</td>
      <td>1901.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.500000</td>
      <td>0.866025</td>
      <td>-0.501242</td>
      <td>-0.865307</td>
    </tr>
    <tr>
      <th>119066</th>
      <td>2018-08-02 23:00:00</td>
      <td>1789.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.258819</td>
      <td>0.965926</td>
      <td>-0.501242</td>
      <td>-0.865307</td>
    </tr>
    <tr>
      <th>119067</th>
      <td>2018-08-03 00:00:00</td>
      <td>1656.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>-0.516062</td>
      <td>-0.856551</td>
    </tr>
  </tbody>
</table>
<p>119068 rows Ã— 78 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-c3aa9151-0548-40db-8e5a-76d257e62a58')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-c3aa9151-0548-40db-8e5a-76d257e62a58 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-c3aa9151-0548-40db-8e5a-76d257e62a58');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>


<br>

## 6. Generating Holiday features

ì•ì„œ ê·¸ë˜í”„ë¡œ í™•ì¸í•˜ì˜€ë“¯ ì£¼ë§ ì—¬ë¶€ì— ë”°ë¼ ì „ë ¥ëŸ‰ì´ í° í­ìœ¼ë¡œ ë°”ë€Œê³  ìˆë‹¤. ë”°ë¼ì„œ ì£¼ë§ ì—¬ë¶€ë¥¼ binaryí•˜ê²Œ ë‚˜íƒ€ë‚´ì¤€ë‹¤.



```python
from datetime import date
import holidays

df_features.set_index(['Datetime'], inplace=True)
us_holidays = holidays.US()

def is_holiday(date):
    date = date.replace(hour = 0)
    return 1 if (date in us_holidays) else 0

def add_holiday_col(df, holidays):
    return df.assign(is_holiday = df.index.to_series().apply(is_holiday))


df_features = add_holiday_col(df_features, us_holidays)
df_features
```





  <div id="df-920b9f75-cafc-468f-84fc-d40942a56e08">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>value</th>
      <th>MONTH_1</th>
      <th>MONTH_2</th>
      <th>MONTH_3</th>
      <th>MONTH_4</th>
      <th>MONTH_5</th>
      <th>MONTH_6</th>
      <th>MONTH_7</th>
      <th>MONTH_8</th>
      <th>MONTH_9</th>
      <th>...</th>
      <th>WEEKDAY_2</th>
      <th>WEEKDAY_3</th>
      <th>WEEKDAY_4</th>
      <th>WEEKDAY_5</th>
      <th>WEEKDAY_6</th>
      <th>sin_HOUR</th>
      <th>cos_HOUR</th>
      <th>sin_DAY</th>
      <th>cos_DAY</th>
      <th>is_holiday</th>
    </tr>
    <tr>
      <th>Datetime</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2005-01-01 01:00:00</th>
      <td>1364.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.258819</td>
      <td>0.965926</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2005-01-01 02:00:00</th>
      <td>1273.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.500000</td>
      <td>0.866025</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2005-01-01 03:00:00</th>
      <td>1218.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.707107</td>
      <td>0.707107</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2005-01-01 04:00:00</th>
      <td>1170.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.866025</td>
      <td>0.500000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2005-01-01 05:00:00</th>
      <td>1166.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.965926</td>
      <td>0.258819</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-08-02 20:00:00</th>
      <td>1966.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.866025</td>
      <td>0.500000</td>
      <td>-0.501242</td>
      <td>-0.865307</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2018-08-02 21:00:00</th>
      <td>1944.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.707107</td>
      <td>0.707107</td>
      <td>-0.501242</td>
      <td>-0.865307</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2018-08-02 22:00:00</th>
      <td>1901.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.500000</td>
      <td>0.866025</td>
      <td>-0.501242</td>
      <td>-0.865307</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2018-08-02 23:00:00</th>
      <td>1789.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.258819</td>
      <td>0.965926</td>
      <td>-0.501242</td>
      <td>-0.865307</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2018-08-03 00:00:00</th>
      <td>1656.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>-0.516062</td>
      <td>-0.856551</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>119068 rows Ã— 78 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-920b9f75-cafc-468f-84fc-d40942a56e08')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-920b9f75-cafc-468f-84fc-d40942a56e08 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-920b9f75-cafc-468f-84fc-d40942a56e08');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>


<br>

## 7. Splitting the data into test, validation and train sets


```python
from sklearn.model_selection import train_test_split

def feature_label_split(df, target_col):
    y = df[[target_col]]
    X = df.drop(columns=[target_col])
    return X, y

def train_val_test_split(df, target_col, test_ratio):
    val_ratio = test_ratio / (1 - test_ratio)
    X, y = feature_label_split(df, target_col)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=False)
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, shuffle=False)
    return X_train, X_val, X_test, y_train, y_val, y_test

X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(df_features, 'value', 0.2)
```


```python
print(X_train.shape)
print(X_val.shape)
print(X_test.shape)
```

    (71440, 77)
    (23814, 77)
    (23814, 77)
    
<br>

## 8. Scaling

ìŠ¤ì¼€ì¼ë§ì€ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ í›¨ì”¬ ìš©ì´í•˜ê²Œ í•´ì£¼ë¯€ë¡œ ì‹ ê²½ë§ì—ì„œ íš¨ê³¼ì ì´ë‹¤.



```python
from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler

def get_scaler(scaler):
    scalers = {
        "minmax": MinMaxScaler,
        "standard": StandardScaler,
        "maxabs": MaxAbsScaler,
        "robust": RobustScaler,
    }
    return scalers.get(scaler.lower())()
```


```python
scaler = get_scaler('minmax')
X_train_arr = scaler.fit_transform(X_train)
X_val_arr = scaler.transform(X_val)
X_test_arr = scaler.transform(X_test)

y_train_arr = scaler.fit_transform(y_train)
y_val_arr = scaler.transform(y_val)
y_test_arr = scaler.transform(y_test)
```

<br>

## 9. Loading the data into DataLoaders

PyTorchì˜ `DataLoader` classë¥¼ ì‚¬ìš©í•˜ë©´ ì‹ ê²½ë§ í•™ìŠµì— í•„ìš”í•œ mini-batch í˜•íƒœë¡œ ìª¼ê°œì–´ ë°ì´í„°ë¥¼ iterableí•˜ê²Œ ë§Œë“¤ì–´ì¤€ë‹¤.

ê·¸ì— ì•ì„œ ë°ì´í„°ì˜ í˜•íƒœë¥¼ Tensorí˜•ìœ¼ë¡œ ë°”ê¾¸ì–´ì¤€ë‹¤.



```python
from torch.utils.data import TensorDataset, DataLoader

batch_size = 64

train_features = torch.Tensor(X_train_arr)
train_targets = torch.Tensor(y_train_arr)
val_features = torch.Tensor(X_val_arr)
val_targets = torch.Tensor(y_val_arr)
test_features = torch.Tensor(X_test_arr)
test_targets = torch.Tensor(y_test_arr)

train = TensorDataset(train_features, train_targets)
val = TensorDataset(val_features, val_targets)
test = TensorDataset(test_features, test_targets)

train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)
val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)
test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)
test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)
```

<br>

## 10. Defining the RNN model classes(RNN, LSTM, GRU)


### 10-1. RNN



```python
class RNNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        """The __init__ method that initiates an RNN instance.

        Args:
            input_dim (int): The number of nodes in the input layer
            hidden_dim (int): The number of nodes in each layer
            layer_dim (int): The number of layers in the network
            output_dim (int): The number of nodes in the output layer
            dropout_prob (float): The probability of nodes being dropped out

        """
        # __init__ ë©”ì†Œë“œì—ì„œ super(RNNModel, self).__init_()ì„ í•´ì¤Œìœ¼ë¡œì¨ 
        # í˜¸ì¶œ ë‹¨ê³„ì—ì„œ ë¶€ëª¨ í´ë˜ìŠ¤(nn.Module)ì˜ __init__ ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•´ì£¼ê³ , ë‹¤ì–‘í•œ ë³€ìˆ˜ë“¤ì„ ìƒì†ë°›ì„ ìˆ˜ ìˆìŒ.
        super(RNNModel, self).__init__()

        # ê° ì¸µì„ ëª‡ ê°œ ìŒ“ì„ ê²ƒì¸ì§€ ì •ì˜
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim

        # RNN layers
        self.rnn = nn.RNN(
            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob
        )
        # ëª¨ë“  ë‰´ëŸ°ì´ ë‹¤ìŒ ì¸µì˜ ëª¨ë“  ë‰´ëŸ°ê³¼ ì—°ê²°ë˜ëŠ” 'ì™„ì „ì—°ê²°ì¸µ'
        # í‰íƒ„í™”(Flatten)ë¥¼ í•œë‹¤.
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        """forwardëŠ” ì…ë ¥ê°’ì¸ tensorë¥¼ forward propadation(ìˆœì „íŒŒ)í•œë‹¤

        ì¸ì:
            x (torch.Tensor): ì…ë ¥ tensorì˜ ì°¨ì›ì€ (batch size, sequence length, input_dim)

        ê²°ê³¼ê°’:
            torch.Tensor: The output tensor of the shape (batch size, output_dim)

        """
        # ì´ˆê¸° ì€ë‹‰ìƒíƒœë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•´ì¤€ë‹¤.
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()

        # ìˆœì „íŒŒ ê³¼ì •(input -> hidden)
        out, h0 = self.rnn(x, h0.detach())

        # 3ì°¨ì›(batch_size, seq_length, hidden_size)ìœ¼ë¡œ êµ¬ì„±ëœ outputì„ ë§ˆì§€ë§‰ seq_lenthë§Œ ê°–ê³ ì˜´ìœ¼ë¡œì¨ 2ì°¨ì›ìœ¼ë¡œ
        # ë§ˆì§€ë§‰ ì¶œë ¥ë§Œ ê°€ì§€ê³  FCì¸µì— ë„£ì„ ì¤€ë¹„í•˜ëŠ” ê²ƒì„
        out = out[:, -1, :]

        # Convert the final state to our desired output shape (batch_size, output_dim)
        out = self.fc(out)
        return out
```

<br>

### 10-2. LSTM
ì¶œë ¥, ì…ë ¥, ì‚­ì œ ê²Œì´íŠ¸ë¥¼ ê°–ê³  ìˆì–´ ë¶ˆí•„ìš”í•œ ê¸°ì–µì€ ì‚­ì œí•˜ê³  ì¥ê¸° ê¸°ì–µì— íŠ¹í™”ëœ ëª¨ë¸ì´ë‹¤.


```python
class LSTMModel(nn.Module):
    """LSTMModel class extends nn.Module class and works as a constructor for LSTMs.

       LSTMModel class initiates a LSTM module based on PyTorch's nn.Module class.
       It has only two methods, namely init() and forward(). While the init()
       method initiates the model with the given input parameters, the forward()
       method defines how the forward propagation needs to be calculated.
       Since PyTorch automatically defines back propagation, there is no need
       to define back propagation method.

       Attributes:
           hidden_dim (int): The number of nodes in each layer
           layer_dim (str): The number of layers in the network
           lstm (nn.LSTM): The LSTM model constructed with the input parameters.
           fc (nn.Linear): The fully connected layer to convert the final state
                           of LSTMs to our desired output shape.

    """
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        """The __init__ method that initiates a LSTM instance.

        Args:
            input_dim (int): The number of nodes in the input layer
            hidden_dim (int): The number of nodes in each layer
            layer_dim (int): The number of layers in the network
            output_dim (int): The number of nodes in the output layer
            dropout_prob (float): The probability of nodes being dropped out

        """
        super(LSTMModel, self).__init__()

        # Defining the number of layers and the nodes in each layer
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim

        # LSTM layers
        self.lstm = nn.LSTM(
            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob
        )

        # Fully connected layer
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        """The forward method takes input tensor x and does forward propagation

        Args:
            x (torch.Tensor): The input tensor of the shape (batch size, sequence length, input_dim)

        Returns:
            torch.Tensor: The output tensor of the shape (batch size, output_dim)

        """
        # Initializing hidden state for first input with zeros
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()

        # RNNê³¼ ë‹¬ë¦¬ LSTMì—ëŠ” cell state(ì…€ ìƒíƒœ)ê°€ ì¡´ì¬í•œë‹¤. ì´ ì—­ì‹œ hidden stateì²˜ëŸ¼ 0ìœ¼ë¡œ ìƒì„±í•´ì¤€ë‹¤.
        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()

        # We need to detach as we are doing truncated backpropagation through time (BPTT)
        # If we don't, we'll backprop all the way to the start even after going through another batch
        # Forward propagation by passing in the input, hidden state, and cell state into the model
        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))

        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)
        # so that it can fit into the fully connected layer
        out = out[:, -1, :]

        # Convert the final state to our desired output shape (batch_size, output_dim)
        out = self.fc(out)

        return out
```

<br>

### 10-3 GRU
LSTMì²˜ëŸ¼ ì¥ê¸° ê¸°ì–µì— íš¨ê³¼ì ì´ì§€ë§Œ GRUëŠ” ì—…ë°ì´íŠ¸ ê²Œì´íŠ¸ì™€ ë¦¬ì…‹ ê²Œì´íŠ¸ë§Œ ì¡´ì¬í•œë‹¤. ë˜í•œ cell state(ì…€ ìƒíƒœ)ë„ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.



```python
class GRUModel(nn.Module):
    """GRUModel class extends nn.Module class and works as a constructor for GRUs.

       GRUModel class initiates a GRU module based on PyTorch's nn.Module class.
       It has only two methods, namely init() and forward(). While the init()
       method initiates the model with the given input parameters, the forward()
       method defines how the forward propagation needs to be calculated.
       Since PyTorch automatically defines back propagation, there is no need
       to define back propagation method.

       Attributes:
           hidden_dim (int): The number of nodes in each layer
           layer_dim (str): The number of layers in the network
           gru (nn.GRU): The GRU model constructed with the input parameters.
           fc (nn.Linear): The fully connected layer to convert the final state
                           of GRUs to our desired output shape.

    """
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        """The __init__ method that initiates a GRU instance.

        Args:
            input_dim (int): The number of nodes in the input layer
            hidden_dim (int): The number of nodes in each layer
            layer_dim (int): The number of layers in the network
            output_dim (int): The number of nodes in the output layer
            dropout_prob (float): The probability of nodes being dropped out

        """
        super(GRUModel, self).__init__()

        # Defining the number of layers and the nodes in each layer
        self.layer_dim = layer_dim
        self.hidden_dim = hidden_dim

        # GRU layers
        self.gru = nn.GRU(
            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob
        )

        # Fully connected layer
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        """The forward method takes input tensor x and does forward propagation

        Args:
            x (torch.Tensor): The input tensor of the shape (batch size, sequence length, input_dim)

        Returns:
            torch.Tensor: The output tensor of the shape (batch size, output_dim)

        """
        # Initializing hidden state for first input with zeros
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()

        # Forward propagation by passing in the input and hidden state into the model
        # 
        out, _ = self.gru(x, h0.detach())

        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)
        # so that it can fit into the fully connected layer
        out = out[:, -1, :]

        # Convert the final state to our desired output shape (batch_size, output_dim)
        out = self.fc(out)

        return out

```


```python
def get_model(model, model_params):
    models = {
        "rnn": RNNModel,
        "lstm": LSTMModel,
        "gru": GRUModel,
    }
    return models.get(model.lower())(**model_params)
```

<br>

## 11. Making Predictions
ì•„ë˜ì—ì„  ëª¨ë¸ë¡œ í›ˆë ¨ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ê³  ì˜¤ì°¨ë¥¼ ê³„ì‚°í•˜ê³  ì˜µí‹°ë§ˆì´ì§•ì„ í•˜ëŠ” ê³¼ì •ì„ `train_step()`ë©”ì„œë“œë¡œ ë§Œë“¤ì–´ì£¼ì—ˆë‹¤. ì´ê²ƒì´ í•˜ë‚˜ì˜ epochì´ ëœë‹¤. ê·¸ë¦¬ê³  `train()` ë©”ì„œë“œì—ì„œëŠ” ê°ê°ì˜ epochì„ ë°˜ë³µí•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. ê·¸ ë°–ì˜ validation, evaluateë¥¼ í•  ìˆ˜ ìˆëŠ” ë©”ì„œë“œë¥¼ ì¢…í•©í•˜ì—¬ `optimization`ë¼ëŠ” classë¥¼ ë§Œë“¤ì—ˆë‹¤.

trainê³¼ evaluationì—ì„œ ê°€ì¥ í° ì°¨ì´ì ì€ ì „ìëŠ” ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ì§€ë§Œ, í›„ìëŠ” ê·¸ë ‡ì§€ ì•Šë‹¤ëŠ” ì ì´ë‹¤.


```python
class Optimization:
    """Optimization is a helper class that allows training, validation, prediction.

    Optimization is a helper class that takes model, loss function, optimizer function
    learning scheduler (optional), early stopping (optional) as inputs. In return, it
    provides a framework to train and validate the models, and to predict future values
    based on the models.

    Attributes:
        model (RNNModel, LSTMModel, GRUModel): Model class created for the type of RNN
        loss_fn (torch.nn.modules.Loss): Loss function to calculate the losses
        optimizer (torch.optim.Optimizer): Optimizer function to optimize the loss function
        train_losses (list[float]): The loss values from the training
        val_losses (list[float]): The loss values from the validation
        last_epoch (int): The number of epochs that the models is trained
    """
    def __init__(self, model, loss_fn, optimizer):
        """
        Args:
            model (RNNModel, LSTMModel, GRUModel): Model class created for the type of RNN
            loss_fn (torch.nn.modules.Loss): Loss function to calculate the losses
            optimizer (torch.optim.Optimizer): Optimizer function to optimize the loss function
        """
        self.model = model
        self.loss_fn = loss_fn
        self.optimizer = optimizer
        self.train_losses = []
        self.val_losses = []
        
    # trainingì˜ one step(=one epoch)ì„ ë‹´ë‹¹í•˜ëŠ” í•¨ìˆ˜
    def train_step(self, x, y):
        """The method train_step completes one step of training.

        Given the features (x) and the target values (y) tensors, the method completes
        one step of the training. First, it activates the train mode to enable back prop.
        After generating predicted values (yhat) by doing forward propagation, it calculates
        the losses by using the loss function. Then, it computes the gradients by doing
        back propagation and updates the weights by calling step() function.

        Args:
            x (torch.Tensor): Tensor for features to train one step
            y (torch.Tensor): Tensor for target values to calculate losses

        """
        # Sets model to train mode
        self.model.train()

        # Makes predictions
        yhat = self.model(x)

        # Computes loss
        loss = self.loss_fn(y, yhat)

        # Computes gradients
        loss.backward()

        # Updates parameters and zeroes gradients
        self.optimizer.step()
        self.optimizer.zero_grad()

        # Returns the loss
        return loss.item()

    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):
        """The method train performs the model training

        The method takes DataLoaders for training and validation datasets, batch size for
        mini-batch training, number of epochs to train, and number of features as inputs.
        Then, it carries out the training by iteratively calling the method train_step for
        n_epochs times. If early stopping is enabled, then it  checks the stopping condition
        to decide whether the training needs to halt before n_epochs steps. Finally, it saves
        the model in a designated file path.

        Args:
            train_loader (torch.utils.data.DataLoader): DataLoader that stores training data
            val_loader (torch.utils.data.DataLoader): DataLoader that stores validation data
            batch_size (int): Batch size for mini-batch training
            n_epochs (int): Number of epochs, i.e., train steps, to train
            n_features (int): Number of feature columns

        """
        model_path = f'{self.model}_{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'

        # train_stepì„ n_epochë§Œí¼ ë°˜ë³µí•´ì¤€ë‹¤.
        for epoch in range(1, n_epochs + 1):
            batch_losses = []
            # mini-batchë¡œ ìª¼ê°œì§„ ë‹¨ìœ„ì”© í•™ìŠµ
            for x_batch, y_batch in train_loader:
                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)
                y_batch = y_batch.to(device)
                loss = self.train_step(x_batch, y_batch)
                batch_losses.append(loss)
            training_loss = np.mean(batch_losses)
            self.train_losses.append(training_loss)

            # validationì„ í•  ë•Œì—ëŠ” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ ë¹„í™œì„±í™”í•œë‹¤.
            with torch.no_grad():
                batch_val_losses = []
                for x_val, y_val in val_loader:
                    x_val = x_val.view([batch_size, -1, n_features]).to(device)
                    y_val = y_val.to(device)
                    self.model.eval()
                    yhat = self.model(x_val)
                    val_loss = self.loss_fn(y_val, yhat).item()
                    batch_val_losses.append(val_loss)
                validation_loss = np.mean(batch_val_losses)
                self.val_losses.append(validation_loss)

            if (epoch <= 10) | (epoch % 50 == 0):
                print(
                    f"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\t Validation loss: {validation_loss:.4f}"
                )

        torch.save(self.model.state_dict(), model_path)

    def evaluate(self, test_loader, batch_size=1, n_features=1):
        """The method evaluate performs the model evaluation

        The method takes DataLoaders for the test dataset, batch size for mini-batch testing,
        and number of features as inputs. Similar to the model validation, it iteratively
        predicts the target values and calculates losses. Then, it returns two lists that
        hold the predictions and the actual values.

        Note:
            This method assumes that the prediction from the previous step is available at
            the time of the prediction, and only does one-step prediction into the future.

        Args:
            test_loader (torch.utils.data.DataLoader): DataLoader that stores test data
            batch_size (int): Batch size for mini-batch training
            n_features (int): Number of feature columns

        Returns:
            list[float]: The values predicted by the model
            list[float]: The actual values in the test set.

        """
        # evaluationì„ í•  ë•Œì—ëŠ” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ ë¹„í™œì„±í™”í•œë‹¤.
        with torch.no_grad():
            predictions = []
            values = []
            for x_test, y_test in test_loader:
                x_test = x_test.view([batch_size, -1, n_features]).to(device)
                y_test = y_test.to(device)
                self.model.eval()
                yhat = self.model(x_test)
                predictions.append(yhat.to(device).detach().numpy())
                values.append(y_test.to(device).detach().numpy())

        return predictions, values

    def plot_losses(self):
        """The method plots the calculated loss values for training and validation
        """
        plt.plot(self.train_losses, label="Training loss")
        plt.plot(self.val_losses, label="Validation loss")
        plt.legend()
        plt.title("Losses")
        plt.show()
        plt.close()
```

<br>

### 11-1 Training the model


```python
import torch.optim as optim

input_dim = len(X_train.columns)
output_dim = 1
hidden_dim = 64
layer_dim = 3
batch_size = 64
dropout = 0.2
n_epochs = 20
learning_rate = 1e-3
weight_decay = 1e-6

model_params = {'input_dim': input_dim,
                'hidden_dim' : hidden_dim,
                'layer_dim' : layer_dim,
                'output_dim' : output_dim,
                'dropout_prob' : dropout}

model = get_model('lstm', model_params)

loss_fn = nn.MSELoss(reduction="mean")
optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)


opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)
opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)
opt.plot_losses()

predictions, values = opt.evaluate(
    test_loader_one,
    batch_size=1,
    n_features=input_dim
)
```

    [1/20] Training loss: 0.0141	 Validation loss: 0.0132
    [2/20] Training loss: 0.0096	 Validation loss: 0.0109
    [3/20] Training loss: 0.0088	 Validation loss: 0.0100
    [4/20] Training loss: 0.0087	 Validation loss: 0.0109
    [5/20] Training loss: 0.0083	 Validation loss: 0.0096
    [6/20] Training loss: 0.0076	 Validation loss: 0.0099
    [7/20] Training loss: 0.0074	 Validation loss: 0.0098
    [8/20] Training loss: 0.0070	 Validation loss: 0.0099
    [9/20] Training loss: 0.0067	 Validation loss: 0.0109
    [10/20] Training loss: 0.0066	 Validation loss: 0.0101
    


    
<img src="https://user-images.githubusercontent.com/115082062/229083763-45edc8bc-6d82-4ffa-b9ad-672ebdfc1380.png">

    

<br>

### 11-2. Formating the predictions
ì´ì œ ì˜ˆì¸¡í•œ ê²°ê³¼ê°’ì„ ìŠ¤ì¼€ì¼ë§ í•˜ê¸° ì „ìœ¼ë¡œ ë˜ëŒë ¤ì•¼ í•œë‹¤. ì´ë¥¼ ìœ„í•´ `inverse_transform`ì„ ì‚¬ìš©í•œë‹¤.


```python
def inverse_transform(scaler, df, columns):
    for col in columns:
        df[col] = scaler.inverse_transform(df[col])
    return df


def format_predictions(predictions, values, df_test, scaler):
    vals = np.concatenate(values, axis=0).ravel()
    preds = np.concatenate(predictions, axis=0).ravel()
    df_result = pd.DataFrame(data={"value": vals, "prediction": preds}, index=df_test.head(len(vals)).index)
    df_result = df_result.sort_index()
    df_result = inverse_transform(scaler, df_result, [["value", "prediction"]])
    return df_result


df_result = format_predictions(predictions, values, X_test, scaler)
df_result
```





  <div id="df-83dc086f-7475-45ec-a002-91466749227b">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>value</th>
      <th>prediction</th>
    </tr>
    <tr>
      <th>Datetime</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2015-11-14 18:00:00</th>
      <td>1493.000000</td>
      <td>1586.771240</td>
    </tr>
    <tr>
      <th>2015-11-14 19:00:00</th>
      <td>1521.000000</td>
      <td>1594.307617</td>
    </tr>
    <tr>
      <th>2015-11-14 20:00:00</th>
      <td>1505.000000</td>
      <td>1593.699585</td>
    </tr>
    <tr>
      <th>2015-11-14 21:00:00</th>
      <td>1488.000000</td>
      <td>1578.892334</td>
    </tr>
    <tr>
      <th>2015-11-14 22:00:00</th>
      <td>1458.000000</td>
      <td>1546.280518</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-08-02 20:00:00</th>
      <td>1966.000000</td>
      <td>2471.009766</td>
    </tr>
    <tr>
      <th>2018-08-02 21:00:00</th>
      <td>1944.000000</td>
      <td>2393.057129</td>
    </tr>
    <tr>
      <th>2018-08-02 22:00:00</th>
      <td>1901.000122</td>
      <td>2286.193604</td>
    </tr>
    <tr>
      <th>2018-08-02 23:00:00</th>
      <td>1789.000000</td>
      <td>2138.349121</td>
    </tr>
    <tr>
      <th>2018-08-03 00:00:00</th>
      <td>1656.000000</td>
      <td>1878.640991</td>
    </tr>
  </tbody>
</table>
<p>23814 rows Ã— 2 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-83dc086f-7475-45ec-a002-91466749227b')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-83dc086f-7475-45ec-a002-91466749227b button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-83dc086f-7475-45ec-a002-91466749227b');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<br>


### 11-3. calculating error metrics

ìŠ¤ì¼€ì¼ë§í•œ ê²ƒì„ ì›ë˜ í˜•íƒœë¡œ ë°”ê¾¸ì–´ì¤€ í›„ MAE, RMSE, R^2 ë©”íŠ¸ë¦­ìœ¼ë¡œ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•´ì¤„ ê²ƒì´ë‹¤.


```python
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

def calculate_metrics(df):
    result_metrics = {'mae' : mean_absolute_error(df.value, df.prediction),
                      'rmse' : mean_squared_error(df.value, df.prediction) ** 0.5,
                      'r2' : r2_score(df.value, df.prediction)}
    
    print("Mean Absolute Error:       ", result_metrics["mae"])
    print("Root Mean Squared Error:   ", result_metrics["rmse"])
    print("R^2 Score:                 ", result_metrics["r2"])
    return result_metrics

result_metrics = calculate_metrics(df_result)
```

    Mean Absolute Error:        167.16405
    Root Mean Squared Error:    204.08217745861592
    R^2 Score:                  0.5153430919596642
    

<br>

### 11-4. Generating Baseline model
ì¼ë°˜ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ë§Œë“¤ì–´ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ë¹„êµí•´ë³´ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì´ë‹¤.


```python
from sklearn.linear_model import LinearRegression

def build_baseline_model(df, test_ratio, target_col):
    X, y = feature_label_split(df, target_col)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_ratio, shuffle=False
    )
    model = LinearRegression()
    model.fit(X_train, y_train)
    prediction = model.predict(X_test)

    result = pd.DataFrame(y_test)
    result["prediction"] = prediction
    result = result.sort_index()

    return result

df_baseline = build_baseline_model(df_features, 0.2, 'value')
baseline_metrics = calculate_metrics(df_baseline)
```

    Mean Absolute Error:        181.14435507999497
    Root Mean Squared Error:    220.20121350349825
    R^2 Score:                  0.435760267567847
    

<br>

### 11.5. Visualizing the predictions


```python
import plotly.offline as pyo
import plotly.graph_objs as go
from plotly.offline import iplot


def plot_predictions(df_result, df_baseline):
    data = []
    
    value = go.Scatter(
        x=df_result.index,
        y=df_result.value,
        mode="lines",
        name="values",
        marker=dict(),
        text=df_result.index,
        line=dict(color="rgba(0,0,0, 0.3)"),
    )
    data.append(value)

    baseline = go.Scatter(
        x=df_baseline.index,
        y=df_baseline.prediction,
        mode="lines",
        line={"dash": "dot"},
        name='linear regression',
        marker=dict(),
        text=df_baseline.index,
        opacity=0.8,
    )
    data.append(baseline)
    
    prediction = go.Scatter(
        x=df_result.index,
        y=df_result.prediction,
        mode="lines",
        line={"dash": "dot"},
        name='predictions',
        marker=dict(),
        text=df_result.index,
        opacity=0.8,
    )
    data.append(prediction)
    
    layout = dict(
        title="Predictions vs Actual Values for the dataset",
        xaxis=dict(title="Time", ticklen=5, zeroline=False),
        yaxis=dict(title="Value", ticklen=5, zeroline=False),
    )

    fig = dict(data=data, layout=layout)
    iplot(fig)
    
    
# Set notebook mode to work in offline
pyo.init_notebook_mode()

plot_predictions(df_result, df_baseline)
```


