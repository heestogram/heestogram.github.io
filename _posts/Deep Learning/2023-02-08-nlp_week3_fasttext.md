---
title: "[NLP] FastTextì™€ Word2Vec ë¹„êµ"
excerpt: "Word2Vecì™€ FastTextë¡œ ê°ê° í† í°í™”ë¥¼ í•˜ê³  ë‹¨ì–´ ìœ ì‚¬ë„ë¥¼ ë¹„êµí•´ë³´ì"
toc: true
toc_label: "ëª©ì°¨"
toc_sticky: true

tags: [Deep Learning, NLP, Word2Vec, FastText]

published: true

categories:
  - DL

date: 2023-02-08 21:00:00
last_modified_at: 2023-02-08 21:00:00
---


<br>

<div class="notice--primary" markdown="1">
ğŸ’¡ êµë‚´ í•™íšŒ NLP ë¶„ë°˜ì—ì„œ í•™ìŠµí•œ ë‚´ìš©ì„ ì •ë¦¬í•œ í¬ìŠ¤íŒ…ì…ë‹ˆë‹¤.
</div>

<br>

ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ ë§Œë“œëŠ” ë°©ë²•ì—ëŠ” Word2Vecë¥¼ ì œì™¸í•˜ê³ ë„ í˜ì´ìŠ¤ë¶ì—ì„œ ê°œë°œí•œ FastTextê°€ ìˆë‹¤. Word2VecëŠ” ë‹¨ì–´ë¥¼ ìª¼ê°œì§ˆ ìˆ˜ ì—†ëŠ” ìµœì†Œ ë‹¨ìœ„ë¡œ ë³´ëŠ” ë°˜ë©´, FastTextëŠ” í•˜ë‚˜ì˜ ë‹¨ì–´ ì•ˆì—ë„ ì—¬ëŸ¬ ë‹¨ì–´(subword)ê°€ ì¡´ì¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼í•œë‹¤.

<br>

```python
# Colabì— Mecab ì„¤ì¹˜
!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git
%cd Mecab-ko-for-Google-Colab
!bash install_mecab-ko_on_colab190912.sh
```

    Cloning into 'Mecab-ko-for-Google-Colab'...
    remote: Enumerating objects: 115, done.[K
    remote: Counting objects: 100% (24/24), done.[K
    remote: Compressing objects: 100% (20/20), done.[K
    remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91[K
    Receiving objects: 100% (115/115), 1.27 MiB | 18.07 MiB/s, done.
    Resolving deltas: 100% (50/50), done.
    /content/Mecab-ko-for-Google-Colab
    Installing konlpy.....
    Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
    Collecting konlpy
      Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m19.4/19.4 MB[0m [31m31.7 MB/s[0m eta [36m0:00:00[0m
    [?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)
    Collecting JPype1>=0.7.0
      Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m465.6/465.6 KB[0m [31m17.6 MB/s[0m eta [36m0:00:00[0m
    [?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)
    Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)
    Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)
    Installing collected packages: JPype1, konlpy
    Successfully installed JPype1-1.4.1 konlpy-0.6.0
    Done
    Installing mecab-0.996-ko-0.9.2.tar.gz.....
    Downloading mecab-0.996-ko-0.9.2.tar.gz.......
    from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
    --2023-01-27 10:15:34--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
    Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.1, 18.205.93.0, ...
    Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.
    HTTP request sent, awaiting response... 302 Found
    Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNIAS3ZMGW&Signature=0WUMbbdT48DyfImAvrTDLIk0ZtA%3D&x-amz-security-token=FwoGZXIvYXdzENz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDD4hMmDklksPMTTyziK%2BAUUD3OmgCCAFAPOqX7zWbgf%2BFp%2FZS%2Bz1uP4%2B0p5pFUcOJkaSf2U8rkITGbVSxeAiIjsB3mJJzhQu7slIHU36c4NRmH2N3YrjkgVmzaUnNxGt7bW1lxe87Nusvovea6Qn8i3cAUN3gkO0fjhbKIUwDH%2B1%2FXe0E%2FvDYo7xHIE7MoP0ztzOGCj8n%2Ft0oJ7aKfbTrGsMl74bIfHKjHz5KTjpkpUdt77a5GQc4ZEED1lcn4G%2FHbsh06TCDbXUfmxmUqMotsjOngYyLZYNUgKCavxqol4Sy9%2FFytXxC8NGheFJFzRhwlM05Bdre3Knczcl%2BQkIt6zjkg%3D%3D&Expires=1674816318 [following]
    --2023-01-27 10:15:34--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNIAS3ZMGW&Signature=0WUMbbdT48DyfImAvrTDLIk0ZtA%3D&x-amz-security-token=FwoGZXIvYXdzENz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDD4hMmDklksPMTTyziK%2BAUUD3OmgCCAFAPOqX7zWbgf%2BFp%2FZS%2Bz1uP4%2B0p5pFUcOJkaSf2U8rkITGbVSxeAiIjsB3mJJzhQu7slIHU36c4NRmH2N3YrjkgVmzaUnNxGt7bW1lxe87Nusvovea6Qn8i3cAUN3gkO0fjhbKIUwDH%2B1%2FXe0E%2FvDYo7xHIE7MoP0ztzOGCj8n%2Ft0oJ7aKfbTrGsMl74bIfHKjHz5KTjpkpUdt77a5GQc4ZEED1lcn4G%2FHbsh06TCDbXUfmxmUqMotsjOngYyLZYNUgKCavxqol4Sy9%2FFytXxC8NGheFJFzRhwlM05Bdre3Knczcl%2BQkIt6zjkg%3D%3D&Expires=1674816318
    Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.192.33, 52.216.52.209, 52.216.21.99, ...
    Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.192.33|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 1414979 (1.3M) [application/x-tar]
    Saving to: â€˜mecab-0.996-ko-0.9.2.tar.gzâ€™
    
    mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.1s    
    
    2023-01-27 10:15:34 (10.6 MB/s) - â€˜mecab-0.996-ko-0.9.2.tar.gzâ€™ saved [1414979/1414979]
    
    Done
    Unpacking mecab-0.996-ko-0.9.2.tar.gz.......
    Done
    Change Directory to mecab-0.996-ko-0.9.2.......
    installing mecab-0.996-ko-0.9.2.tar.gz........
    configure
    make
    make check
    make install
    ldconfig
    Done
    Change Directory to /content
    Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......
    from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
    --2023-01-27 10:17:37--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
    Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.1, 18.205.93.2, ...
    Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.
    HTTP request sent, awaiting response... 302 Found
    Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNK4SIQU6I&Signature=1jG1BiE8GwyaC7KNybHLzRPX3dM%3D&x-amz-security-token=FwoGZXIvYXdzENz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDKnCJyrwF6mc29OJqSK%2BAbdOfQhkWa1uu3r2GI9cxBqLNKkrkc05K68f0MSxveMc5p01qX685HDcIl7%2FCty5a46840zh7oaND1UEo%2FjrT%2BRiQTyFbDwlQvfwaqyxvduhAIA1OhhtAQA%2F6nHxN0Ub7s0e%2B6pAOBrrx6vHWGpItmHTEEDm0lF9wtqZsd%2BPzbeseQeUwkwmZ4CE1ZIZNG5RiT2qieeKFsONUPysD%2F%2BGxCH3xxreGm7eqzLGG66%2FwefIMmKn%2BzXwVQoH0KujiSMorcnOngYyLQDyLEgg2uVbjyw0eb1lYQX%2Bo3JavpYn5ucsBil9FcoEim%2FMUx3QWKB9GEsPlg%3D%3D&Expires=1674816437 [following]
    --2023-01-27 10:17:37--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNK4SIQU6I&Signature=1jG1BiE8GwyaC7KNybHLzRPX3dM%3D&x-amz-security-token=FwoGZXIvYXdzENz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDKnCJyrwF6mc29OJqSK%2BAbdOfQhkWa1uu3r2GI9cxBqLNKkrkc05K68f0MSxveMc5p01qX685HDcIl7%2FCty5a46840zh7oaND1UEo%2FjrT%2BRiQTyFbDwlQvfwaqyxvduhAIA1OhhtAQA%2F6nHxN0Ub7s0e%2B6pAOBrrx6vHWGpItmHTEEDm0lF9wtqZsd%2BPzbeseQeUwkwmZ4CE1ZIZNG5RiT2qieeKFsONUPysD%2F%2BGxCH3xxreGm7eqzLGG66%2FwefIMmKn%2BzXwVQoH0KujiSMorcnOngYyLQDyLEgg2uVbjyw0eb1lYQX%2Bo3JavpYn5ucsBil9FcoEim%2FMUx3QWKB9GEsPlg%3D%3D&Expires=1674816437
    Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 3.5.29.124, 52.216.52.153, 52.217.72.68, ...
    Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|3.5.29.124|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 49775061 (47M) [application/x-tar]
    Saving to: â€˜mecab-ko-dic-2.1.1-20180720.tar.gzâ€™
    
    mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   103MB/s    in 0.5s    
    
    2023-01-27 10:17:38 (103 MB/s) - â€˜mecab-ko-dic-2.1.1-20180720.tar.gzâ€™ saved [49775061/49775061]
    
    Done
    Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......
    Done
    Change Directory to mecab-ko-dic-2.1.1-20180720
    Done
    installing........
    configure
    make
    make install
    apt-get update
    apt-get upgrade
    apt install curl
    apt install git
    bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)
    Done
    Successfully Installed
    Now you can use Mecab
    from konlpy.tag import Mecab
    mecab = Mecab()
    ì‚¬ìš©ì ì‚¬ì „ ì¶”ê°€ ë°©ë²• : https://bit.ly/3k0ZH53
    NameError: name 'Tagger' is not defined ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŸ°íƒ€ì„ì„ ì¬ì‹¤í–‰ í•´ì£¼ì„¸ìš”
    ë¸”ë¡œê·¸ì— í•´ê²° ë°©ë²•ì„ ë‚¨ê²¨ì£¼ì‹  tanaë‹˜ ê°ì‚¬í•©ë‹ˆë‹¤.
    


```python
from konlpy.tag import Mecab
mecab = Mecab()
```


```python
# í•œê¸€ ìëª¨ ë‹¨ìœ„ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜
!pip install hgtk
```

    Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
    Collecting hgtk
      Downloading hgtk-0.1.3.tar.gz (6.2 kB)
      Preparing metadata (setup.py) ... [?25l[?25hdone
    Building wheels for collected packages: hgtk
      Building wheel for hgtk (setup.py) ... [?25l[?25hdone
      Created wheel for hgtk: filename=hgtk-0.1.3-py2.py3-none-any.whl size=6688 sha256=ccb728f3e9ec15bf590a90a00872c21a0b6d03e6fd313964f1798f63864a7ce7
      Stored in directory: /root/.cache/pip/wheels/93/33/b8/bc2256172a415340e34f3c11ef2b0f3f391769000bb74de988
    Successfully built hgtk
    Installing collected packages: hgtk
    Successfully installed hgtk-0.1.3
    


```python
# fasttext ì„¤ì¹˜
!git clone https://github.com/facebookresearch/fastText.git
%cd fastText
!make
!pip install .
```

    Cloning into 'fastText'...
    remote: Enumerating objects: 3930, done.[K
    remote: Counting objects: 100% (944/944), done.[K
    remote: Compressing objects: 100% (140/140), done.[K
    remote: Total 3930 (delta 854), reused 804 (delta 804), pack-reused 2986[K
    Receiving objects: 100% (3930/3930), 8.24 MiB | 15.81 MiB/s, done.
    Resolving deltas: 100% (2505/2505), done.
    /content/Mecab-ko-for-Google-Colab/fastText
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc
    c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext
    Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
    Processing /content/Mecab-ko-for-Google-Colab/fastText
      Preparing metadata (setup.py) ... [?25l[?25hdone
    Collecting pybind11>=2.2
      Using cached pybind11-2.10.3-py3-none-any.whl (222 kB)
    Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext==0.9.2) (57.4.0)
    Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext==0.9.2) (1.21.6)
    Building wheels for collected packages: fasttext
      Building wheel for fasttext (setup.py) ... [?25l[?25hdone
      Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=4393595 sha256=56a469331166df0f3d88aab254d9b878cc8a896582e6b59875992128e70d2470
      Stored in directory: /tmp/pip-ephem-wheel-cache-o2baqkp6/wheels/3b/a9/65/8f58628dd4d195a5073adc57ce4877b6a22bd3fab7047c6984
    Successfully built fasttext
    Installing collected packages: pybind11, fasttext
    Successfully installed fasttext-0.9.2 pybind11-2.10.3
    

<br>

## 1. ë°ì´í„° ë¡œë“œ


```python
import re
import pandas as pd
import urllib.request
from tqdm import tqdm
import hgtk
```


```python
# ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·°
urllib.request.urlretrieve("https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt", filename="ratings_total.txt")
```




    ('ratings_total.txt', <http.client.HTTPMessage at 0x7f39131fd9a0>)




```python
total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])
print('ì „ì²´ ë¦¬ë·° ê°œìˆ˜ :',len(total_data)) # ì „ì²´ ë¦¬ë·° ê°œìˆ˜ ì¶œë ¥
```

    ì „ì²´ ë¦¬ë·° ê°œìˆ˜ : 200000
    


```python
total_data.head()
```





  <div id="df-76a82664-bee2-4748-9a74-c100e7148340">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ratings</th>
      <th>reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>ë°°ê³µë¹ ë¥´ê³  êµ¿</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>íƒë°°ê°€ ì—‰ë§ì´ë„¤ìš© ì €í¬ì§‘ ë°‘ì—ì¸µì— ë§ë„ì—†ì´ ë†”ë‘ê³ ê°€ê³ </td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>ì•„ì£¼ì¢‹ì•„ìš” ë°”ì§€ ì •ë§ ì¢‹ì•„ì„œ2ê°œ ë” êµ¬ë§¤í–ˆì–´ìš” ì´ê°€ê²©ì— ëŒ€ë°•ì…ë‹ˆë‹¤. ë°”ëŠì§ˆì´ ì¡°ê¸ˆ ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>ì„ ë¬¼ìš©ìœ¼ë¡œ ë¹¨ë¦¬ ë°›ì•„ì„œ ì „ë‹¬í–ˆì–´ì•¼ í•˜ëŠ” ìƒí’ˆì´ì—ˆëŠ”ë° ë¨¸ê·¸ì»µë§Œ ì™€ì„œ ë‹¹í™©í–ˆìŠµë‹ˆë‹¤. ì „...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>ë¯¼íŠ¸ìƒ‰ìƒ ì˜ˆë»ìš”. ì˜† ì†ì¡ì´ëŠ” ê±°ëŠ” ìš©ë„ë¡œë„ ì‚¬ìš©ë˜ë„¤ìš” ã…ã…</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-76a82664-bee2-4748-9a74-c100e7148340')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-76a82664-bee2-4748-9a74-c100e7148340 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-76a82664-bee2-4748-9a74-c100e7148340');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>


<br>


## 2. hgtk íŠœí† ë¦¬ì–¼

word embeddingì´ ë‹¨ì–´ ë‹¨ìœ„ì˜ ì„ë² ë”©ì´ì—ˆë‹¤ë©´, character embeddingì€ ë¬¸ì ë‹¨ìœ„ì˜ ì„ë² ë”©ì´ë‹¤. í•œêµ­ì–´ë¥¼ character embeddingí•  ìˆ˜ ìˆëŠ” ê²ƒì´ ë°”ë¡œ ììŒ ëª¨ìŒ ë¶„ë¦¬ê¸° hgtkì´ë‹¤.

 ì˜ì–´ëŠ” í•˜ë‚˜ì˜ ì•ŒíŒŒë²³(52ì)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ character embeddingì„ í•˜ì§€ë§Œ, í•œêµ­ì–´ì—ì„œ í•˜ë‚˜ì˜ ìŒì ˆë³„ë¡œ character embeddingì„ í•˜ë©´ 11172ê°œì˜ ìŒì ˆì´ ìˆê¸° ë•Œë¬¸ì— ê³„ì‚°ëŸ‰ì´ ë„ˆë¬´ ë§ë‹¤. ê·¸ë˜ì„œ ê·¸ë³´ë‹¤ ì‘ì€ ë‹¨ìœ„ì¸ ììŒ ëª¨ìŒìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ë‹¤.


```python
# í•œê¸€ì¸ì§€ ì²´í¬
print(hgtk.checker.is_hangul('ã„±'))
print(hgtk.checker.is_hangul('12'))
print(hgtk.checker.is_hangul('a'))
```

    True
    False
    False
    


```python
# ìŒì ˆì„ ì´ˆì„±, ì¤‘ì„±, ì¢…ì„±ìœ¼ë¡œ ë¶„í•´
print(hgtk.letter.decompose('ë‚¨'))
# ì´ˆì„±, ì¤‘ì„±, ì¢…ì„±ì„ í•˜ë‚˜ì˜ ìŒì ˆë¡œ ê²°í•©
print(hgtk.letter.compose('ã„´', 'ã…', 'ã…'))
```

    ('ã„´', 'ã…', 'ã…')
    ë‚¨
    


```python
# ê²°í•©í•  ìˆ˜ ì—†ëŠ” ìƒí™©ì—ì„œëŠ” ì—ëŸ¬ ë°œìƒ
try:
  hgtk.letter.compose('ã„´', 'ã…', 'ã…') # ì¤‘ì„±ì´ ì—†ëŠ” ê²½ìš°
except:
  print('ì—ëŸ¬ ë°œìƒ')
```

    ì—ëŸ¬ ë°œìƒ
    

<br>

## 3. ë°ì´í„° ì „ì²˜ë¦¬

fasttextëŠ” subword ë‹¨ìœ„ë¡œ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•˜ëŠ” ë„êµ¬ì´ë‹¤. í•œêµ­ì–´ì—ì„œ subwordëŠ” ììŒ ëª¨ìŒ ë‹¨ìœ„ë¡œ ìƒê°í•  ìˆ˜ ìˆë‹¤. fasttextì— í•™ìŠµì‹œí‚¬ ë°ì´í„°ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì•ì„œ ë¡œë“œí•œ ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·°ë“¤ì„ hgtkë¥¼ í™œìš©í•´ ììŒ ëª¨ìŒ ë‹¨ìœ„ë¡œ ì „ì²˜ë¦¬í•´ì¤„ ê²ƒì´ë‹¤.


```python
def word_to_jamo(token):
  def to_special_token(jamo): # ê²½ìš°ì— ë”°ë¼ ì´ˆ, ì¤‘, ì¢…ì„±ì´ ë‹¤ ìˆëŠ” ê²Œ ì•„ë‹Œ ê²½ìš°ë„ ìˆë‹¤. ì´ ê²½ìš° -ë¥¼ ë°˜í™˜í•´ì£¼ëŠ” í•¨ìˆ˜
    if not jamo:
      return '-'
    else:
      return jamo

  decomposed_token = ''
  for char in token:
    try:
      # char(ìŒì ˆ)ì„ ì´ˆì„±, ì¤‘ì„±, ì¢…ì„±ìœ¼ë¡œ ë¶„ë¦¬
      cho, jung, jong = hgtk.letter.decompose(char)

      # ìëª¨ê°€ ë¹ˆ ë¬¸ìì¼ ê²½ìš° íŠ¹ìˆ˜ë¬¸ì -ë¡œ ëŒ€ì²´
      cho = to_special_token(cho)
      jung = to_special_token(jung)
      jong = to_special_token(jong)
      decomposed_token = decomposed_token + cho + jung + jong

    # ë§Œì•½ char(ìŒì ˆ)ì´ í•œê¸€ì´ ì•„ë‹ ê²½ìš° ìëª¨ë¥¼ ë‚˜ëˆ„ì§€ ì•Šê³  ì¶”ê°€
    except Exception as exception:
      if type(exception).__name__ == 'NotHangulException':
        decomposed_token += char
    
  # ë‹¨ì–´ í† í°ì˜ ìëª¨ ë‹¨ìœ„ ë¶„ë¦¬ ê²°ê³¼ë¥¼ ì¶”ê°€
  return decomposed_token
```


```python
print(word_to_jamo('ë‚¨ë™ìƒ'))
print(word_to_jamo('ì•¼êµ¬')) # ì•¼êµ¬ì˜ ê²½ìš° ì¢…ì„±ì´ ì—†ìœ¼ë¯€ë¡œ ì¢…ì„± ë¶€ë¶„ì„ -ë¡œ ë°˜í™˜
```

    ã„´ã…ã…ã„·ã…—ã…‡ã……ã…ã…‡
    ã…‡ã…‘-ã„±ã…œ-
    


```python
print(mecab.morphs('ì„ ë¬¼ìš©ìœ¼ë¡œ ë¹¨ë¦¬ ë°›ì•„ì„œ ì „ë‹¬í–ˆì–´ì•¼ í•˜ëŠ” ìƒí’ˆì´ì—ˆëŠ”ë° ë¨¸ê·¸ì»µë§Œ ì™€ì„œ ë‹¹í™©í–ˆìŠµë‹ˆë‹¤.'))
```

    ['ì„ ë¬¼', 'ìš©', 'ìœ¼ë¡œ', 'ë¹¨ë¦¬', 'ë°›', 'ì•„ì„œ', 'ì „ë‹¬', 'í–ˆì–´ì•¼', 'í•˜', 'ëŠ”', 'ìƒí’ˆ', 'ì´', 'ì—ˆ', 'ëŠ”ë°', 'ë¨¸ê·¸', 'ì»µ', 'ë§Œ', 'ì™€ì„œ', 'ë‹¹í™©', 'í–ˆ', 'ìŠµë‹ˆë‹¤', '.']
    


```python
# mecabìœ¼ë¡œ í˜•íƒœì†Œë¥¼ ë¶„ë¦¬í•´ì£¼ê³  ê·¸ í˜•íƒœì†Œë§ˆë‹¤ ê°ê° ììŒëª¨ìŒì„ ë¶„ë¦¬í•´ì£¼ëŠ” í•¨ìˆ˜
def tokenize_by_jamo(s):
    return [word_to_jamo(token) for token in mecab.morphs(s)]
```


```python
print(tokenize_by_jamo('ì„ ë¬¼ìš©ìœ¼ë¡œ ë¹¨ë¦¬ ë°›ì•„ì„œ ì „ë‹¬í–ˆì–´ì•¼ í•˜ëŠ” ìƒí’ˆì´ì—ˆëŠ”ë° ë¨¸ê·¸ì»µë§Œ ì™€ì„œ ë‹¹í™©í–ˆìŠµë‹ˆë‹¤.'))
```

    ['ã……ã…“ã„´ã…ã…œã„¹', 'ã…‡ã…›ã…‡', 'ã…‡ã…¡-ã„¹ã…—-', 'ã…ƒã…ã„¹ã„¹ã…£-', 'ã…‚ã…ã„·', 'ã…‡ã…-ã……ã…“-', 'ã…ˆã…“ã„´ã„·ã…ã„¹', 'ã…ã…ã…†ã…‡ã…“-ã…‡ã…‘-', 'ã…ã…-', 'ã„´ã…¡ã„´', 'ã……ã…ã…‡ã…ã…œã…', 'ã…‡ã…£-', 'ã…‡ã…“ã…†', 'ã„´ã…¡ã„´ã„·ã…”-', 'ã…ã…“-ã„±ã…¡-', 'ã…‹ã…“ã…‚', 'ã…ã…ã„´', 'ã…‡ã…˜-ã……ã…“-', 'ã„·ã…ã…‡ã…ã…˜ã…‡', 'ã…ã…ã…†', 'ã……ã…¡ã…‚ã„´ã…£-ã„·ã…-', '.']
    


```python
# ë¦¬ë·° ë°ì´í„°ì˜ reviews ì»¬ëŸ¼ë§Œì„ ê°€ì ¸ì™€ì„œ ìëª¨ ë¶„ë¦¬
tokenized_data = []

for sample in tqdm(total_data['reviews'].to_numpy()):
    tokenzied_sample = tokenize_by_jamo(sample) # ìì†Œ ë‹¨ìœ„ í† í°í™”
    tokenized_data.append(tokenzied_sample)
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200000/200000 [01:14<00:00, 2686.42it/s]
    


```python
print(len(tokenized_data))
print("ì „ì²˜ë¦¬ ì „:", total_data['reviews'][1])
print("ì „ì²˜ë¦¬ í›„:", tokenized_data[1])
```

    200000
    ì „ì²˜ë¦¬ ì „: íƒë°°ê°€ ì—‰ë§ì´ë„¤ìš© ì €í¬ì§‘ ë°‘ì—ì¸µì— ë§ë„ì—†ì´ ë†”ë‘ê³ ê°€ê³ 
    ì „ì²˜ë¦¬ í›„: ['ã…Œã…ã„±ã…‚ã…-', 'ã„±ã…-', 'ã…‡ã…“ã…‡ã…ã…ã…‡', 'ã…‡ã…£-', 'ã„´ã…”-', 'ã…‡ã…›ã…‡', 'ã…ˆã…“-ã…ã…¢-', 'ã…ˆã…£ã…‚', 'ã…ã…£ã…Œ', 'ã…‡ã…”-', 'ã…Šã…¡ã…‡', 'ã…‡ã…”-', 'ã…ã…ã„¹', 'ã„·ã…—-', 'ã…‡ã…“ã…„ã…‡ã…£-', 'ã„´ã…˜-ã„·ã…œ-', 'ã„±ã…—-', 'ã„±ã…-', 'ã„±ã…—-']
    

ë‹¨ì–´ë¥¼ ìëª¨ ë¶„ë¦¬í•œ ê²ƒì„ ì—­ìœ¼ë¡œ í•˜ì—¬ ìëª¨ ìƒíƒœë¥¼ ë‹¨ì–´ë¡œ ë‹¤ì‹œ ê²°í•©ì‹œí‚¤ëŠ” í•¨ìˆ˜ë„ ì •ì˜í•  ê²ƒì´ë‹¤. ì´ëŠ” ë‹¨ì–´ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ í‰ê°€í•  ë•Œ ìëª¨ ë¶„ë¦¬ê°€ ëœ ìƒíƒœê°€ ì•„ë‹ˆë¼ ë‹¨ì–´ ìƒíƒœë¡œ í¸ë¦¬í•˜ê²Œ ë³´ê¸° ìœ„í•¨ì´ë‹¤.


```python
def jamo_to_word(jamo_sequence):
  tokenized_jamo = []
  index = 0
  
  # 1. ì´ˆê¸° ì…ë ¥
  # jamo_sequence = 'ã„´ã…ã…ã„·ã…—ã…‡ã……ã…ã…‡'

  while index < len(jamo_sequence):
    # ë¬¸ìê°€ í•œê¸€(ì •ìƒì ì¸ ìëª¨)ì´ ì•„ë‹ ê²½ìš°
    if not hgtk.checker.is_hangul(jamo_sequence[index]):
      tokenized_jamo.append(jamo_sequence[index])
      index = index + 1

    # ë¬¸ìê°€ ì •ìƒì ì¸ ìëª¨ë¼ë©´ ì´ˆì„±, ì¤‘ì„±, ì¢…ì„±ì„ í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ê°„ì£¼.
    else:
      tokenized_jamo.append(jamo_sequence[index:index + 3])
      index = index + 3

  # 2. ìëª¨ ë‹¨ìœ„ í† í°í™” ì™„ë£Œ
  # tokenized_jamo : ['ã„´ã…ã…', 'ã„·ã…—ã…‡', 'ã……ã…ã…‡']
  
  word = ''
  try:
    for jamo in tokenized_jamo:

      # ì´ˆì„±, ì¤‘ì„±, ì¢…ì„±ì˜ ë¬¶ìŒìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ê²½ìš°
      if len(jamo) == 3:
        if jamo[2] == "-":
          # ì¢…ì„±ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
          word = word + hgtk.letter.compose(jamo[0], jamo[1])
        else:
          # ì¢…ì„±ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°
          word = word + hgtk.letter.compose(jamo[0], jamo[1], jamo[2])
      # í•œê¸€ì´ ì•„ë‹Œ ê²½ìš°
      else:
        word = word + jamo

  # ë³µì› ì¤‘(hgtk.letter.compose) ì—ëŸ¬ ë°œìƒ ì‹œ ì´ˆê¸° ì…ë ¥ ë¦¬í„´.
  # ë³µì›ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ì˜ˆì‹œ) 'ã„´!ã…ã„·ã…—ã…‡ã……ã…ã…‡'
  except Exception as exception:  
    if type(exception).__name__ == 'NotHangulException':
      return jamo_sequence

  # 3. ë‹¨ì–´ë¡œ ë³µì› ì™„ë£Œ
  # word : 'ë‚¨ë™ìƒ'

  return word
```

<br>

## 4. FastText


```python
import fasttext
```

fasttextë¥¼ ì‹¤í–‰í•˜ê¸°ì— ì•ì„œ í›ˆë ¨ ëŒ€ìƒì¸ ë‹¨ì–´ë“¤ì„ txt íŒŒì¼ë¡œ ì¤€ë¹„í•´ë‘¬ì•¼ í•œë‹¤. ë”°ë¼ì„œ `tokenized_data.txt`ë¼ëŠ” íŒŒì¼ì„ ì“°ê¸° ëª¨ë“œ(w)ë¡œ ìƒì„±í•´ì£¼ê³  ì•ì„œ ì „ì²˜ë¦¬í•œ `tokenized_data`ë¥¼ ì…ë ¥í•´ì¤€ë‹¤.


```python
with open('tokenized_data.txt', 'w') as out:
  for line in tqdm(tokenized_data, unit=' line'):
    out.write(' '.join(line) + '\n')
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200000/200000 [00:00<00:00, 286973.78 line/s]
    

ì•„ë˜ì²˜ëŸ¼ í›ˆë ¨í•  ë‹¨ì–´ê°€ ë‹´ê¸´ txt íŒŒì¼ì„ ì§€ì •í•˜ê³  modelì„ `cbow`ë‚˜ `skipgram` ì¤‘ì— í•˜ë‚˜ë¥¼ ê³ ë¥´ë©´ ëœë‹¤.


```python
model = fasttext.train_unsupervised('tokenized_data.txt', model='cbow')
```


```python
model.save_model("fasttext.bin")
```


```python
model = fasttext.load_model("fasttext.bin")
```


```python
model[word_to_jamo('ë‚¨ë™ìƒ')] # 'ã„´ã…ã…ã„·ã…—ã…‡ã……ã…ã…‡'
```




    array([-0.15177222, -0.74635   , -0.8032616 ,  0.19086838, -0.778221  ,
           -0.33223176, -0.11894439, -0.72866446,  0.37754712,  0.33814308,
            0.36616278, -0.49859792,  0.15212303, -0.787831  , -0.25276604,
           -0.10590696, -0.02901313, -0.19102712, -0.40464807,  0.37677866,
            0.37623113, -0.44016936, -0.6346251 , -0.4784998 ,  0.36894986,
            0.06783067, -0.20056958,  0.85232157,  0.9760077 , -0.20355019,
            0.46145713,  0.00457911,  0.66409916, -0.60430694, -0.45035866,
            0.5918075 , -1.1969922 , -0.2010963 , -0.36899805,  0.02050064,
           -0.14902137,  0.41190356, -0.09631964,  0.123348  , -0.19831082,
           -0.9359135 , -0.20674314, -0.48348927, -0.09120885,  0.1754866 ,
            0.4776521 ,  0.7623648 , -0.07341626,  0.18894948,  0.5302282 ,
            0.7917357 ,  0.48697317, -0.05473014,  0.34746835, -0.3974606 ,
           -0.86817527,  0.01599673,  1.035565  ,  0.56748825,  0.405412  ,
            0.35544434, -0.4864636 ,  0.05915926, -0.34068304,  0.39836073,
           -0.52921456, -0.3147612 , -0.2996531 , -0.7403795 ,  0.2946075 ,
            0.7669133 ,  0.6944267 , -0.2107564 , -0.48978466,  0.20623395,
            1.4869727 , -0.6125487 ,  0.5904486 ,  0.17088331,  0.34967554,
            0.17796417, -0.3819747 , -0.66418344,  0.41854003,  0.6213065 ,
           -0.8461816 , -0.30119175, -0.42944723,  0.9458985 ,  0.36967832,
            0.25508663, -0.76534146,  0.03767111,  1.6508778 , -0.7287428 ],
          dtype=float32)



'ë‚¨ë™ìƒ'ì´ë¼ëŠ” ë‹¨ì–´ì™€ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ë‹¨ì–´ë“¤(ìëª¨ ë¶„ë¦¬ëœ ìƒíƒœ)ì„ kê°œë§Œí¼ ì¶œë ¥í•´ì¤€ë‹¤.


```python
model.get_nearest_neighbors(word_to_jamo('ë‚¨ë™ìƒ'), k=10)
```




    [(0.8813450932502747, 'ã„·ã…—ã…‡ã……ã…ã…‡'),
     (0.8390687108039856, 'ã„´ã…ã…ã…Šã…£ã„´'),
     (0.7702850103378296, 'ã……ã…ã…‡ã…‡ã…£ã„¹'),
     (0.752815306186676, 'ã„´ã…ã…ã…‡ã…-'),
     (0.7487542629241943, 'ã…Šã…£ã„´ã„±ã…œ-'),
     (0.7453957200050354, 'ã„´ã…ã…ã…ã…•ã„´'),
     (0.7136173248291016, 'ã…ˆã…—-ã…‹ã…-'),
     (0.7125541567802429, 'ã…‡ã…“ã„´ã„´ã…£-'),
     (0.7080659866333008, 'ã„´ã…ã„´ã……ã…ã…‡'),
     (0.7055453658103943, 'ã„´ã…ã…ã…ˆã…-')]



ì•ì„œ ë§Œë“  `jamo_to_word`ë¡œ ê°€ë…ì„±ì´ ì¢‹ê²Œ ì¶œë ¥í•œë‹¤.


```python
def transform(word_sequence):
  return [(jamo_to_word(word), similarity) for (similarity, word) in word_sequence]
```


```python
print(transform(model.get_nearest_neighbors(word_to_jamo('ë‚¨ë™ìƒ'), k=10)))
print(transform(model.get_nearest_neighbors(word_to_jamo('êµ¬ë§¤'), k=10)))
print(transform(model.get_nearest_neighbors(word_to_jamo('ë°°ë‹¬'), k=10)))
```

    [('ë™ìƒ', 0.8813450932502747), ('ë‚¨ì¹œ', 0.8390687108039856), ('ìƒì¼', 0.7702850103378296), ('ë‚¨ì•„', 0.752815306186676), ('ì¹œêµ¬', 0.7487542629241943), ('ë‚¨í¸', 0.7453957200050354), ('ì¡°ì¹´', 0.7136173248291016), ('ì–¸ë‹ˆ', 0.7125541567802429), ('ë‚œìƒ', 0.7080659866333008), ('ë‚¨ì', 0.7055453658103943)]
    [('êµ¬ë§¤ì²˜', 0.8525390028953552), ('êµ¬ì…', 0.8198325037956238), ('ì£¼ë¬¸', 0.7629261016845703), ('ì£¼ë¬¸ê±´', 0.6979227066040039), ('ì£¼ë¬¸ì„œ', 0.6397473216056824), ('êµ¬ë§¤ì', 0.6206300854682922), ('êµ¬ë©”', 0.6068757772445679), ('êµ¬í† ', 0.6061024069786072), ('ì´ìš©', 0.5840553641319275), ('ì¬ì…', 0.5768207311630249)]
    [('ë°°ì†¡ì§€', 0.8438760042190552), ('ê¹¨ë‹¬', 0.7850202322006226), ('ë§¤ë‹¬', 0.7729867100715637), ('ë©”ë‹¬', 0.7509331107139587), ('ë°±ë°°', 0.7500661015510559), ('íƒë°°', 0.7392227053642273), ('ì†¡ì¥', 0.7373930811882019), ('ë°°ê³µ', 0.7373281121253967), ('ê³µì§€', 0.7181926369667053), ('ìš´ì†¡ì¥', 0.7179238200187683)]
    

<br>

## 5. Word2Vec
ì´ì œ word2vecë¥¼ ì‚¬ìš©í•˜ì—¬ ìëª¨ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•´ë³¼ ê²ƒì´ë‹¤.


```python
# ë¶ˆìš©ì–´ ì •ì˜
stopwords = ['ì˜','ê°€','ì´','ì€','ë“¤','ëŠ”','ì¢€','ì˜','ê±','ê³¼','ë„','ë¥¼','ìœ¼ë¡œ','ì','ì—','ì™€','í•œ','í•˜ë‹¤']

tokenized_data2 = []
for sentence in tqdm(total_data['reviews'].to_list()):
    tokenized_sentence = mecab.morphs(sentence) # í† í°í™”
    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # ë¶ˆìš©ì–´ ì œê±°
    tokenized_data2.append(stopwords_removed_sentence)
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200000/200000 [01:09<00:00, 2871.90it/s]
    


```python
print("fasttextìš© ë°ì´í„°:", tokenized_data2[0])
print("word2vecìš© ë°ì´í„°:", tokenized_data[0])
```

    fasttextìš© ë°ì´í„°: ['ë°°ê³µ', 'ë¹ ë¥´', 'ê³ ', 'êµ¿']
    word2vecìš© ë°ì´í„°: ['ã…‚ã…-ã„±ã…—ã…‡', 'ã…ƒã…-ã„¹ã…¡-', 'ã„±ã…—-', 'ã„±ã…œã……']
    


```python
from gensim.models import Word2Vec

model2 = Word2Vec(sentences = tokenized_data2, size = 1000, window = 5, min_count = 5, workers = 4, sg = 0)
```


```python
# ì™„ì„±ëœ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ì˜ í¬ê¸° í™•ì¸
# ë‹¨ì–´ì˜ ì´ ê°œìˆ˜ëŠ” 14959ê°œì´ê³  ë²¡í„° ì°¨ì›ì€ 1000ìœ¼ë¡œ ì¶•ì†Œë˜ì—ˆë‹¤.
model2.wv.vectors.shape
```




    (14959, 1000)


<br>

## 6. FastTextì™€ Word2Vec ê²°ê³¼ ë¹„êµ


```python
print("FastText ìœ ì‚¬ë„:", transform(model.get_nearest_neighbors(word_to_jamo('ë‚¨ë™ìƒ'), k=10)))
print("Word2Vec ìœ ì‚¬ë„:", model2.wv.most_similar("ë‚¨ë™ìƒ"))
```

    FastText ìœ ì‚¬ë„: [('ë™ìƒ', 0.8813450932502747), ('ë‚¨ì¹œ', 0.8390687108039856), ('ìƒì¼', 0.7702850103378296), ('ë‚¨ì•„', 0.752815306186676), ('ì¹œêµ¬', 0.7487542629241943), ('ë‚¨í¸', 0.7453957200050354), ('ì¡°ì¹´', 0.7136173248291016), ('ì–¸ë‹ˆ', 0.7125541567802429), ('ë‚œìƒ', 0.7080659866333008), ('ë‚¨ì', 0.7055453658103943)]
    Word2Vec ìœ ì‚¬ë„: [('ì¹œí•œ', 0.7148764729499817), ('ì—„ë‹ˆ', 0.7146899700164795), ('í¸ì°®', 0.7134093642234802), ('ë˜ë¯¸', 0.7106471061706543), ('ì–´ë¦°ì´ë‚ ', 0.6990622282028198), ('ì…í•™', 0.6911965608596802), ('ì¹œì •', 0.6903277039527893), ('ê¸°ë…ì¼', 0.6902635097503662), ('ê°œì—…', 0.6821399927139282), ('ì‚¬ì¶˜ê¸°', 0.6806015968322754)]
    


```python
print("FastText ìœ ì‚¬ë„:", transform(model.get_nearest_neighbors(word_to_jamo('ì£¼ë¬¸'), k=10)))
print("Word2Vec ìœ ì‚¬ë„:", model2.wv.most_similar("ì£¼ë¬¸"))
```

    FastText ìœ ì‚¬ë„: [('ì£¼ë¬¸ê±´', 0.9059317708015442), ('ì£¼ë¬¸ì„œ', 0.8423793315887451), ('êµ¬ì…', 0.7743308544158936), ('êµ¬ë§¤', 0.7629262208938599), ('ì£¼ë¬¸ì', 0.7511577606201172), ('ì£¼ë¬´ì‹œ', 0.71355140209198), ('ì£¼ë¬´', 0.6975243091583252), ('êµ¬ë§¤ì²˜', 0.6918202638626099), ('ì‹œì¼°ì—ˆ', 0.6846689581871033), ('ì‹œí‚¨', 0.6711220741271973)]
    Word2Vec ìœ ì‚¬ë„: [('êµ¬ë§¤', 0.827530026435852), ('êµ¬ì…', 0.8101752996444702), ('ì„ íƒ', 0.634414792060852), ('ê²°ì œ', 0.5618018507957458), ('ì‹œì¼°', 0.5513455867767334), ('ì¤€ë¹„', 0.5279896259307861), ('ì‹œí‚¨', 0.5216350555419922), ('ë„ì „', 0.5213436484336853), ('ë„ì°©', 0.5197646617889404), ('ì‹ ì²­', 0.5068678855895996)]
    

FastTextë¡œ ê³„ì‚°ëœ ìœ ì‚¬ë„ë¥¼ ë³´ë©´ Word2Vecì— ë¹„í•´ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ë³´ì—¬ì¤Œê³¼ ë™ì‹œì— ì˜ë¯¸ì™€ í˜•íƒœë„ ë”ìš± ê·¼ì ‘í•´ìˆëŠ” ê²ƒì„ ì²´ê°í•  ìˆ˜ ìˆë‹¤.

ë˜í•œ FastTextê°€ ì¡°ê¸ˆ ë” ë‹¨ì–´ì˜ ìƒê¹€ìƒˆì— ì£¼ëª©í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì²´ê°ëœë‹¤. ì˜ˆì»¨ëŒ€ Word2VecëŠ” 'ì£¼ë¬¸'ì´ë¼ëŠ” ë‹¨ì–´ì— ëŒ€í•´ 'êµ¬ì…', 'ì´ìš©', 'ì„ íƒ' ë“± ìƒê¹€ìƒˆì— ì°¨ì´ê°€ ìˆëŠ” ë‹¤ì–´ë“¤ë„ ìœ ì‚¬í•œ ê²ƒìœ¼ë¡œ ì¶œë ¥í•œ ë°˜ë©´, FastTextëŠ” 'ì£¼ë¬¸ê±´', 'ì£¼ë¬¸ì„œ', 'ì£¼ë¬´ì‹œ' ë“± ìƒê¹€ìƒˆê°€ ë‹®ì•„ìˆëŠ” ë‹¨ì–´ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ì¶œë ¥í•˜ê³  ìˆë‹¤. ë¬¼ë¡  ëŒ€ë¶€ë¶„ ì˜ë¯¸ì ìœ¼ë¡œë„ ë§ë‹¿ì•„ìˆëŠ” ë‹¨ì–´ë“¤ì„ ì˜ ì¶œë ¥í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.

í•´ë‹¹ ë°ì´í„°ì…‹ë§Œì„ ë†“ê³ ë³´ì•˜ì„ ë•ŒëŠ” FastTextì˜ ì„±ëŠ¥ì´ ë³´ë‹¤ ë‚˜ì€ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.
