---
title: "[DL] GRUë¡œ ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° ê°ì„±ë¶„ë¥˜"
excerpt: "kerasì˜ GRUë¥¼ ì´ìš©í•˜ì—¬ ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·°ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ê°ì„± ë¶„ë¥˜ë¥¼ í•´ë³´ì"
toc: true
toc_label: "ëª©ì°¨"
toc_sticky: true

tags: [Deep Learning, RNN, LSTM, GRU, ì‹œê³„ì—´, keras]

published: true

categories:
  - DL

date: 2023-02-15 21:00:00
last_modified_at: 2023-02-15 21:00:00
---


<br>

<div class="notice--primary" markdown="1">
ğŸ’¡ êµë‚´ í•™íšŒ NLP ë¶„ë°˜ì—ì„œ í•™ìŠµí•œ ë‚´ìš©ì„ ì •ë¦¬í•œ í¬ìŠ¤íŒ…ì…ë‹ˆë‹¤.
</div>

<br>

## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜


```python
import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import sklearn.preprocessing
from sklearn.metrics import r2_score

from keras.layers import Dense,Dropout,SimpleRNN,LSTM
from keras.models import Sequential
```


```python
from google.colab import drive
drive.mount('/content/drive')
```

    Mounted at /content/drive
    


```python
# mecab ì„¤ì¹˜

!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git
%cd Mecab-ko-for-Google-Colab
!bash install_mecab-ko_on_colab190912.sh
```

    Cloning into 'Mecab-ko-for-Google-Colab'...
    remote: Enumerating objects: 115, done.[K
    remote: Counting objects: 100% (24/24), done.[K
    remote: Compressing objects: 100% (20/20), done.[K
    remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91[K
    Receiving objects: 100% (115/115), 1.27 MiB | 10.24 MiB/s, done.
    Resolving deltas: 100% (50/50), done.
    /content/Mecab-ko-for-Google-Colab
    Installing konlpy.....
    Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
    Collecting konlpy
      Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m19.4/19.4 MB[0m [31m70.1 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting JPype1>=0.7.0
      Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m465.6/465.6 KB[0m [31m46.4 MB/s[0m eta [36m0:00:00[0m
    [?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)
    Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)
    Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (23.0)
    Installing collected packages: JPype1, konlpy
    Successfully installed JPype1-1.4.1 konlpy-0.6.0
    Done
    Installing mecab-0.996-ko-0.9.2.tar.gz.....
    Downloading mecab-0.996-ko-0.9.2.tar.gz.......
    from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
    --2023-02-06 16:56:58--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
    Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22c0:3470, ...
    Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
    HTTP request sent, awaiting response... 302 Found
    Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNEF262DGD&Signature=gmZiYsFNXB7X259Mn0bsqnPpY7c%3D&x-amz-security-token=FwoGZXIvYXdzENL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDLcg540wLoqDmxvwByK%2BAXPdA%2FF79RPhnAkQCvilIYMQ1n3ow07VFUUBS9lf%2BsNttFMpOoKiig8tiLfaL9vMQ8UgpLkLAFLVtKP43wO2o5RIcGnKo4zaqOOpQ39IKjmbTrAQ%2BuutOHzRRnwYvdlL%2Fz4VQw8jyiY8BMyXMjtT08CdUcq9O3TZ8zhFAfEd1FGs%2F9ZGR2tZdFHEan%2FnwGJHXPf5l%2FrbOwtTfXGC2o9cnheyF5DCCaNd%2Fj4l1vN96NiXCfjgaXSIyN7rdoXaoTYot%2BCEnwYyLevcB5Y8MCzIcFowuBTcOYzH4ho3MK9UBsLCzldh5ETyiHwQ3KGvXZeDLwfSgw%3D%3D&Expires=1675704128 [following]
    --2023-02-06 16:56:58--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNEF262DGD&Signature=gmZiYsFNXB7X259Mn0bsqnPpY7c%3D&x-amz-security-token=FwoGZXIvYXdzENL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDLcg540wLoqDmxvwByK%2BAXPdA%2FF79RPhnAkQCvilIYMQ1n3ow07VFUUBS9lf%2BsNttFMpOoKiig8tiLfaL9vMQ8UgpLkLAFLVtKP43wO2o5RIcGnKo4zaqOOpQ39IKjmbTrAQ%2BuutOHzRRnwYvdlL%2Fz4VQw8jyiY8BMyXMjtT08CdUcq9O3TZ8zhFAfEd1FGs%2F9ZGR2tZdFHEan%2FnwGJHXPf5l%2FrbOwtTfXGC2o9cnheyF5DCCaNd%2Fj4l1vN96NiXCfjgaXSIyN7rdoXaoTYot%2BCEnwYyLevcB5Y8MCzIcFowuBTcOYzH4ho3MK9UBsLCzldh5ETyiHwQ3KGvXZeDLwfSgw%3D%3D&Expires=1675704128
    Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.235.17, 52.217.168.97, 52.217.102.140, ...
    Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.235.17|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 1414979 (1.3M) [application/x-tar]
    Saving to: â€˜mecab-0.996-ko-0.9.2.tar.gzâ€™
    
    mecab-0.996-ko-0.9. 100%[===================>]   1.35M  7.74MB/s    in 0.2s    
    
    2023-02-06 16:56:58 (7.74 MB/s) - â€˜mecab-0.996-ko-0.9.2.tar.gzâ€™ saved [1414979/1414979]
    
    Done
    Unpacking mecab-0.996-ko-0.9.2.tar.gz.......
    Done
    Change Directory to mecab-0.996-ko-0.9.2.......
    installing mecab-0.996-ko-0.9.2.tar.gz........
    configure
    make
    make check
    make install
    ldconfig
    Done
    Change Directory to /content
    Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......
    from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
    --2023-02-06 16:58:39--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
    Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c0:3470, 2406:da00:ff00::6b17:d1f5, ...
    Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
    HTTP request sent, awaiting response... 302 Found
    Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNB3YVVMGH&Signature=pCkkO8Ksf%2Fpgh519O%2Brn%2B6ejA1Y%3D&x-amz-security-token=FwoGZXIvYXdzENL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDHfFWQvswfni%2FckBmSK%2BAclElMhF5bHngDO2omgbiI7jhIxlsGYRHkczwupGkGjAuj0ir0WacqFA%2FCpzUyrTlSS1Lgbsd1r%2Bzxi%2FnELbylThFVboOeixxrF931Un7aaB3fTOuhmbVIdvTSxJ2dBFME8UqLxsY95wkNTXBvoET2M%2BykGm4kN1JGYTYuiGX2zvMujYpt%2BJqVmNWVPk7Glt1OVUDeGygzn2n7iQyu2rhJWadIGaRQVzESPMTibIzmtiICRZgc4KpvnMAHOaoD0ogN2EnwYyLWyvRMkCS%2BTyN0yqkk%2FmWP2yK1LrbT8RINzvoiIqmDpZS%2FsUGjBLEhSl3ueplg%3D%3D&Expires=1675703689 [following]
    --2023-02-06 16:58:39--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNB3YVVMGH&Signature=pCkkO8Ksf%2Fpgh519O%2Brn%2B6ejA1Y%3D&x-amz-security-token=FwoGZXIvYXdzENL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDHfFWQvswfni%2FckBmSK%2BAclElMhF5bHngDO2omgbiI7jhIxlsGYRHkczwupGkGjAuj0ir0WacqFA%2FCpzUyrTlSS1Lgbsd1r%2Bzxi%2FnELbylThFVboOeixxrF931Un7aaB3fTOuhmbVIdvTSxJ2dBFME8UqLxsY95wkNTXBvoET2M%2BykGm4kN1JGYTYuiGX2zvMujYpt%2BJqVmNWVPk7Glt1OVUDeGygzn2n7iQyu2rhJWadIGaRQVzESPMTibIzmtiICRZgc4KpvnMAHOaoD0ogN2EnwYyLWyvRMkCS%2BTyN0yqkk%2FmWP2yK1LrbT8RINzvoiIqmDpZS%2FsUGjBLEhSl3ueplg%3D%3D&Expires=1675703689
    Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.200.81, 52.216.112.243, 3.5.29.123, ...
    Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.200.81|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 49775061 (47M) [application/x-tar]
    Saving to: â€˜mecab-ko-dic-2.1.1-20180720.tar.gzâ€™
    
    mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  69.5MB/s    in 0.7s    
    
    2023-02-06 16:58:40 (69.5 MB/s) - â€˜mecab-ko-dic-2.1.1-20180720.tar.gzâ€™ saved [49775061/49775061]
    
    Done
    Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......
    Done
    Change Directory to mecab-ko-dic-2.1.1-20180720
    Done
    installing........
    configure
    make
    make install
    apt-get update
    apt-get upgrade
    apt install curl
    apt install git
    bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)
    Done
    Successfully Installed
    Now you can use Mecab
    from konlpy.tag import Mecab
    mecab = Mecab()
    ì‚¬ìš©ì ì‚¬ì „ ì¶”ê°€ ë°©ë²• : https://bit.ly/3k0ZH53
    NameError: name 'Tagger' is not defined ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŸ°íƒ€ì„ì„ ì¬ì‹¤í–‰ í•´ì£¼ì„¸ìš”
    ë¸”ë¡œê·¸ì— í•´ê²° ë°©ë²•ì„ ë‚¨ê²¨ì£¼ì‹  tanaë‹˜ ê°ì‚¬í•©ë‹ˆë‹¤.
    


```python
import urllib.request
from collections import Counter
from konlpy.tag import Mecab
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
```

<br>

## 2. ë°ì´í„° ë¡œë“œ, train, test split


```python
urllib.request.urlretrieve("https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt", filename="ratings_total.txt")
```




    ('ratings_total.txt', <http.client.HTTPMessage at 0x7f94b1227be0>)




```python
total_data = pd.read_table('ratings_total.txt', names=['ratings','reviews'])    #column name ì¶”ê°€
print('ì „ì²´ ë¦¬ë·° ê°œìˆ˜: ', len(total_data))
```

    ì „ì²´ ë¦¬ë·° ê°œìˆ˜:  200000
    


```python
total_data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 200000 entries, 0 to 199999
    Data columns (total 2 columns):
     #   Column   Non-Null Count   Dtype 
    ---  ------   --------------   ----- 
     0   ratings  200000 non-null  int64 
     1   reviews  200000 non-null  object
    dtypes: int64(1), object(1)
    memory usage: 3.1+ MB
    


```python
total_data.groupby('ratings').count()
```





  <div id="df-baf06779-fbcd-4d3a-8894-4b52e7545110">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reviews</th>
    </tr>
    <tr>
      <th>ratings</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>36048</td>
    </tr>
    <tr>
      <th>2</th>
      <td>63989</td>
    </tr>
    <tr>
      <th>4</th>
      <td>18786</td>
    </tr>
    <tr>
      <th>5</th>
      <td>81177</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-baf06779-fbcd-4d3a-8894-4b52e7545110')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-baf06779-fbcd-4d3a-8894-4b52e7545110 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-baf06779-fbcd-4d3a-8894-4b52e7545110');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
# í‰ì  4,5ì¸ ë¦¬ë·°ì—ëŠ” ë ˆì´ë¸” 1 / í‰ì  1,2ì¸ ë¦¬ë·°ì—ëŠ” ë ˆì´ë¸” 0
total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)
total_data[:5]
```





  <div id="df-b314d212-81bb-4039-838f-f62dfa758de6">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ratings</th>
      <th>reviews</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>ë°°ê³µë¹ ë¥´ê³  êµ¿</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>íƒë°°ê°€ ì—‰ë§ì´ë„¤ìš© ì €í¬ì§‘ ë°‘ì—ì¸µì— ë§ë„ì—†ì´ ë†”ë‘ê³ ê°€ê³ </td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>ì•„ì£¼ì¢‹ì•„ìš” ë°”ì§€ ì •ë§ ì¢‹ì•„ì„œ2ê°œ ë” êµ¬ë§¤í–ˆì–´ìš” ì´ê°€ê²©ì— ëŒ€ë°•ì…ë‹ˆë‹¤. ë°”ëŠì§ˆì´ ì¡°ê¸ˆ ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>ì„ ë¬¼ìš©ìœ¼ë¡œ ë¹¨ë¦¬ ë°›ì•„ì„œ ì „ë‹¬í–ˆì–´ì•¼ í•˜ëŠ” ìƒí’ˆì´ì—ˆëŠ”ë° ë¨¸ê·¸ì»µë§Œ ì™€ì„œ ë‹¹í™©í–ˆìŠµë‹ˆë‹¤. ì „...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>ë¯¼íŠ¸ìƒ‰ìƒ ì˜ˆë»ìš”. ì˜† ì†ì¡ì´ëŠ” ê±°ëŠ” ìš©ë„ë¡œë„ ì‚¬ìš©ë˜ë„¤ìš” ã…ã…</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-b314d212-81bb-4039-838f-f62dfa758de6')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-b314d212-81bb-4039-838f-f62dfa758de6 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-b314d212-81bb-4039-838f-f62dfa758de6');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
# ì¤‘ë³µ ìƒ˜í”Œ ì œê±°
total_data.drop_duplicates(subset=['reviews'], inplace=True)
print('ì´ ìƒ˜í”Œì˜ ìˆ˜', len(total_data))
```

    ì´ ìƒ˜í”Œì˜ ìˆ˜ 199908
    


```python
# nullê°’ ìœ ë¬´ í™•ì¸

print(total_data.isnull().values.any())
```

    False
    


```python
# 3:1 ë¹„ìœ¨ë¡œ train, test ë‚˜ëˆ„ê¸°

train_data, test_data = train_test_split(total_data, test_size=.25, random_state=42)
print('í›ˆë ¨ ë¦¬ë·° ìˆ˜ :', len(train_data))
print('í…ŒìŠ¤íŠ¸ ë¦¬ë·° ìˆ˜ :', len(test_data))
```

    í›ˆë ¨ ë¦¬ë·° ìˆ˜ : 149931
    í…ŒìŠ¤íŠ¸ ë¦¬ë·° ìˆ˜ : 49977
    


```python
# ë ˆì´ë¸” ë¶„í¬ í™•ì¸
total_data.groupby('label').count()
```





  <div id="df-acd16a0d-f5f2-4911-9ad2-70bfc74bd567">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ratings</th>
      <th>reviews</th>
    </tr>
    <tr>
      <th>label</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>99955</td>
      <td>99955</td>
    </tr>
    <tr>
      <th>1</th>
      <td>99953</td>
      <td>99953</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-acd16a0d-f5f2-4911-9ad2-70bfc74bd567')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-acd16a0d-f5f2-4911-9ad2-70bfc74bd567 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-acd16a0d-f5f2-4911-9ad2-70bfc74bd567');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>


<br>

## 3. ë°ì´í„° ì „ì²˜ë¦¬, í˜•íƒœì†Œ ë¶„ì„


```python
train_data['reviews'] = train_data['reviews'].str.replace("[^ã„±-ã… ã…-ã…£ ê°€-í£]","") #í•œê¸€ê³¼ ê³µë°±ë§Œ ë‚¨ê¸°ê¸°ê¸°
train_data['reviews'].replace('', np.nan, inplace=True)
print(train_data.isnull().sum())
```

    <ipython-input-15-7eeb1b2c945b>:1: FutureWarning: The default value of regex will change from True to False in a future version.
      train_data['reviews'] = train_data['reviews'].str.replace("[^ã„±-ã… ã…-ã…£ ê°€-í£]","") #í•œê¸€ê³¼ ê³µë°±ë§Œ ë‚¨ê¸°ê¸°ê¸°
    

    ratings    0
    reviews    0
    label      0
    dtype: int64
    


```python
test_data.drop_duplicates(subset=['reviews'], inplace=True) 
test_data['reviews'] = test_data['reviews'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]","")
test_data['reviews'].replace("",np.nan,inplace=True)
test_data = test_data.dropna(how='any')
print('ì „ì²˜ë¦¬ í›„ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ìˆ˜: ', len(test_data))
```

    ì „ì²˜ë¦¬ í›„ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ìˆ˜:  49977
    

    <ipython-input-16-c6b4042129ef>:2: FutureWarning: The default value of regex will change from True to False in a future version.
      test_data['reviews'] = test_data['reviews'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]","")
    


```python
mecab = Mecab()
stopwords = ['ë„', 'ëŠ”', 'ë‹¤', 'ì˜', 'ê°€', 'ì´', 'ì€', 'í•œ', 'ì—', 'í•˜', 'ê³ ', 'ì„', 'ë¥¼', 'ì¸', 'ë“¯', 'ê³¼', 'ì™€', 'ë„¤', 'ë“¤', 'ë“¯', 'ì§€', 'ì„', 'ê²Œ']
```


```python
train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)
train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [s for s in x if s not in stopwords])

test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)
test_data['tokenized'] = test_data['reviews'].apply(lambda x: [s for s in x if s not in stopwords])
```


```python
train_data['tokenized']
```




    59666     [ì‚¬ì´ì¦ˆ, ì„¼ì¹˜, ì”©, ëŠ˜ë¦°, ê±´ë°, ì‘, ì•„ìš”, ê·¸ë¦¬ê³ , ìƒ‰ìƒ, ì™„ì „, ë‹¬ë¼ìš”, ...
    12433         [ã…‚, ë¶ˆ, ë§Œì¡±, ë¹—ì´, ì•„í””, ë©, í”¼ë¶€, ë¹—, ì§ˆ, ëª»í•´, ì£¼, ê²Ÿ, ë„¤ìš”]
    146516    [ì œí’ˆ, ì“°, ì‚¼, ì¼, ë§Œ, ë³€ê¸°, ë¬¼, ì˜, ì•ˆ, ë‚´ë ¤ê°”, ì–´ìš”, í˜¹ì‹œë‚˜, í•´ì„œ...
    158109                                        [ì ë‹¹, ë§Œì¡±, í•©ë‹ˆë‹¤]
    70219      [í¸í•˜, ìê³ , ì´ìš©, ë°€í‚¤, íŠ¼, ë°, ì†, ì€ê·¼, ë§ì´, ì„œ, ì €, íŒ¨, ì“°, ìš”]
                                    ...                        
    119904    [ê·¸ëƒ¥, ê·¸ë˜ìš”, ã„·, ã„·, ã„·, ã„·, ã…‚, ã…‚, ã…‚, ã…‚, ê·¸ëƒ¥, ê·¸ë˜ìš”, ã„·, ...
    103714    [ë¹„ì‹¸, ìš”, ì§„ì§œ, ë³„ê±°, ì•„ë‹ˆ, í—ˆì ‘, ìƒê²¼, ëŠ”ë°, ì´ê²Œ, ë§Œ, ì›, ë¼ë‹ˆ, ...
    131960                           [ì¥, ì£¼ë¬¸, ì•ˆ, ë©ë‹ˆë‹¤, ì¥, ê°€ëŠ¥, í•´ìš”]
    146908    [í•˜ë¦¼, ì¹˜í‚¨, ì—¬ê¸°, ì„œ, êµ¬ì…, ë‹ˆ, ì—„ì²­, ì €ë ´, ë„¤ìš”, ë°°ì†¡, ì¾…, ê½, ì–¼...
    121984                       [ì¡°ê¸ˆ, ì•½í•´, ë³´ì´, ëŠ”ë°, ì €ë ´, ì˜, ì‚¿, ì–´ìš”]
    Name: tokenized, Length: 149931, dtype: object


<br>

## 4. ë‹¨ì–´, ê¸¸ì´ì˜ ë¶„í¬ í™•ì¸


```python
negative_words = np.hstack(train_data[train_data.label==0]['tokenized'].values)
positive_words = np.hstack(train_data[train_data.label==1]['tokenized'].values)
```


```python
negative_word_count = Counter(negative_words)
print(negative_word_count.most_common(20))
```

    [('ë„¤ìš”', 31799), ('ëŠ”ë°', 20295), ('ì•ˆ', 19718), ('ì–´ìš”', 14849), ('ìˆ', 13200), ('ë„ˆë¬´', 13058), ('í–ˆ', 11783), ('ì¢‹', 9812), ('ë°°ì†¡', 9677), ('ê°™', 8997), ('êµ¬ë§¤', 8876), ('ì–´', 8869), ('ê±°', 8854), ('ì—†', 8670), ('ì•„ìš”', 8642), ('ìŠµë‹ˆë‹¤', 8436), ('ê·¸ëƒ¥', 8355), ('ë˜', 8345), ('ì˜', 8029), ('ì•Š', 7984)]
    


```python
positive_word_count = Counter(positive_words)
print(positive_word_count.most_common(20))
```

    [('ì¢‹', 39488), ('ì•„ìš”', 21184), ('ë„¤ìš”', 19895), ('ì–´ìš”', 18686), ('ì˜', 18602), ('êµ¬ë§¤', 16171), ('ìŠµë‹ˆë‹¤', 13320), ('ìˆ', 12391), ('ë°°ì†¡', 12275), ('ëŠ”ë°', 11670), ('í–ˆ', 9818), ('í•©ë‹ˆë‹¤', 9801), ('ë¨¹', 9635), ('ì¬', 9273), ('ë„ˆë¬´', 8397), ('ê°™', 7868), ('ë§Œì¡±', 7261), ('ê±°', 6482), ('ì–´', 6294), ('ì“°', 6292)]
    


```python
from wordcloud import WordCloud
import matplotlib.pyplot as plt

%matplotlib inline
def displayWordCloud(data = None, backgroundcolor = 'white', width=None, height=None):
    wordcloud = WordCloud(font_path = '/content/drive/MyDrive/sentence/MALGUN.TTF', 
                          background_color = backgroundcolor, 
                          width = width, 
                          height = height).generate(data)
    plt.figure(figsize = (15 , 10))
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.show()
```


```python
displayWordCloud(data = ' '.join(negative_words), width=600, height=400)
```


    
<img src="https://user-images.githubusercontent.com/115082062/229086634-a13ed41d-9a46-45e0-b6cd-8af3b861a6c0.png">

    

<br>

```python
displayWordCloud(data = ' '.join(positive_words), width=600, height=400)
```


    
<img src="https://user-images.githubusercontent.com/115082062/229086804-7f4756c1-955a-4694-a4ac-0911b25a9e6d.png">

    



```python
fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5))
text_len = train_data[train_data['label']==1]['tokenized'].map(lambda x:len(x)) # ê° rowì˜ ê¸¸ì´ë¥¼ ë°˜í™˜
ax1.hist(text_len, color='red')
ax1.set_title('Positive Reviews')
ax1.set_xlabel('length of samples')
ax1.set_ylabel('number of samples')
print('ê¸ì • ë¦¬ë·° í‰ê·  ê¸¸ì´: ', np.mean(text_len))

text_len = train_data[train_data['label']==0]['tokenized'].map(lambda x:len(x))
ax2.hist(text_len, color='blue')
ax2.set_title('Negative Reviews')
fig.suptitle('Words in texts')
ax2.set_xlabel('length of samples')
ax2.set_ylabel('number of samples')
print('ë¶€ì • ë¦¬ë·°ì˜ í‰ê·  ê¸¸ì´ :', np.mean(text_len))

plt.show()
```

    ê¸ì • ë¦¬ë·° í‰ê·  ê¸¸ì´:  13.587751456414221
    ë¶€ì • ë¦¬ë·°ì˜ í‰ê·  ê¸¸ì´ : 17.029525614672043
    


    
<img src="https://user-images.githubusercontent.com/115082062/229086887-1b2e0e70-657c-4eb1-bb30-8de9a775f52b.png">

<br>
    



```python
X_train = train_data['tokenized'].values
y_train = train_data['label'].values
X_test= test_data['tokenized'].values
y_test = test_data['label'].values
```

<br>

## 5. í† í¬ë‚˜ì´ì§•


```python
tokenizer = Tokenizer()
tokenizer.fit_on_texts(X_train)
```


```python
threshold=2
total_cnt = len(tokenizer.word_index) #vocabìˆ˜
rare_cnt=0  #ë“±ì¥ë¹ˆë„ threshold ë¯¸ë§Œì¸ ë‹¨ì–´ ìˆ˜ ì¹´ìš´íŠ¸
total_freq =0   #í›ˆë ¨ ë°ì´í„°ì˜ ì „ì²´ ë‹¨ì–´ ë¹ˆë„ìˆ˜ ì´í•©
rare_freq = 0   #ë“±ì¥ë¹ˆë„ threshold ë¯¸ë§Œì¸ ë‹¨ì–´ì˜ ë“±ì¥ ë¹ˆë„ìˆ˜ ì´í•©

for key, value in tokenizer.word_counts.items(): # itemsì— ê° ë‹¨ì–´ê°€ ('ë‹¨ì–´', ì¶œí˜„ ë¹ˆë„) í˜•ì‹ìœ¼ë¡œ ì €ì¥ë˜ì–´ìˆë‹¤.
    total_freq += value # sum(ëª¨ë“  ë‹¨ì–´ì˜ ì¶œí˜„ë¹ˆë„)

    if (value < threshold): # íŠ¹ì • ë‹¨ì–´ì˜ ì¶œí˜„ ë¹ˆë„ê°€ ê¸°ì¤€ê°’(2)ë³´ë‹¤ ì‘ìœ¼ë©´
        rare_cnt += 1 # í¬ê·€ ë‹¨ì–´ countë¥¼ í•˜ë‚˜ ì˜¬ë¦¬ê³ 
        rare_freq += value # í¬ê·€ ë‹¨ì–´ ì¶œí˜„ ë¹ˆë„ì— ê·¸ ë‹¨ì–´ì˜ ì¶œí˜„ ë¹ˆë„ë§Œí¼ ë”í•œë‹¤.

print('ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸° :',total_cnt)
print('ë“±ì¥ë¹ˆë„ê°€ %së²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: %s' %(threshold-1, rare_cnt))
print('ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨:', (rare_cnt/total_cnt)*100)
print('ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨:', (rare_freq/total_freq)*100)
```

    ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸° : 39997
    ë“±ì¥ë¹ˆë„ê°€ 1ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 18212
    ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 45.53341500612546
    ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 0.79352492030765
    


```python
# ì „ì²´ ë‹¨ì–´ ì¤‘ ë“±ì¥ ë¹ˆë„ 2 ë¯¸ë§Œì¸ ë‹¨ì–´ ì œê±°í•  ê²ƒ
vocab_size = total_cnt - rare_cnt + 2 #0ë²ˆ íŒ¨ë”© í† í°, OOVí† í° ê³ ë ¤í•´ì„œ +2
print("ë‹¨ì–´ ì§‘í•© í¬ê¸°:", vocab_size)
```

    ë‹¨ì–´ ì§‘í•© í¬ê¸°: 21787
    


```python
'''í† í¬ë‚˜ì´ì €ë¡œ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ìˆ«ì ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
   ì •ìˆ˜ ì¸ì½”ë”©ì—ì„œ ì´ë³´ë‹¤ í° ìˆ«ì ë¶€ì—¬ëœ ë‹¨ì–´ëŠ” OOVë¡œ ë³€í™˜'''

tokenizer = Tokenizer(vocab_size, oov_token='OOV')
tokenizer.fit_on_texts(X_train)
X_train = tokenizer.texts_to_sequences(X_train)
X_test = tokenizer.texts_to_sequences(X_test)
```


```python
# ì •ìˆ˜ ì¸ì½”ë”©ëœ ë‹¨ì–´ë“¤ì´ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ë˜ì—ˆìŒìŒ
print(X_train[:3])
print(X_test[:3])
```

    [[67, 2060, 299, 14260, 263, 73, 6, 236, 168, 137, 805, 2951, 625, 2, 77, 62, 207, 40, 1343, 155, 3, 6], [482, 409, 52, 8530, 2561, 2517, 339, 2918, 250, 2357, 38, 473, 2], [46, 24, 825, 105, 35, 2372, 160, 7, 10, 8061, 4, 1319, 29, 140, 322, 41, 59, 160, 140, 7, 1916, 2, 113, 162, 1379, 323, 119, 136]]
    [[721, 581, 1, 704, 1, 767, 1, 116, 1, 434, 1832, 522, 3516, 1935, 59], [956, 991, 1, 1, 1302, 1, 113, 1, 640, 56, 22], [410, 3327, 1, 1274, 2079, 22, 1, 5418, 290, 134, 1, 3, 27, 1, 15, 28, 22, 1, 513, 1, 449, 17, 33, 1, 618, 1342, 1, 33, 59, 1, 7, 1, 22]]
    

<br>

## 6. íŒ¨ë”©


```python
print("ë¦¬ë·° ìµœëŒ€ ê¸¸ì´: ", max(len(l) for l in X_train))
print("ë¦¬ë·° í‰ê·  ê¸¸ì´: ", sum(map(len, X_train))/len(X_train))
```

    ë¦¬ë·° ìµœëŒ€ ê¸¸ì´:  85
    ë¦¬ë·° í‰ê·  ê¸¸ì´:  15.30754813881052
    


```python
plt.hist([len(s) for s in X_train], bins=50)
plt.xlabel('length of samples')
plt.ylabel('number of samles')
plt.show()
```


    
<img src="https://user-images.githubusercontent.com/115082062/229087006-68311587-6007-4aca-b9d1-eb63dcdfb76d.png">

    



```python
def below_threshold_len(max_len, nested_list):
    cnt=0
    for s in nested_list:
        if(len(s) <= max_len):
            cnt += 1
    print("ì „ì²´ ìƒ˜í”Œ ì¤‘ ê¸¸ì´ê°€ %s ì´í•˜ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨: %s" %(max_len, (cnt/len(nested_list))*100))
```


```python
max_len = 55
below_threshold_len(max_len, X_train)
```

    ì „ì²´ ìƒ˜í”Œ ì¤‘ ê¸¸ì´ê°€ 55 ì´í•˜ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨: 99.8459291273986
    


```python
# ê¸¸ì´ 55ë¡œ íŒ¨ë”©
X_train = pad_sequences(X_train, maxlen = max_len)
X_test = pad_sequences(X_test, maxlen = max_len)
```

<br>

## 7. GRUë¡œ ê°ì„±ë¶„ë¥˜

ì½”ë© ëŸ°íƒ€ì„ ìœ í˜•ì„ GPUë¡œ ë°”ê¾¸ê³  ì‹¤í–‰í–ˆë‹¤.


```python
from keras.layers import Embedding, Dense, GRU, Dropout, Activation
from keras.models import Sequential, load_model
from keras.callbacks import EarlyStopping, ModelCheckpoint
```


```python
gru_model = Sequential()
gru_model.add(Embedding(input_dim= vocab_size,output_dim= 100))
gru_model.add(GRU(128))
gru_model.add(Dense(1, activation='sigmoid'))

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)

gru_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])

history = gru_model.fit(X_train, y_train, epochs=15, callbacks=[es,mc], batch_size=60, validation_split=.2)
```

    Epoch 1/15
    1994/2000 [============================>.] - ETA: 0s - loss: 0.2725 - acc: 0.8971
    Epoch 1: val_acc improved from -inf to 0.91833, saving model to best_model.h5
    2000/2000 [==============================] - 24s 9ms/step - loss: 0.2725 - acc: 0.8971 - val_loss: 0.2285 - val_acc: 0.9183
    Epoch 2/15
    1995/2000 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9230
    Epoch 2: val_acc did not improve from 0.91833
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.2147 - acc: 0.9230 - val_loss: 0.2326 - val_acc: 0.9133
    Epoch 3/15
    2000/2000 [==============================] - ETA: 0s - loss: 0.1983 - acc: 0.9293
    Epoch 3: val_acc improved from 0.91833 to 0.92767, saving model to best_model.h5
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.1983 - acc: 0.9293 - val_loss: 0.2028 - val_acc: 0.9277
    Epoch 4/15
    1997/2000 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9336
    Epoch 4: val_acc did not improve from 0.92767
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.1873 - acc: 0.9335 - val_loss: 0.2142 - val_acc: 0.9208
    Epoch 5/15
    1996/2000 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9372
    Epoch 5: val_acc did not improve from 0.92767
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.1781 - acc: 0.9372 - val_loss: 0.2068 - val_acc: 0.9251
    Epoch 6/15
    2000/2000 [==============================] - ETA: 0s - loss: 0.1689 - acc: 0.9408
    Epoch 6: val_acc did not improve from 0.92767
    2000/2000 [==============================] - 19s 9ms/step - loss: 0.1689 - acc: 0.9408 - val_loss: 0.2191 - val_acc: 0.9218
    Epoch 7/15
    1998/2000 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9442
    Epoch 7: val_acc did not improve from 0.92767
    2000/2000 [==============================] - 19s 9ms/step - loss: 0.1597 - acc: 0.9442 - val_loss: 0.2137 - val_acc: 0.9232
    Epoch 7: early stopping
    


```python
gru_model = Sequential()
gru_model.add(Embedding(input_dim= vocab_size,output_dim= 100))
gru_model.add(GRU(128))
gru_model.add(Activation('tanh'))
gru_model.add(Dropout(0.2))
gru_model.add(Dense(1, activation='relu'))

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)

gru_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])

history = gru_model.fit(X_train, y_train, epochs=15, callbacks=[es,mc], batch_size=60, validation_split=.2)
```

    Epoch 1/15
    1998/2000 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.8783
    Epoch 1: val_acc improved from -inf to 0.90232, saving model to best_model.h5
    2000/2000 [==============================] - 20s 9ms/step - loss: 0.5147 - acc: 0.8783 - val_loss: 0.7252 - val_acc: 0.9023
    Epoch 2/15
    1997/2000 [============================>.] - ETA: 0s - loss: 0.4555 - acc: 0.9074
    Epoch 2: val_acc improved from 0.90232 to 0.91166, saving model to best_model.h5
    2000/2000 [==============================] - 19s 10ms/step - loss: 0.4553 - acc: 0.9074 - val_loss: 0.5507 - val_acc: 0.9117
    Epoch 3/15
    1999/2000 [============================>.] - ETA: 0s - loss: 0.4140 - acc: 0.9159
    Epoch 3: val_acc improved from 0.91166 to 0.92063, saving model to best_model.h5
    2000/2000 [==============================] - 17s 9ms/step - loss: 0.4140 - acc: 0.9159 - val_loss: 0.4179 - val_acc: 0.9206
    Epoch 4/15
    1994/2000 [============================>.] - ETA: 0s - loss: 0.4019 - acc: 0.9226
    Epoch 4: val_acc improved from 0.92063 to 0.92293, saving model to best_model.h5
    2000/2000 [==============================] - 17s 9ms/step - loss: 0.4015 - acc: 0.9226 - val_loss: 0.3970 - val_acc: 0.9229
    Epoch 5/15
    1998/2000 [============================>.] - ETA: 0s - loss: 0.3799 - acc: 0.9271
    Epoch 5: val_acc did not improve from 0.92293
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.3801 - acc: 0.9270 - val_loss: 0.3479 - val_acc: 0.9183
    Epoch 6/15
    1995/2000 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.9310
    Epoch 6: val_acc did not improve from 0.92293
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.3787 - acc: 0.9311 - val_loss: 0.4709 - val_acc: 0.9204
    Epoch 7/15
    1998/2000 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.9337
    Epoch 7: val_acc did not improve from 0.92293
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.3748 - acc: 0.9337 - val_loss: 0.3532 - val_acc: 0.9122
    Epoch 8/15
    1995/2000 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.9373
    Epoch 8: val_acc did not improve from 0.92293
    2000/2000 [==============================] - 17s 9ms/step - loss: 0.3463 - acc: 0.9373 - val_loss: 0.3703 - val_acc: 0.9194
    Epoch 9/15
    1999/2000 [============================>.] - ETA: 0s - loss: 0.3580 - acc: 0.9399
    Epoch 9: val_acc did not improve from 0.92293
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.3580 - acc: 0.9399 - val_loss: 0.4435 - val_acc: 0.9219
    Epoch 9: early stopping
    


```python
gru_model = Sequential()
gru_model.add(Embedding(input_dim= vocab_size,output_dim= 256))
gru_model.add(GRU(128))
gru_model.add(Dropout(0.3))
gru_model.add(Dense(1, activation='sigmoid'))

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)

gru_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])

history = gru_model.fit(X_train, y_train, epochs=15, callbacks=[es,mc], batch_size=60, validation_split=.2)
```

    Epoch 1/15
    1996/2000 [============================>.] - ETA: 0s - loss: 0.2660 - acc: 0.9005
    Epoch 1: val_acc improved from -inf to 0.91356, saving model to best_model.h5
    2000/2000 [==============================] - 19s 9ms/step - loss: 0.2660 - acc: 0.9005 - val_loss: 0.2375 - val_acc: 0.9136
    Epoch 2/15
    1995/2000 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9236
    Epoch 2: val_acc improved from 0.91356 to 0.92437, saving model to best_model.h5
    2000/2000 [==============================] - 17s 8ms/step - loss: 0.2118 - acc: 0.9236 - val_loss: 0.2077 - val_acc: 0.9244
    Epoch 3/15
    2000/2000 [==============================] - ETA: 0s - loss: 0.1949 - acc: 0.9311
    Epoch 3: val_acc improved from 0.92437 to 0.92747, saving model to best_model.h5
    2000/2000 [==============================] - 22s 11ms/step - loss: 0.1949 - acc: 0.9311 - val_loss: 0.2061 - val_acc: 0.9275
    Epoch 4/15
    1999/2000 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9361
    Epoch 4: val_acc improved from 0.92747 to 0.92787, saving model to best_model.h5
    2000/2000 [==============================] - 17s 9ms/step - loss: 0.1828 - acc: 0.9361 - val_loss: 0.2009 - val_acc: 0.9279
    Epoch 5/15
    1993/2000 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9406
    Epoch 5: val_acc did not improve from 0.92787
    2000/2000 [==============================] - 17s 8ms/step - loss: 0.1717 - acc: 0.9405 - val_loss: 0.2026 - val_acc: 0.9265
    Epoch 6/15
    1998/2000 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9444
    Epoch 6: val_acc did not improve from 0.92787
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.1619 - acc: 0.9444 - val_loss: 0.2105 - val_acc: 0.9251
    Epoch 7/15
    1997/2000 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9484
    Epoch 7: val_acc did not improve from 0.92787
    2000/2000 [==============================] - 18s 9ms/step - loss: 0.1515 - acc: 0.9485 - val_loss: 0.2094 - val_acc: 0.9233
    Epoch 8/15
    1997/2000 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9517
    Epoch 8: val_acc did not improve from 0.92787
    2000/2000 [==============================] - 17s 8ms/step - loss: 0.1420 - acc: 0.9517 - val_loss: 0.2217 - val_acc: 0.9212
    Epoch 8: early stopping
    


```python
# epochë³„ ì •í™•ë„ ê·¸ë˜í”„
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#epochë³„ loss ê·¸ë˜í”„
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
```


    
<img src="https://user-images.githubusercontent.com/115082062/229087082-7edbd1f1-2c68-4836-a094-1ef2d70c5f44.png">

    



    
<img src="https://user-images.githubusercontent.com/115082062/229087227-dda7fab4-6e9a-4949-a733-16d72a2e85b3.png">

<br>
    

