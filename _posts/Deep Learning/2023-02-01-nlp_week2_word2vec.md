---
title: "[NLP] Word2Vec ì—°ìŠµ"
excerpt: "Word2Vecë¥¼ ì‚¬ìš©í•˜ì—¬ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë‹¨ì–´ í† í°í™”"
toc: true
toc_label: "ëª©ì°¨"
toc_sticky: true

tags: [Deep Learning, NLP, Word2Vec]

published: true

categories:
  - DL

date: 2023-02-01 21:00:00
last_modified_at: 2023-02-01 21:00:00
---


<br>

<div class="notice--primary" markdown="1">
ğŸ’¡ êµë‚´ í•™íšŒ NLP ë¶„ë°˜ì—ì„œ í•™ìŠµí•œ ë‚´ìš©ì„ ì •ë¦¬í•œ í¬ìŠ¤íŒ…ì…ë‹ˆë‹¤.
</div>

<br>


```python
import gensim
gensim.__version__
```




    '3.6.0'




```python
!pip install konlpy
```


### Okt ëŠë¦´ ê²½ìš° Mecab ì‚¬ìš©!
Okt í˜•íƒœì†Œ ë¶„ì„ê¸°ê°€ ëŠë¦´ ê²½ìš° Mecabìœ¼ë¡œ í•˜ë©´ ë” ë‚˜ì€ ì†ë„ë¡œ ì…€ì´ ì‹¤í–‰ëœë‹¤. ì•„ë˜ ë°©ë²•ëŒ€ë¡œ Mecabì„ ì„¤ì¹˜í•  ìˆ˜ ìˆë‹¤.


```python
! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git
```

    Cloning into 'Mecab-ko-for-Google-Colab'...
    remote: Enumerating objects: 115, done.[K
    remote: Counting objects: 100% (24/24), done.[K
    remote: Compressing objects: 100% (20/20), done.[K
    remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91[K
    Receiving objects: 100% (115/115), 1.27 MiB | 6.19 MiB/s, done.
    Resolving deltas: 100% (50/50), done.
    


```python
cd Mecab-ko-for-Google-Colab
```

    /content/Mecab-ko-for-Google-Colab
    


```python
!bash install_mecab-ko_on_colab_light_220429.sh
```


```python
from konlpy.tag import Mecab
```

`name 'Tagger' is not defined` ì˜¤ë¥˜ê°€ ëœ¨ë©´ ëŸ°íƒ€ì„ ì¬ì‹¤í–‰!


```python
mecab = Mecab()
```

<br>

## 1. ì˜ì–´ Word2Vec ë§Œë“¤ê¸°


```python
import re
import urllib.request
import zipfile
from lxml import etree
from nltk.tokenize import word_tokenize, sent_tokenize
```


```python
import nltk
nltk.download('punkt')
```

    [nltk_data] Downloading package punkt to /root/nltk_data...
    [nltk_data]   Unzipping tokenizers/punkt.zip.
    




    True




```python
# í›ˆë ¨ë°ì´í„° ë‹¤ìš´ë¡œë“œ
urllib.request.urlretrieve("https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml", filename="ted_en-20160408.xml")
```




    ('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7fe4c4e64b20>)




```python
targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')
target_text = etree.parse(targetXML)

# xml íŒŒì¼ë¡œë¶€í„° <content>ì™€ </content> ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ê°€ì ¸ì˜¨ë‹¤.
parse_text = '\n'.join(target_text.xpath('//content/text()'))

# ì •ê·œ í‘œí˜„ì‹ì˜ sub ëª¨ë“ˆì„ í†µí•´ content ì¤‘ê°„ì— ë“±ì¥í•˜ëŠ” (Audio), (Laughter) ë“±ì˜ ë°°ê²½ìŒ ë¶€ë¶„ì„ ì œê±°.
# í•´ë‹¹ ì½”ë“œëŠ” ê´„í˜¸ë¡œ êµ¬ì„±ëœ ë‚´ìš©ì„ ì œê±°.
content_text = re.sub(r'\([^)]*\)', '', parse_text)

# ì…ë ¥ ì½”í¼ìŠ¤ì— ëŒ€í•´ì„œ NLTKë¥¼ ì´ìš©í•˜ì—¬ ë¬¸ì¥ í† í°í™”ë¥¼ ìˆ˜í–‰.
sent_text = sent_tokenize(content_text)

# ê° ë¬¸ì¥ì— ëŒ€í•´ì„œ êµ¬ë‘ì ì„ ì œê±°í•˜ê³ , ëŒ€ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜.
normalized_text = []
for string in sent_text:
     tokens = re.sub(r"[^a-z0-9]+", " ", string.lower())
     normalized_text.append(tokens)

# ê° ë¬¸ì¥ì— ëŒ€í•´ì„œ NLTKë¥¼ ì´ìš©í•˜ì—¬ ë‹¨ì–´ í† í°í™”ë¥¼ ìˆ˜í–‰.
result = [word_tokenize(sentence) for sentence in normalized_text]
```


```python
print('ì´ ìƒ˜í”Œì˜ ê°œìˆ˜ : {}'.format(len(result)))
```

    ì´ ìƒ˜í”Œì˜ ê°œìˆ˜ : 273380
    


```python
# ìƒ˜í”Œ 3ê°œë§Œ ì¶œë ¥
for line in result[:3]:
    print(line)
```

    ['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']
    ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']
    ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']
    


```python
from gensim.models import Word2Vec
from gensim.models import KeyedVectors
```

- `size` = ì›Œë“œ ë²¡í„°ì˜ íŠ¹ì§• ê°’. ì¦‰, ì„ë² ë”© ëœ ë²¡í„°ì˜ ì°¨ì›.
- `window` = ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸°
- `min_count` = ë‹¨ì–´ ìµœì†Œ ë¹ˆë„ ìˆ˜ ì œí•œ (ë¹ˆë„ê°€ ì ì€ ë‹¨ì–´ë“¤ì€ í•™ìŠµí•˜ì§€ ì•ŠëŠ”ë‹¤.)
- `workers` = í•™ìŠµì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ìˆ˜
- `sg` = 0ì€ CBOW, 1ì€ Skip-gram.

CBOWëŠ” target word ê·¼ì²˜ì˜ ë¬¸ë§¥ì„ íŒŒì•…í•˜ì—¬ target wordë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì´ê³ , Skip-gramì€ target wordë¥¼ ë³´ê³  ë¬¸ë§¥ì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì´ë‹¤. `window`ë€ ì¸ìëŠ” ê·¼ì²˜ ë¬¸ë§¥ì˜ ë‹¨ì–´ë¥¼ ëª‡ê°œë¡œ í• ì§€ ê·¸ í¬ê¸°ë¥¼ ì„¤ì •í•˜ëŠ” ì¸ìì´ë‹¤.

![neural language model vs word2vec](https://user-images.githubusercontent.com/115082062/213910013-2c91f210-090d-47f7-b842-33f64a3b2c50.png)



```python
model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)
```

`model.wv.most_similar()`ë¥¼ í†µí•´ ì…ë ¥í•œ ë‹¨ì–´ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶œë ¥í•´ì¤€ë‹¤.


```python
model_result = model.wv.most_similar("ball")
print(model_result)
```

    [('button', 0.7781341075897217), ('rock', 0.7767028212547302), ('wheel', 0.7757996320724487), ('glass', 0.7734857201576233), ('rope', 0.7651770114898682), ('hole', 0.7528566718101501), ('balloon', 0.7417528033256531), ('grass', 0.7401809096336365), ('keyboard', 0.736878514289856), ('wire', 0.7237794399261475)]
    

ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚°ì •ëœ ë²¡í„°ë“¤ì´ê¸° ë•Œë¬¸ì— ì—°ì‚°ë„ ê°€ëŠ¥í•˜ë‹¤.


```python
model.wv.most_similar(positive=['woman'], negative=['man'])
```




    [('cancer', 0.3617965281009674),
     ('pregnant', 0.3389925956726074),
     ('failed', 0.3244003653526306),
     ('born', 0.322529673576355),
     ('married', 0.32099631428718567),
     ('her', 0.3199157416820526),
     ('older', 0.3169713616371155),
     ('child', 0.3151988387107849),
     ('united', 0.3039064109325409),
     ('patient', 0.29988113045692444)]




```python
model.wv.save_word2vec_format('eng_w2v') # ëª¨ë¸ ì €ì¥
loaded_model = KeyedVectors.load_word2vec_format("eng_w2v") # ëª¨ë¸ ë¡œë“œ
```


```python
model_result = loaded_model.most_similar("ball")
print(model_result)
```

    [('button', 0.7781341075897217), ('rock', 0.7767028212547302), ('wheel', 0.7757996320724487), ('glass', 0.7734857201576233), ('rope', 0.7651770114898682), ('hole', 0.7528566718101501), ('balloon', 0.7417528033256531), ('grass', 0.7401809096336365), ('keyboard', 0.736878514289856), ('wire', 0.7237794399261475)]
    

<br>

## 2. í•œêµ­ì–´ Word2Vec ë§Œë“¤ê¸°


```python
import pandas as pd
import matplotlib.pyplot as plt
import urllib.request
from gensim.models.word2vec import Word2Vec
from konlpy.tag import Okt
import tqdm
```


```python
# ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„° ë‹¤ìš´ë¡œë“œ
urllib.request.urlretrieve("https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt", filename="ratings.txt")
```




    ('ratings.txt', <http.client.HTTPMessage at 0x7fb484cab0a0>)




```python
train_data = pd.read_table('ratings.txt')
```


```python
train_data.head()
```





  <div id="df-7475dda5-c0ea-4737-87d7-3f2b14fdd497">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>document</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8112052</td>
      <td>ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8132799</td>
      <td>ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ, ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4655635</td>
      <td>í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” 1ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ.. ìµœê³ .</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9251303</td>
      <td>ì™€.. ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜.. ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤.. ê·¸ë˜ ì´ëŸ°...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10067386</td>
      <td>ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”.</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7475dda5-c0ea-4737-87d7-3f2b14fdd497')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-7475dda5-c0ea-4737-87d7-3f2b14fdd497 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-7475dda5-c0ea-4737-87d7-3f2b14fdd497');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
print(len(train_data))
```

    200000
    


```python
train_data.info() # ê²°ì¸¡ê°’ì´ ì¡´ì¬í•˜ëŠ” í–‰ 8ê°œ ìˆìŒ
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 200000 entries, 0 to 199999
    Data columns (total 3 columns):
     #   Column    Non-Null Count   Dtype 
    ---  ------    --------------   ----- 
     0   id        200000 non-null  int64 
     1   document  199992 non-null  object
     2   label     200000 non-null  int64 
    dtypes: int64(2), object(1)
    memory usage: 4.6+ MB
    


```python
train_data = train_data.dropna(how = 'any') # ê²°ì¸¡ ê°’ ì¡´ì¬í•˜ëŠ” í–‰ ì œê±°
```


```python
print(len(train_data)) # 8ê°œ í–‰ì´ ì‚¬ë¼ì§
```

    199992
    


```python
# ì •ê·œ í‘œí˜„ì‹ì„ í†µí•œ í•œê¸€ ì™¸ ë¬¸ì ì œê±°
train_data['document'] = train_data['document'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]","")
```

    <ipython-input-8-d10eedfa8951>:2: FutureWarning: The default value of regex will change from True to False in a future version.
      train_data['document'] = train_data['document'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]","")
    


```python
train_data.head()
```





  <div id="df-6ac77ccd-b9b4-41bb-9cef-8374a3476340">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>document</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8112052</td>
      <td>ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8132799</td>
      <td>ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°ì—…...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4655635</td>
      <td>í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ ìµœê³ </td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9251303</td>
      <td>ì™€ ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜ ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤ ê·¸ë˜ ì´ëŸ°ê²Œ ì§„ì§œ ì˜í™”ì§€</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10067386</td>
      <td>ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6ac77ccd-b9b4-41bb-9cef-8374a3476340')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6ac77ccd-b9b4-41bb-9cef-8374a3476340 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6ac77ccd-b9b4-41bb-9cef-8374a3476340');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
from google import colab
colab.drive.mount("/content/drive")
```

    Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
    


```python
# ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ì •ì˜
with open('/content/drive/MyDrive/sentence/stopwords.txt',  encoding='cp949') as f:
    list_file = f.readlines()
    stopwords = list_file[0].split(",")
```

oktë¡œ í•  ë•Œ 17ë¶„ ê±¸ë¦¬ëŠ” ê²ƒì´ mecabìœ¼ë¡œ í•  ë• 1ë¶„ë°–ì— ì•ˆ ê±¸ë¦°ë‹¤.


```python
okt = Okt()

tokenized_data = []
for sentence in tqdm.tqdm(train_data['document']):
    tokenized_sentence = okt.morphs(sentence, stem=True) # í† í°í™”
    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # ë¶ˆìš©ì–´ ì œê±°
    tokenized_data.append(stopwords_removed_sentence)
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199992/199992 [17:30<00:00, 190.29it/s]
    


```python
tokenized_data = []
for sentence in tqdm.tqdm(train_data['document']):
    tokenized_sentence = mecab.morphs(sentence) # í† í°í™”
    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # ë¶ˆìš©ì–´ ì œê±°
    tokenized_data.append(stopwords_removed_sentence)
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199992/199992 [01:18<00:00, 2549.23it/s]
    


```python
print(tokenized_data[:3])
```

    [['ì–´ë¦´', 'ë³´', 'ê³ ', 'ë´ë„', 'ì¬ë°Œ', 'ì–´ìš”'], ['ë””ìì¸', 'ë°°ìš°', 'í•™ìƒ', 'ì™¸êµ­', 'ë””ìì´ë„ˆ', 'ì¼êµ°', 'ì „í†µ', 'í†µí•´', 'ë°œì „', 'í•´', 'ë¬¸í™”', 'ì‚°ì—…', 'ë¶€ëŸ¬ì› ', 'ëŠ”ë°', 'ì‚¬ì‹¤', 'ë‚˜ë¼', 'ì–´ë ¤ìš´', 'ì‹œì ˆ', 'ë', 'ì—´ì •', 'ì§€í‚¨', 'ë…¸ë¼ë…¸', 'ê°™', 'ì „í†µ', 'ìˆ', 'ê°™', 'ì‚¬ëŒ', 'ê¿ˆ', 'ê¾¸', 'ê³ ', 'ì´ë¤„ë‚˜ê°ˆ', 'ìˆ˜', 'ìˆ', 'ë‹¤ëŠ”', 'ê°ì‚¬', 'í•©ë‹ˆë‹¤'], ['í´ë¦¬ìŠ¤', 'ìŠ¤í† ë¦¬', 'ì‹œë¦¬ì¦ˆ', 'ë‰´', 'ë²„ë¦´', 'ê»˜', 'ì—†', 'ìŒ', 'ìµœê³ ']]
    

ë¶ˆìš©ì–´ì˜ ê°œìˆ˜ë¥¼ ëŠ˜ë ¸ë”ë‹ˆ ì˜ˆì‹œë³´ë‹¤ ê¸¸ì´ê°€ ë” ì§§ì•„ì¡Œë‹¤.


```python
# ë¦¬ë·° ê¸¸ì´ ë¶„í¬ í™•ì¸
print('ë¦¬ë·°ì˜ ìµœëŒ€ ê¸¸ì´ :',max(len(review) for review in tokenized_data))
print('ë¦¬ë·°ì˜ í‰ê·  ê¸¸ì´ :',sum(map(len, tokenized_data))/len(tokenized_data))
plt.hist([len(review) for review in tokenized_data], bins=50)
plt.xlabel('length of samples')
plt.ylabel('number of samples')
plt.show()
```

    ë¦¬ë·°ì˜ ìµœëŒ€ ê¸¸ì´ : 70
    ë¦¬ë·°ì˜ í‰ê·  ê¸¸ì´ : 10.689342573702948
    


    
<img src="https://user-images.githubusercontent.com/115082062/228714723-cfe6a40f-9be3-4180-9197-d711e3d25139.png">
    



```python
model = Word2Vec(sentences = tokenized_data, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)
```


```python
model.wv.vectors.shape # ì´ 17806ê°œì˜ ë‹¨ì–´ê°€ 100ì°¨ì›ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤.
```




    (17806, 100)




```python
print(model.wv.most_similar("ì´ë™ì§„")) 
#ê°™ì€ í‰ë¡ ê°€ì¸ ê¹€í˜œë¦¬, ë°•í‰ì‹ì´ ë³´ì¸ë‹¤. 'ì‹ì´'ëŠ” ë°•í‰ì‹ì˜ ë³„ì¹­ì¸ 'í‰ì‹ì´í˜•'ì—ì„œ ë–¨ì–´ì ¸ ë‚˜ì˜¨ ê²ƒ ê°™ë‹¤.
```

    [('ê¹€í˜œë¦¬', 0.8537285327911377), ('ì‹ì´', 0.8399664163589478), ('ì”¨ë„¤', 0.8380143642425537), ('ë°•í‰ì‹', 0.8304151296615601), ('í—ˆì§€ì›…', 0.8267611861228943), ('ìˆœë¡€', 0.8207776546478271), ('ì‹ ë¶„', 0.8180666565895081), ('ì¶©', 0.815009355545044), ('ì´ìš©ì² ', 0.811989426612854), ('ì„±ì§€', 0.810979962348938)]
    


```python
model.wv.most_similar(positive=['íƒ€ì§œ'])
```




    [('ê³µê³µ', 0.9504997134208679),
     ('ë„˜ì‚¬ë²½', 0.9432716965675354),
     ('ì¸ì •ë°›ë‹¤', 0.9430745840072632),
     ('ì„¸ë¥´', 0.9405409693717957),
     ('ë””ìŠ¤ì½”', 0.9401938915252686),
     ('ë²¤í—ˆ', 0.9397081136703491),
     ('êµë³¸', 0.9386974573135376),
     ('ì˜ì ', 0.9380705952644348),
     ('ê²½ì§€', 0.9379533529281616),
     ('ì• ë‹ˆë©”', 0.9374954700469971)]




```python
model.wv.most_similar(positive=['ì†¡ê°•í˜¸'], negative=['ì£¼ì—°'])
```




    [('íœ´ì¼', 0.6941962242126465),
     ('ì—‡ìŒ', 0.6847164034843445),
     ('í€µ', 0.6747357249259949),
     ('ê³ ì¬', 0.669157862663269),
     ('ì„œì—¬', 0.6675720810890198),
     ('í™€ë¦°', 0.6667022109031677),
     ('ì•„ë³´', 0.6652776598930359),
     ('ì›ì¹˜ì•Šë‹¤', 0.6618590354919434),
     ('ë§ì¶¤ë²•', 0.661419153213501),
     ('ë…¹ì°¨', 0.6606814861297607)]




```python
model.wv.similarity('ì†¡ê°•í˜¸', 'í•˜ì •ìš°')
```




    0.870262




```python
model.wv.similarity('ì†¡ê°•í˜¸', 'ì•¼êµ¬')
```




    0.19670776

<br>


## 3. ì‚¬ì „ í›ˆë ¨ëœ Word2Vec

êµ¬ê¸€ì—ì„œ ì œê³µí•˜ëŠ” ì‚¬ì „ í›ˆë ¨ëœ Word2Vec ëª¨ë¸ì„ ê°€ì ¸ì˜¬ ê²ƒì´ë‹¤. ì´ ëª¨ë¸ì€ 3ë°±ë§Œ ê°œì˜ ë‹¨ì–´ë¥¼ 300ì°¨ì›ì˜ ì„ë² ë”© ë²¡í„°ë¡œ ë§Œë“¤ì–´ë†“ì€ ê²ƒì´ë‹¤.

ì˜ˆì‹œ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ë‹¤ `HTTP Error 404: Not Found` ì—ëŸ¬ê°€ ë‚˜ëŠ” ê²½ìš°ëŠ”

https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit

ìœ„ ë§í¬ì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë°›ê³  ì••ì¶•ì„ í‘¼ í›„ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì ë‹¹í•œ ë””ë ‰í† ë¦¬ì— ë„£ì–´ë‘ê³  ì‹¤í–‰í•˜ë©´ ëœë‹¤.


```python
import gensim
import urllib.request

# ëª¨ë¸ ì €ì¥í•´ë†“ì€ ê²½ë¡œë¥¼ ì ì–´ì£¼ë©´ ëœë‹¤
word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/kubig/GoogleNews-vectors-negative300.bin', binary=True)
```

3ë°±ë§Œ ê°œì˜ ë‹¨ì–´ê°€ ì €ì¥ëœ ëª¨ë¸ì´ë‹¤ë³´ë‹ˆ ìš©ëŸ‰ì´ 3ê¸°ê°€ê°€ ë„˜ëŠ”ë‹¤.


```python
print(word2vec_model.vectors.shape)
```

    (3000000, 300)
    

`similarity()`ë¥¼ í†µí•´ ë‘ ë‹¨ì–´ì˜ ìœ ì‚¬ë„ë¥¼ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤.


```python
print(word2vec_model.similarity('baseball', 'football'))
print(word2vec_model.similarity('baseball', 'car'))
```

    0.6162001
    0.1090335
    
